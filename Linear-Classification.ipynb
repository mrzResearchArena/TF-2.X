{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Linear-Classification.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mrzResearchArena/TF-2.X/blob/master/Linear-Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "51CB8bMaQG3t",
        "colab_type": "code",
        "outputId": "65d58645-32c2-42a5-bedb-c78a03fc041c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "try:\n",
        "    %tensorflow_version 2.x  # Colab only.\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "import tensorflow as tf\n",
        "import sklearn\n",
        "import numpy as np\n",
        "print(tf.__version__)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "`%tensorflow_version` only switches the major version: `1.x` or `2.x`.\n",
            "You set: `2.x  # Colab only.`. This will be interpreted as: `2.x`.\n",
            "\n",
            "\n",
            "TensorFlow 2.x selected.\n",
            "2.1.0-rc1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iYfAz4yvQcMV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.datasets import load_breast_cancer \n",
        "D = load_breast_cancer()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IhKGwF7cRaEH",
        "colab_type": "code",
        "outputId": "77e1e95a-d547-4df4-846f-e7966ff2cb71",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "D.keys()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['data', 'target', 'target_names', 'DESCR', 'feature_names', 'filename'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cc9gTDtsRiUW",
        "colab_type": "code",
        "outputId": "98bfcfed-a746-4319-ae5d-df75075e046e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 249
        }
      },
      "source": [
        "X = D['data']\n",
        "# X.shape # --> (569, 30)\n",
        "X"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2.654e-01, 4.601e-01,\n",
              "        1.189e-01],\n",
              "       [2.057e+01, 1.777e+01, 1.329e+02, ..., 1.860e-01, 2.750e-01,\n",
              "        8.902e-02],\n",
              "       [1.969e+01, 2.125e+01, 1.300e+02, ..., 2.430e-01, 3.613e-01,\n",
              "        8.758e-02],\n",
              "       ...,\n",
              "       [1.660e+01, 2.808e+01, 1.083e+02, ..., 1.418e-01, 2.218e-01,\n",
              "        7.820e-02],\n",
              "       [2.060e+01, 2.933e+01, 1.401e+02, ..., 2.650e-01, 4.087e-01,\n",
              "        1.240e-01],\n",
              "       [7.760e+00, 2.454e+01, 4.792e+01, ..., 0.000e+00, 2.871e-01,\n",
              "        7.039e-02]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Xq9_NzRRofW",
        "colab_type": "code",
        "outputId": "f19fc8da-0329-4c39-da2e-adf071e75328",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 482
        }
      },
      "source": [
        "Y = D['target']\n",
        "# Y.shape # --> (569,)\n",
        "Y"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0,\n",
              "       1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "       1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
              "       0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1,\n",
              "       1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0,\n",
              "       0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0,\n",
              "       1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n",
              "       1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0,\n",
              "       0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0,\n",
              "       0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
              "       1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1,\n",
              "       1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1,\n",
              "       1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
              "       1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
              "       1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1,\n",
              "       1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TZX_ohg1TBLC",
        "colab_type": "code",
        "outputId": "655a7a1d-5a51-4e82-a68e-bd56acff2708",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 482
        }
      },
      "source": [
        "# from sklearn.utils import shuffle\n",
        "X, Y = sklearn.utils.shuffle(X, Y)\n",
        "Y"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1,\n",
              "       1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1,\n",
              "       0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1,\n",
              "       0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1,\n",
              "       0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1,\n",
              "       0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1,\n",
              "       0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1,\n",
              "       1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0,\n",
              "       0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1,\n",
              "       0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0,\n",
              "       1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0,\n",
              "       1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1,\n",
              "       1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1,\n",
              "       1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0,\n",
              "       1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0,\n",
              "       0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0,\n",
              "       1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1,\n",
              "       1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1,\n",
              "       0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
              "       1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
              "       1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1,\n",
              "       0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1,\n",
              "       1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
              "       1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1,\n",
              "       0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1,\n",
              "       1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FOJASsacjolG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Label(Y):\n",
        "    v = np.zeros(shape=(len(Y), len(set(Y))))\n",
        "    for i in range(len(Y)):\n",
        "        v[i, Y[i]] = 1\n",
        "    \n",
        "    return v\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ayO54lWzlHDh",
        "colab_type": "code",
        "outputId": "970ca3ee-69cf-4a81-ffdc-f9f272fdf283",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        }
      },
      "source": [
        "Y = Label(Y)\n",
        "Y"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       ...,\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TdUls1VhR2l4",
        "colab_type": "code",
        "outputId": "35244a90-a5ee-4811-c8a4-6bf6e2a9ca6a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "D['target_names'] # malignant --> 0 and benign --> 1"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['malignant', 'benign'], dtype='<U9')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cLGXSnbRSQJ5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.33, random_state=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VpJktftRa9Sy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "z = StandardScaler()\n",
        "\n",
        "X_train = z.fit_transform(X_train)\n",
        "X_test = z.transform(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jtoMxc-WSrDG",
        "colab_type": "code",
        "outputId": "cc1b26ee-c00b-4a21-d3da-5fab017a30a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "N, D = X_train.shape\n",
        "print(N, D)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "381 30\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JYA6tUGcS7Mo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Input(shape=(D)),\n",
        "    tf.keras.layers.Dense(units=2, activation='softmax')                             \n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p9pVoxcGUS3Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'],\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q4_888LkU31C",
        "colab_type": "code",
        "outputId": "8f6f4251-e7f9-492a-baa9-ecb2f35b16f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "result = model.fit(X_train, Y_train, validation_data=(X_test, Y_test), epochs=200)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 381 samples, validate on 188 samples\n",
            "Epoch 1/200\n",
            "381/381 [==============================] - 2s 5ms/sample - loss: 0.8325 - accuracy: 0.5564 - val_loss: 0.6622 - val_accuracy: 0.6489\n",
            "Epoch 2/200\n",
            "381/381 [==============================] - 0s 128us/sample - loss: 0.7160 - accuracy: 0.6535 - val_loss: 0.5567 - val_accuracy: 0.7074\n",
            "Epoch 3/200\n",
            "381/381 [==============================] - 0s 135us/sample - loss: 0.6183 - accuracy: 0.7297 - val_loss: 0.4805 - val_accuracy: 0.7819\n",
            "Epoch 4/200\n",
            "381/381 [==============================] - 0s 118us/sample - loss: 0.5439 - accuracy: 0.7717 - val_loss: 0.4230 - val_accuracy: 0.8191\n",
            "Epoch 5/200\n",
            "381/381 [==============================] - 0s 118us/sample - loss: 0.4883 - accuracy: 0.7979 - val_loss: 0.3782 - val_accuracy: 0.8670\n",
            "Epoch 6/200\n",
            "381/381 [==============================] - 0s 124us/sample - loss: 0.4392 - accuracy: 0.8294 - val_loss: 0.3459 - val_accuracy: 0.8777\n",
            "Epoch 7/200\n",
            "381/381 [==============================] - 0s 121us/sample - loss: 0.4031 - accuracy: 0.8451 - val_loss: 0.3198 - val_accuracy: 0.8830\n",
            "Epoch 8/200\n",
            "381/381 [==============================] - 0s 113us/sample - loss: 0.3713 - accuracy: 0.8556 - val_loss: 0.2984 - val_accuracy: 0.8883\n",
            "Epoch 9/200\n",
            "381/381 [==============================] - 0s 126us/sample - loss: 0.3453 - accuracy: 0.8688 - val_loss: 0.2795 - val_accuracy: 0.8936\n",
            "Epoch 10/200\n",
            "381/381 [==============================] - 0s 126us/sample - loss: 0.3207 - accuracy: 0.8740 - val_loss: 0.2651 - val_accuracy: 0.8989\n",
            "Epoch 11/200\n",
            "381/381 [==============================] - 0s 145us/sample - loss: 0.3017 - accuracy: 0.8845 - val_loss: 0.2516 - val_accuracy: 0.9043\n",
            "Epoch 12/200\n",
            "381/381 [==============================] - 0s 139us/sample - loss: 0.2841 - accuracy: 0.8976 - val_loss: 0.2397 - val_accuracy: 0.9096\n",
            "Epoch 13/200\n",
            "381/381 [==============================] - 0s 120us/sample - loss: 0.2692 - accuracy: 0.9081 - val_loss: 0.2300 - val_accuracy: 0.9096\n",
            "Epoch 14/200\n",
            "381/381 [==============================] - 0s 125us/sample - loss: 0.2554 - accuracy: 0.9108 - val_loss: 0.2206 - val_accuracy: 0.9096\n",
            "Epoch 15/200\n",
            "381/381 [==============================] - 0s 112us/sample - loss: 0.2441 - accuracy: 0.9186 - val_loss: 0.2127 - val_accuracy: 0.9255\n",
            "Epoch 16/200\n",
            "381/381 [==============================] - 0s 117us/sample - loss: 0.2330 - accuracy: 0.9186 - val_loss: 0.2054 - val_accuracy: 0.9309\n",
            "Epoch 17/200\n",
            "381/381 [==============================] - 0s 117us/sample - loss: 0.2230 - accuracy: 0.9318 - val_loss: 0.1988 - val_accuracy: 0.9309\n",
            "Epoch 18/200\n",
            "381/381 [==============================] - 0s 119us/sample - loss: 0.2143 - accuracy: 0.9344 - val_loss: 0.1924 - val_accuracy: 0.9362\n",
            "Epoch 19/200\n",
            "381/381 [==============================] - 0s 119us/sample - loss: 0.2062 - accuracy: 0.9344 - val_loss: 0.1865 - val_accuracy: 0.9362\n",
            "Epoch 20/200\n",
            "381/381 [==============================] - 0s 112us/sample - loss: 0.1988 - accuracy: 0.9396 - val_loss: 0.1815 - val_accuracy: 0.9362\n",
            "Epoch 21/200\n",
            "381/381 [==============================] - 0s 117us/sample - loss: 0.1922 - accuracy: 0.9423 - val_loss: 0.1767 - val_accuracy: 0.9415\n",
            "Epoch 22/200\n",
            "381/381 [==============================] - 0s 111us/sample - loss: 0.1859 - accuracy: 0.9475 - val_loss: 0.1722 - val_accuracy: 0.9468\n",
            "Epoch 23/200\n",
            "381/381 [==============================] - 0s 120us/sample - loss: 0.1803 - accuracy: 0.9475 - val_loss: 0.1681 - val_accuracy: 0.9521\n",
            "Epoch 24/200\n",
            "381/381 [==============================] - 0s 131us/sample - loss: 0.1751 - accuracy: 0.9475 - val_loss: 0.1640 - val_accuracy: 0.9521\n",
            "Epoch 25/200\n",
            "381/381 [==============================] - 0s 108us/sample - loss: 0.1701 - accuracy: 0.9475 - val_loss: 0.1603 - val_accuracy: 0.9521\n",
            "Epoch 26/200\n",
            "381/381 [==============================] - 0s 111us/sample - loss: 0.1658 - accuracy: 0.9528 - val_loss: 0.1569 - val_accuracy: 0.9574\n",
            "Epoch 27/200\n",
            "381/381 [==============================] - 0s 113us/sample - loss: 0.1614 - accuracy: 0.9528 - val_loss: 0.1538 - val_accuracy: 0.9628\n",
            "Epoch 28/200\n",
            "381/381 [==============================] - 0s 109us/sample - loss: 0.1577 - accuracy: 0.9554 - val_loss: 0.1506 - val_accuracy: 0.9628\n",
            "Epoch 29/200\n",
            "381/381 [==============================] - 0s 122us/sample - loss: 0.1540 - accuracy: 0.9554 - val_loss: 0.1477 - val_accuracy: 0.9628\n",
            "Epoch 30/200\n",
            "381/381 [==============================] - 0s 119us/sample - loss: 0.1506 - accuracy: 0.9554 - val_loss: 0.1449 - val_accuracy: 0.9574\n",
            "Epoch 31/200\n",
            "381/381 [==============================] - 0s 114us/sample - loss: 0.1474 - accuracy: 0.9580 - val_loss: 0.1423 - val_accuracy: 0.9574\n",
            "Epoch 32/200\n",
            "381/381 [==============================] - 0s 113us/sample - loss: 0.1444 - accuracy: 0.9606 - val_loss: 0.1399 - val_accuracy: 0.9574\n",
            "Epoch 33/200\n",
            "381/381 [==============================] - 0s 122us/sample - loss: 0.1417 - accuracy: 0.9633 - val_loss: 0.1375 - val_accuracy: 0.9574\n",
            "Epoch 34/200\n",
            "381/381 [==============================] - 0s 130us/sample - loss: 0.1390 - accuracy: 0.9633 - val_loss: 0.1354 - val_accuracy: 0.9574\n",
            "Epoch 35/200\n",
            "381/381 [==============================] - 0s 149us/sample - loss: 0.1366 - accuracy: 0.9633 - val_loss: 0.1333 - val_accuracy: 0.9574\n",
            "Epoch 36/200\n",
            "381/381 [==============================] - 0s 121us/sample - loss: 0.1343 - accuracy: 0.9633 - val_loss: 0.1315 - val_accuracy: 0.9574\n",
            "Epoch 37/200\n",
            "381/381 [==============================] - 0s 123us/sample - loss: 0.1321 - accuracy: 0.9633 - val_loss: 0.1295 - val_accuracy: 0.9574\n",
            "Epoch 38/200\n",
            "381/381 [==============================] - 0s 116us/sample - loss: 0.1300 - accuracy: 0.9633 - val_loss: 0.1273 - val_accuracy: 0.9574\n",
            "Epoch 39/200\n",
            "381/381 [==============================] - 0s 121us/sample - loss: 0.1280 - accuracy: 0.9633 - val_loss: 0.1258 - val_accuracy: 0.9574\n",
            "Epoch 40/200\n",
            "381/381 [==============================] - 0s 113us/sample - loss: 0.1259 - accuracy: 0.9633 - val_loss: 0.1242 - val_accuracy: 0.9574\n",
            "Epoch 41/200\n",
            "381/381 [==============================] - 0s 113us/sample - loss: 0.1243 - accuracy: 0.9633 - val_loss: 0.1225 - val_accuracy: 0.9574\n",
            "Epoch 42/200\n",
            "381/381 [==============================] - 0s 119us/sample - loss: 0.1225 - accuracy: 0.9633 - val_loss: 0.1211 - val_accuracy: 0.9574\n",
            "Epoch 43/200\n",
            "381/381 [==============================] - 0s 116us/sample - loss: 0.1208 - accuracy: 0.9633 - val_loss: 0.1197 - val_accuracy: 0.9574\n",
            "Epoch 44/200\n",
            "381/381 [==============================] - 0s 118us/sample - loss: 0.1193 - accuracy: 0.9633 - val_loss: 0.1182 - val_accuracy: 0.9574\n",
            "Epoch 45/200\n",
            "381/381 [==============================] - 0s 131us/sample - loss: 0.1178 - accuracy: 0.9633 - val_loss: 0.1169 - val_accuracy: 0.9574\n",
            "Epoch 46/200\n",
            "381/381 [==============================] - 0s 128us/sample - loss: 0.1164 - accuracy: 0.9659 - val_loss: 0.1156 - val_accuracy: 0.9628\n",
            "Epoch 47/200\n",
            "381/381 [==============================] - 0s 112us/sample - loss: 0.1150 - accuracy: 0.9659 - val_loss: 0.1143 - val_accuracy: 0.9628\n",
            "Epoch 48/200\n",
            "381/381 [==============================] - 0s 110us/sample - loss: 0.1137 - accuracy: 0.9659 - val_loss: 0.1131 - val_accuracy: 0.9628\n",
            "Epoch 49/200\n",
            "381/381 [==============================] - 0s 123us/sample - loss: 0.1124 - accuracy: 0.9659 - val_loss: 0.1122 - val_accuracy: 0.9628\n",
            "Epoch 50/200\n",
            "381/381 [==============================] - 0s 132us/sample - loss: 0.1111 - accuracy: 0.9659 - val_loss: 0.1112 - val_accuracy: 0.9628\n",
            "Epoch 51/200\n",
            "381/381 [==============================] - 0s 124us/sample - loss: 0.1100 - accuracy: 0.9659 - val_loss: 0.1100 - val_accuracy: 0.9628\n",
            "Epoch 52/200\n",
            "381/381 [==============================] - 0s 121us/sample - loss: 0.1089 - accuracy: 0.9685 - val_loss: 0.1091 - val_accuracy: 0.9628\n",
            "Epoch 53/200\n",
            "381/381 [==============================] - 0s 125us/sample - loss: 0.1078 - accuracy: 0.9685 - val_loss: 0.1081 - val_accuracy: 0.9681\n",
            "Epoch 54/200\n",
            "381/381 [==============================] - 0s 136us/sample - loss: 0.1067 - accuracy: 0.9685 - val_loss: 0.1071 - val_accuracy: 0.9681\n",
            "Epoch 55/200\n",
            "381/381 [==============================] - 0s 137us/sample - loss: 0.1057 - accuracy: 0.9685 - val_loss: 0.1061 - val_accuracy: 0.9681\n",
            "Epoch 56/200\n",
            "381/381 [==============================] - 0s 116us/sample - loss: 0.1047 - accuracy: 0.9685 - val_loss: 0.1052 - val_accuracy: 0.9681\n",
            "Epoch 57/200\n",
            "381/381 [==============================] - 0s 124us/sample - loss: 0.1038 - accuracy: 0.9685 - val_loss: 0.1044 - val_accuracy: 0.9681\n",
            "Epoch 58/200\n",
            "381/381 [==============================] - 0s 124us/sample - loss: 0.1029 - accuracy: 0.9685 - val_loss: 0.1037 - val_accuracy: 0.9681\n",
            "Epoch 59/200\n",
            "381/381 [==============================] - 0s 128us/sample - loss: 0.1020 - accuracy: 0.9685 - val_loss: 0.1029 - val_accuracy: 0.9681\n",
            "Epoch 60/200\n",
            "381/381 [==============================] - 0s 117us/sample - loss: 0.1012 - accuracy: 0.9685 - val_loss: 0.1022 - val_accuracy: 0.9681\n",
            "Epoch 61/200\n",
            "381/381 [==============================] - 0s 126us/sample - loss: 0.1003 - accuracy: 0.9685 - val_loss: 0.1013 - val_accuracy: 0.9681\n",
            "Epoch 62/200\n",
            "381/381 [==============================] - 0s 140us/sample - loss: 0.0995 - accuracy: 0.9685 - val_loss: 0.1005 - val_accuracy: 0.9681\n",
            "Epoch 63/200\n",
            "381/381 [==============================] - 0s 131us/sample - loss: 0.0988 - accuracy: 0.9685 - val_loss: 0.0996 - val_accuracy: 0.9734\n",
            "Epoch 64/200\n",
            "381/381 [==============================] - 0s 118us/sample - loss: 0.0980 - accuracy: 0.9711 - val_loss: 0.0991 - val_accuracy: 0.9734\n",
            "Epoch 65/200\n",
            "381/381 [==============================] - 0s 115us/sample - loss: 0.0972 - accuracy: 0.9711 - val_loss: 0.0984 - val_accuracy: 0.9734\n",
            "Epoch 66/200\n",
            "381/381 [==============================] - 0s 138us/sample - loss: 0.0966 - accuracy: 0.9711 - val_loss: 0.0976 - val_accuracy: 0.9734\n",
            "Epoch 67/200\n",
            "381/381 [==============================] - 0s 117us/sample - loss: 0.0958 - accuracy: 0.9738 - val_loss: 0.0971 - val_accuracy: 0.9734\n",
            "Epoch 68/200\n",
            "381/381 [==============================] - 0s 115us/sample - loss: 0.0951 - accuracy: 0.9738 - val_loss: 0.0965 - val_accuracy: 0.9734\n",
            "Epoch 69/200\n",
            "381/381 [==============================] - 0s 107us/sample - loss: 0.0945 - accuracy: 0.9738 - val_loss: 0.0959 - val_accuracy: 0.9734\n",
            "Epoch 70/200\n",
            "381/381 [==============================] - 0s 116us/sample - loss: 0.0938 - accuracy: 0.9738 - val_loss: 0.0953 - val_accuracy: 0.9734\n",
            "Epoch 71/200\n",
            "381/381 [==============================] - 0s 123us/sample - loss: 0.0932 - accuracy: 0.9764 - val_loss: 0.0946 - val_accuracy: 0.9734\n",
            "Epoch 72/200\n",
            "381/381 [==============================] - 0s 116us/sample - loss: 0.0926 - accuracy: 0.9764 - val_loss: 0.0940 - val_accuracy: 0.9734\n",
            "Epoch 73/200\n",
            "381/381 [==============================] - 0s 116us/sample - loss: 0.0920 - accuracy: 0.9790 - val_loss: 0.0935 - val_accuracy: 0.9734\n",
            "Epoch 74/200\n",
            "381/381 [==============================] - 0s 122us/sample - loss: 0.0915 - accuracy: 0.9790 - val_loss: 0.0930 - val_accuracy: 0.9734\n",
            "Epoch 75/200\n",
            "381/381 [==============================] - 0s 122us/sample - loss: 0.0909 - accuracy: 0.9790 - val_loss: 0.0925 - val_accuracy: 0.9734\n",
            "Epoch 76/200\n",
            "381/381 [==============================] - 0s 117us/sample - loss: 0.0903 - accuracy: 0.9790 - val_loss: 0.0921 - val_accuracy: 0.9734\n",
            "Epoch 77/200\n",
            "381/381 [==============================] - 0s 145us/sample - loss: 0.0898 - accuracy: 0.9790 - val_loss: 0.0916 - val_accuracy: 0.9734\n",
            "Epoch 78/200\n",
            "381/381 [==============================] - 0s 132us/sample - loss: 0.0893 - accuracy: 0.9816 - val_loss: 0.0912 - val_accuracy: 0.9734\n",
            "Epoch 79/200\n",
            "381/381 [==============================] - 0s 111us/sample - loss: 0.0888 - accuracy: 0.9843 - val_loss: 0.0905 - val_accuracy: 0.9734\n",
            "Epoch 80/200\n",
            "381/381 [==============================] - 0s 114us/sample - loss: 0.0884 - accuracy: 0.9816 - val_loss: 0.0903 - val_accuracy: 0.9734\n",
            "Epoch 81/200\n",
            "381/381 [==============================] - 0s 129us/sample - loss: 0.0878 - accuracy: 0.9843 - val_loss: 0.0898 - val_accuracy: 0.9734\n",
            "Epoch 82/200\n",
            "381/381 [==============================] - 0s 110us/sample - loss: 0.0873 - accuracy: 0.9843 - val_loss: 0.0893 - val_accuracy: 0.9734\n",
            "Epoch 83/200\n",
            "381/381 [==============================] - 0s 112us/sample - loss: 0.0868 - accuracy: 0.9843 - val_loss: 0.0888 - val_accuracy: 0.9734\n",
            "Epoch 84/200\n",
            "381/381 [==============================] - 0s 118us/sample - loss: 0.0864 - accuracy: 0.9843 - val_loss: 0.0883 - val_accuracy: 0.9734\n",
            "Epoch 85/200\n",
            "381/381 [==============================] - 0s 123us/sample - loss: 0.0859 - accuracy: 0.9843 - val_loss: 0.0880 - val_accuracy: 0.9734\n",
            "Epoch 86/200\n",
            "381/381 [==============================] - 0s 116us/sample - loss: 0.0855 - accuracy: 0.9843 - val_loss: 0.0875 - val_accuracy: 0.9734\n",
            "Epoch 87/200\n",
            "381/381 [==============================] - 0s 116us/sample - loss: 0.0851 - accuracy: 0.9843 - val_loss: 0.0871 - val_accuracy: 0.9734\n",
            "Epoch 88/200\n",
            "381/381 [==============================] - 0s 136us/sample - loss: 0.0846 - accuracy: 0.9843 - val_loss: 0.0868 - val_accuracy: 0.9734\n",
            "Epoch 89/200\n",
            "381/381 [==============================] - 0s 109us/sample - loss: 0.0842 - accuracy: 0.9843 - val_loss: 0.0864 - val_accuracy: 0.9734\n",
            "Epoch 90/200\n",
            "381/381 [==============================] - 0s 108us/sample - loss: 0.0838 - accuracy: 0.9843 - val_loss: 0.0860 - val_accuracy: 0.9734\n",
            "Epoch 91/200\n",
            "381/381 [==============================] - 0s 112us/sample - loss: 0.0835 - accuracy: 0.9843 - val_loss: 0.0858 - val_accuracy: 0.9734\n",
            "Epoch 92/200\n",
            "381/381 [==============================] - 0s 115us/sample - loss: 0.0830 - accuracy: 0.9843 - val_loss: 0.0853 - val_accuracy: 0.9734\n",
            "Epoch 93/200\n",
            "381/381 [==============================] - 0s 120us/sample - loss: 0.0827 - accuracy: 0.9843 - val_loss: 0.0849 - val_accuracy: 0.9734\n",
            "Epoch 94/200\n",
            "381/381 [==============================] - 0s 113us/sample - loss: 0.0823 - accuracy: 0.9843 - val_loss: 0.0845 - val_accuracy: 0.9734\n",
            "Epoch 95/200\n",
            "381/381 [==============================] - 0s 124us/sample - loss: 0.0819 - accuracy: 0.9843 - val_loss: 0.0843 - val_accuracy: 0.9734\n",
            "Epoch 96/200\n",
            "381/381 [==============================] - 0s 118us/sample - loss: 0.0816 - accuracy: 0.9843 - val_loss: 0.0838 - val_accuracy: 0.9734\n",
            "Epoch 97/200\n",
            "381/381 [==============================] - 0s 115us/sample - loss: 0.0812 - accuracy: 0.9869 - val_loss: 0.0837 - val_accuracy: 0.9734\n",
            "Epoch 98/200\n",
            "381/381 [==============================] - 0s 108us/sample - loss: 0.0808 - accuracy: 0.9869 - val_loss: 0.0832 - val_accuracy: 0.9734\n",
            "Epoch 99/200\n",
            "381/381 [==============================] - 0s 118us/sample - loss: 0.0805 - accuracy: 0.9869 - val_loss: 0.0829 - val_accuracy: 0.9734\n",
            "Epoch 100/200\n",
            "381/381 [==============================] - 0s 138us/sample - loss: 0.0802 - accuracy: 0.9869 - val_loss: 0.0827 - val_accuracy: 0.9734\n",
            "Epoch 101/200\n",
            "381/381 [==============================] - 0s 116us/sample - loss: 0.0798 - accuracy: 0.9869 - val_loss: 0.0823 - val_accuracy: 0.9734\n",
            "Epoch 102/200\n",
            "381/381 [==============================] - 0s 115us/sample - loss: 0.0795 - accuracy: 0.9869 - val_loss: 0.0821 - val_accuracy: 0.9734\n",
            "Epoch 103/200\n",
            "381/381 [==============================] - 0s 120us/sample - loss: 0.0792 - accuracy: 0.9869 - val_loss: 0.0817 - val_accuracy: 0.9734\n",
            "Epoch 104/200\n",
            "381/381 [==============================] - 0s 112us/sample - loss: 0.0788 - accuracy: 0.9869 - val_loss: 0.0815 - val_accuracy: 0.9734\n",
            "Epoch 105/200\n",
            "381/381 [==============================] - 0s 112us/sample - loss: 0.0785 - accuracy: 0.9869 - val_loss: 0.0811 - val_accuracy: 0.9734\n",
            "Epoch 106/200\n",
            "381/381 [==============================] - 0s 116us/sample - loss: 0.0782 - accuracy: 0.9869 - val_loss: 0.0809 - val_accuracy: 0.9734\n",
            "Epoch 107/200\n",
            "381/381 [==============================] - 0s 135us/sample - loss: 0.0779 - accuracy: 0.9869 - val_loss: 0.0806 - val_accuracy: 0.9734\n",
            "Epoch 108/200\n",
            "381/381 [==============================] - 0s 129us/sample - loss: 0.0777 - accuracy: 0.9869 - val_loss: 0.0804 - val_accuracy: 0.9734\n",
            "Epoch 109/200\n",
            "381/381 [==============================] - 0s 138us/sample - loss: 0.0774 - accuracy: 0.9869 - val_loss: 0.0801 - val_accuracy: 0.9734\n",
            "Epoch 110/200\n",
            "381/381 [==============================] - 0s 106us/sample - loss: 0.0771 - accuracy: 0.9869 - val_loss: 0.0798 - val_accuracy: 0.9734\n",
            "Epoch 111/200\n",
            "381/381 [==============================] - 0s 112us/sample - loss: 0.0768 - accuracy: 0.9869 - val_loss: 0.0795 - val_accuracy: 0.9734\n",
            "Epoch 112/200\n",
            "381/381 [==============================] - 0s 125us/sample - loss: 0.0765 - accuracy: 0.9869 - val_loss: 0.0794 - val_accuracy: 0.9734\n",
            "Epoch 113/200\n",
            "381/381 [==============================] - 0s 130us/sample - loss: 0.0762 - accuracy: 0.9869 - val_loss: 0.0790 - val_accuracy: 0.9734\n",
            "Epoch 114/200\n",
            "381/381 [==============================] - 0s 123us/sample - loss: 0.0760 - accuracy: 0.9869 - val_loss: 0.0789 - val_accuracy: 0.9681\n",
            "Epoch 115/200\n",
            "381/381 [==============================] - 0s 117us/sample - loss: 0.0758 - accuracy: 0.9869 - val_loss: 0.0785 - val_accuracy: 0.9734\n",
            "Epoch 116/200\n",
            "381/381 [==============================] - 0s 117us/sample - loss: 0.0755 - accuracy: 0.9869 - val_loss: 0.0784 - val_accuracy: 0.9681\n",
            "Epoch 117/200\n",
            "381/381 [==============================] - 0s 119us/sample - loss: 0.0752 - accuracy: 0.9869 - val_loss: 0.0781 - val_accuracy: 0.9681\n",
            "Epoch 118/200\n",
            "381/381 [==============================] - 0s 119us/sample - loss: 0.0749 - accuracy: 0.9869 - val_loss: 0.0779 - val_accuracy: 0.9681\n",
            "Epoch 119/200\n",
            "381/381 [==============================] - 0s 123us/sample - loss: 0.0747 - accuracy: 0.9869 - val_loss: 0.0777 - val_accuracy: 0.9681\n",
            "Epoch 120/200\n",
            "381/381 [==============================] - 0s 127us/sample - loss: 0.0744 - accuracy: 0.9869 - val_loss: 0.0776 - val_accuracy: 0.9681\n",
            "Epoch 121/200\n",
            "381/381 [==============================] - 0s 122us/sample - loss: 0.0742 - accuracy: 0.9869 - val_loss: 0.0774 - val_accuracy: 0.9681\n",
            "Epoch 122/200\n",
            "381/381 [==============================] - 0s 125us/sample - loss: 0.0740 - accuracy: 0.9869 - val_loss: 0.0771 - val_accuracy: 0.9681\n",
            "Epoch 123/200\n",
            "381/381 [==============================] - 0s 138us/sample - loss: 0.0738 - accuracy: 0.9869 - val_loss: 0.0770 - val_accuracy: 0.9681\n",
            "Epoch 124/200\n",
            "381/381 [==============================] - 0s 153us/sample - loss: 0.0735 - accuracy: 0.9869 - val_loss: 0.0767 - val_accuracy: 0.9681\n",
            "Epoch 125/200\n",
            "381/381 [==============================] - 0s 116us/sample - loss: 0.0733 - accuracy: 0.9869 - val_loss: 0.0765 - val_accuracy: 0.9681\n",
            "Epoch 126/200\n",
            "381/381 [==============================] - 0s 114us/sample - loss: 0.0731 - accuracy: 0.9869 - val_loss: 0.0762 - val_accuracy: 0.9681\n",
            "Epoch 127/200\n",
            "381/381 [==============================] - 0s 119us/sample - loss: 0.0729 - accuracy: 0.9869 - val_loss: 0.0761 - val_accuracy: 0.9681\n",
            "Epoch 128/200\n",
            "381/381 [==============================] - 0s 139us/sample - loss: 0.0726 - accuracy: 0.9869 - val_loss: 0.0759 - val_accuracy: 0.9681\n",
            "Epoch 129/200\n",
            "381/381 [==============================] - 0s 123us/sample - loss: 0.0724 - accuracy: 0.9869 - val_loss: 0.0757 - val_accuracy: 0.9681\n",
            "Epoch 130/200\n",
            "381/381 [==============================] - 0s 147us/sample - loss: 0.0722 - accuracy: 0.9869 - val_loss: 0.0755 - val_accuracy: 0.9681\n",
            "Epoch 131/200\n",
            "381/381 [==============================] - 0s 113us/sample - loss: 0.0720 - accuracy: 0.9869 - val_loss: 0.0752 - val_accuracy: 0.9681\n",
            "Epoch 132/200\n",
            "381/381 [==============================] - 0s 135us/sample - loss: 0.0718 - accuracy: 0.9869 - val_loss: 0.0752 - val_accuracy: 0.9681\n",
            "Epoch 133/200\n",
            "381/381 [==============================] - 0s 125us/sample - loss: 0.0716 - accuracy: 0.9869 - val_loss: 0.0749 - val_accuracy: 0.9681\n",
            "Epoch 134/200\n",
            "381/381 [==============================] - 0s 124us/sample - loss: 0.0714 - accuracy: 0.9869 - val_loss: 0.0747 - val_accuracy: 0.9681\n",
            "Epoch 135/200\n",
            "381/381 [==============================] - 0s 118us/sample - loss: 0.0712 - accuracy: 0.9869 - val_loss: 0.0746 - val_accuracy: 0.9681\n",
            "Epoch 136/200\n",
            "381/381 [==============================] - 0s 121us/sample - loss: 0.0710 - accuracy: 0.9869 - val_loss: 0.0745 - val_accuracy: 0.9681\n",
            "Epoch 137/200\n",
            "381/381 [==============================] - 0s 122us/sample - loss: 0.0708 - accuracy: 0.9869 - val_loss: 0.0743 - val_accuracy: 0.9681\n",
            "Epoch 138/200\n",
            "381/381 [==============================] - 0s 127us/sample - loss: 0.0706 - accuracy: 0.9843 - val_loss: 0.0743 - val_accuracy: 0.9734\n",
            "Epoch 139/200\n",
            "381/381 [==============================] - 0s 113us/sample - loss: 0.0704 - accuracy: 0.9869 - val_loss: 0.0739 - val_accuracy: 0.9681\n",
            "Epoch 140/200\n",
            "381/381 [==============================] - 0s 113us/sample - loss: 0.0703 - accuracy: 0.9869 - val_loss: 0.0736 - val_accuracy: 0.9681\n",
            "Epoch 141/200\n",
            "381/381 [==============================] - 0s 115us/sample - loss: 0.0701 - accuracy: 0.9869 - val_loss: 0.0735 - val_accuracy: 0.9681\n",
            "Epoch 142/200\n",
            "381/381 [==============================] - 0s 113us/sample - loss: 0.0699 - accuracy: 0.9869 - val_loss: 0.0734 - val_accuracy: 0.9681\n",
            "Epoch 143/200\n",
            "381/381 [==============================] - 0s 126us/sample - loss: 0.0697 - accuracy: 0.9869 - val_loss: 0.0733 - val_accuracy: 0.9734\n",
            "Epoch 144/200\n",
            "381/381 [==============================] - 0s 119us/sample - loss: 0.0695 - accuracy: 0.9869 - val_loss: 0.0731 - val_accuracy: 0.9734\n",
            "Epoch 145/200\n",
            "381/381 [==============================] - 0s 117us/sample - loss: 0.0693 - accuracy: 0.9843 - val_loss: 0.0730 - val_accuracy: 0.9734\n",
            "Epoch 146/200\n",
            "381/381 [==============================] - 0s 108us/sample - loss: 0.0692 - accuracy: 0.9843 - val_loss: 0.0729 - val_accuracy: 0.9734\n",
            "Epoch 147/200\n",
            "381/381 [==============================] - 0s 117us/sample - loss: 0.0690 - accuracy: 0.9843 - val_loss: 0.0727 - val_accuracy: 0.9734\n",
            "Epoch 148/200\n",
            "381/381 [==============================] - 0s 115us/sample - loss: 0.0689 - accuracy: 0.9843 - val_loss: 0.0726 - val_accuracy: 0.9734\n",
            "Epoch 149/200\n",
            "381/381 [==============================] - 0s 124us/sample - loss: 0.0687 - accuracy: 0.9843 - val_loss: 0.0725 - val_accuracy: 0.9734\n",
            "Epoch 150/200\n",
            "381/381 [==============================] - 0s 121us/sample - loss: 0.0686 - accuracy: 0.9843 - val_loss: 0.0721 - val_accuracy: 0.9734\n",
            "Epoch 151/200\n",
            "381/381 [==============================] - 0s 148us/sample - loss: 0.0684 - accuracy: 0.9843 - val_loss: 0.0720 - val_accuracy: 0.9734\n",
            "Epoch 152/200\n",
            "381/381 [==============================] - 0s 133us/sample - loss: 0.0682 - accuracy: 0.9843 - val_loss: 0.0720 - val_accuracy: 0.9734\n",
            "Epoch 153/200\n",
            "381/381 [==============================] - 0s 119us/sample - loss: 0.0680 - accuracy: 0.9843 - val_loss: 0.0718 - val_accuracy: 0.9734\n",
            "Epoch 154/200\n",
            "381/381 [==============================] - 0s 117us/sample - loss: 0.0679 - accuracy: 0.9843 - val_loss: 0.0716 - val_accuracy: 0.9734\n",
            "Epoch 155/200\n",
            "381/381 [==============================] - 0s 114us/sample - loss: 0.0677 - accuracy: 0.9843 - val_loss: 0.0716 - val_accuracy: 0.9734\n",
            "Epoch 156/200\n",
            "381/381 [==============================] - 0s 115us/sample - loss: 0.0676 - accuracy: 0.9843 - val_loss: 0.0713 - val_accuracy: 0.9734\n",
            "Epoch 157/200\n",
            "381/381 [==============================] - 0s 120us/sample - loss: 0.0676 - accuracy: 0.9843 - val_loss: 0.0714 - val_accuracy: 0.9734\n",
            "Epoch 158/200\n",
            "381/381 [==============================] - 0s 121us/sample - loss: 0.0673 - accuracy: 0.9843 - val_loss: 0.0712 - val_accuracy: 0.9734\n",
            "Epoch 159/200\n",
            "381/381 [==============================] - 0s 120us/sample - loss: 0.0671 - accuracy: 0.9843 - val_loss: 0.0710 - val_accuracy: 0.9734\n",
            "Epoch 160/200\n",
            "381/381 [==============================] - 0s 125us/sample - loss: 0.0670 - accuracy: 0.9843 - val_loss: 0.0709 - val_accuracy: 0.9734\n",
            "Epoch 161/200\n",
            "381/381 [==============================] - 0s 112us/sample - loss: 0.0669 - accuracy: 0.9843 - val_loss: 0.0708 - val_accuracy: 0.9734\n",
            "Epoch 162/200\n",
            "381/381 [==============================] - 0s 112us/sample - loss: 0.0667 - accuracy: 0.9843 - val_loss: 0.0706 - val_accuracy: 0.9734\n",
            "Epoch 163/200\n",
            "381/381 [==============================] - 0s 112us/sample - loss: 0.0666 - accuracy: 0.9843 - val_loss: 0.0706 - val_accuracy: 0.9734\n",
            "Epoch 164/200\n",
            "381/381 [==============================] - 0s 114us/sample - loss: 0.0665 - accuracy: 0.9843 - val_loss: 0.0703 - val_accuracy: 0.9734\n",
            "Epoch 165/200\n",
            "381/381 [==============================] - 0s 120us/sample - loss: 0.0664 - accuracy: 0.9843 - val_loss: 0.0703 - val_accuracy: 0.9734\n",
            "Epoch 166/200\n",
            "381/381 [==============================] - 0s 154us/sample - loss: 0.0662 - accuracy: 0.9843 - val_loss: 0.0702 - val_accuracy: 0.9734\n",
            "Epoch 167/200\n",
            "381/381 [==============================] - 0s 117us/sample - loss: 0.0661 - accuracy: 0.9843 - val_loss: 0.0700 - val_accuracy: 0.9734\n",
            "Epoch 168/200\n",
            "381/381 [==============================] - 0s 123us/sample - loss: 0.0659 - accuracy: 0.9843 - val_loss: 0.0699 - val_accuracy: 0.9734\n",
            "Epoch 169/200\n",
            "381/381 [==============================] - 0s 119us/sample - loss: 0.0658 - accuracy: 0.9843 - val_loss: 0.0698 - val_accuracy: 0.9734\n",
            "Epoch 170/200\n",
            "381/381 [==============================] - 0s 111us/sample - loss: 0.0656 - accuracy: 0.9843 - val_loss: 0.0697 - val_accuracy: 0.9734\n",
            "Epoch 171/200\n",
            "381/381 [==============================] - 0s 116us/sample - loss: 0.0656 - accuracy: 0.9843 - val_loss: 0.0696 - val_accuracy: 0.9734\n",
            "Epoch 172/200\n",
            "381/381 [==============================] - 0s 121us/sample - loss: 0.0654 - accuracy: 0.9843 - val_loss: 0.0695 - val_accuracy: 0.9734\n",
            "Epoch 173/200\n",
            "381/381 [==============================] - 0s 156us/sample - loss: 0.0653 - accuracy: 0.9843 - val_loss: 0.0695 - val_accuracy: 0.9734\n",
            "Epoch 174/200\n",
            "381/381 [==============================] - 0s 132us/sample - loss: 0.0651 - accuracy: 0.9843 - val_loss: 0.0693 - val_accuracy: 0.9734\n",
            "Epoch 175/200\n",
            "381/381 [==============================] - 0s 129us/sample - loss: 0.0651 - accuracy: 0.9843 - val_loss: 0.0693 - val_accuracy: 0.9787\n",
            "Epoch 176/200\n",
            "381/381 [==============================] - 0s 122us/sample - loss: 0.0649 - accuracy: 0.9843 - val_loss: 0.0690 - val_accuracy: 0.9787\n",
            "Epoch 177/200\n",
            "381/381 [==============================] - 0s 112us/sample - loss: 0.0648 - accuracy: 0.9843 - val_loss: 0.0688 - val_accuracy: 0.9734\n",
            "Epoch 178/200\n",
            "381/381 [==============================] - 0s 117us/sample - loss: 0.0647 - accuracy: 0.9843 - val_loss: 0.0688 - val_accuracy: 0.9787\n",
            "Epoch 179/200\n",
            "381/381 [==============================] - 0s 121us/sample - loss: 0.0646 - accuracy: 0.9843 - val_loss: 0.0689 - val_accuracy: 0.9787\n",
            "Epoch 180/200\n",
            "381/381 [==============================] - 0s 123us/sample - loss: 0.0644 - accuracy: 0.9843 - val_loss: 0.0687 - val_accuracy: 0.9787\n",
            "Epoch 181/200\n",
            "381/381 [==============================] - 0s 115us/sample - loss: 0.0643 - accuracy: 0.9843 - val_loss: 0.0686 - val_accuracy: 0.9787\n",
            "Epoch 182/200\n",
            "381/381 [==============================] - 0s 116us/sample - loss: 0.0643 - accuracy: 0.9843 - val_loss: 0.0682 - val_accuracy: 0.9787\n",
            "Epoch 183/200\n",
            "381/381 [==============================] - 0s 113us/sample - loss: 0.0641 - accuracy: 0.9843 - val_loss: 0.0684 - val_accuracy: 0.9787\n",
            "Epoch 184/200\n",
            "381/381 [==============================] - 0s 124us/sample - loss: 0.0640 - accuracy: 0.9843 - val_loss: 0.0682 - val_accuracy: 0.9787\n",
            "Epoch 185/200\n",
            "381/381 [==============================] - 0s 147us/sample - loss: 0.0639 - accuracy: 0.9843 - val_loss: 0.0680 - val_accuracy: 0.9787\n",
            "Epoch 186/200\n",
            "381/381 [==============================] - 0s 135us/sample - loss: 0.0639 - accuracy: 0.9843 - val_loss: 0.0682 - val_accuracy: 0.9787\n",
            "Epoch 187/200\n",
            "381/381 [==============================] - 0s 114us/sample - loss: 0.0638 - accuracy: 0.9843 - val_loss: 0.0678 - val_accuracy: 0.9787\n",
            "Epoch 188/200\n",
            "381/381 [==============================] - 0s 113us/sample - loss: 0.0637 - accuracy: 0.9843 - val_loss: 0.0677 - val_accuracy: 0.9787\n",
            "Epoch 189/200\n",
            "381/381 [==============================] - 0s 155us/sample - loss: 0.0635 - accuracy: 0.9843 - val_loss: 0.0677 - val_accuracy: 0.9787\n",
            "Epoch 190/200\n",
            "381/381 [==============================] - 0s 124us/sample - loss: 0.0634 - accuracy: 0.9843 - val_loss: 0.0676 - val_accuracy: 0.9787\n",
            "Epoch 191/200\n",
            "381/381 [==============================] - 0s 116us/sample - loss: 0.0633 - accuracy: 0.9843 - val_loss: 0.0675 - val_accuracy: 0.9787\n",
            "Epoch 192/200\n",
            "381/381 [==============================] - 0s 112us/sample - loss: 0.0631 - accuracy: 0.9843 - val_loss: 0.0673 - val_accuracy: 0.9787\n",
            "Epoch 193/200\n",
            "381/381 [==============================] - 0s 115us/sample - loss: 0.0631 - accuracy: 0.9843 - val_loss: 0.0674 - val_accuracy: 0.9787\n",
            "Epoch 194/200\n",
            "381/381 [==============================] - 0s 137us/sample - loss: 0.0629 - accuracy: 0.9843 - val_loss: 0.0673 - val_accuracy: 0.9787\n",
            "Epoch 195/200\n",
            "381/381 [==============================] - 0s 123us/sample - loss: 0.0629 - accuracy: 0.9843 - val_loss: 0.0673 - val_accuracy: 0.9787\n",
            "Epoch 196/200\n",
            "381/381 [==============================] - 0s 135us/sample - loss: 0.0628 - accuracy: 0.9843 - val_loss: 0.0670 - val_accuracy: 0.9787\n",
            "Epoch 197/200\n",
            "381/381 [==============================] - 0s 126us/sample - loss: 0.0627 - accuracy: 0.9843 - val_loss: 0.0671 - val_accuracy: 0.9787\n",
            "Epoch 198/200\n",
            "381/381 [==============================] - 0s 112us/sample - loss: 0.0626 - accuracy: 0.9843 - val_loss: 0.0671 - val_accuracy: 0.9787\n",
            "Epoch 199/200\n",
            "381/381 [==============================] - 0s 133us/sample - loss: 0.0625 - accuracy: 0.9843 - val_loss: 0.0670 - val_accuracy: 0.9787\n",
            "Epoch 200/200\n",
            "381/381 [==============================] - 0s 120us/sample - loss: 0.0624 - accuracy: 0.9843 - val_loss: 0.0668 - val_accuracy: 0.9787\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0uHbUJa36vhT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Yp = model.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nl7GVx7ZVxa-",
        "colab_type": "code",
        "outputId": "e46cdd62-4c44-4d98-c3c8-961cb76ec06c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "print('Training Accuracy: {}'.format(model.evaluate(X_train, Y_train)))\n",
        "print('Testing Accuracy: {}'.format(model.evaluate(X_test, Y_test)))\n",
        "\n",
        "# # Evaluate the model - evaluate() returns loss and accuracy\n",
        "# print(\"Train score:\", model.evaluate(X_train, Y_train))\n",
        "# print(\"Test score:\", model.evaluate(X_test, Y_test))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "381/381 [==============================] - 0s 73us/sample - loss: 0.0623 - accuracy: 0.9843\n",
            "Training Accuracy: [0.062254386565347354, 0.984252]\n",
            "188/188 [==============================] - 0s 85us/sample - loss: 0.0668 - accuracy: 0.9787\n",
            "Testing Accuracy: [0.06679794588621626, 0.9787234]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7D0VaZNrXev0",
        "colab_type": "code",
        "outputId": "42c7762f-5815-47a9-e759-a55fa3573934",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(result.history['loss'], label='loss')\n",
        "plt.plot(result.history['val_loss'], label='val_loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEGCAYAAABo25JHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RyhFsUefcjxh",
        "colab_type": "code",
        "outputId": "7dfa0385-8542-437b-8242-85c58041e96b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(result.history['accuracy'], label='accuracy')\n",
        "plt.plot(result.history['val_accuracy'], label='val_accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEGCAYAAABo25JHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MoxHh_Exctpx",
        "colab_type": "code",
        "outputId": "4f8f7659-fae0-47c3-8fd0-6a8fb6c19667",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 2)                 62        \n",
            "=================================================================\n",
            "Total params: 62\n",
            "Trainable params: 62\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p9tb6nKuoSKu",
        "colab_type": "code",
        "outputId": "c9072146-fa14-4261-89e8-1043a5f14658",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "Yp"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[5.82247121e-05, 9.99941826e-01],\n",
              "       [8.23037117e-05, 9.99917746e-01],\n",
              "       [8.89319718e-01, 1.10680267e-01],\n",
              "       [3.61241182e-05, 9.99963880e-01],\n",
              "       [9.99999285e-01, 6.74969840e-07],\n",
              "       [9.99989033e-01, 1.09649964e-05],\n",
              "       [1.00000000e+00, 1.83691782e-08],\n",
              "       [9.94582474e-01, 5.41755464e-03],\n",
              "       [5.38371736e-03, 9.94616330e-01],\n",
              "       [9.96864080e-01, 3.13599384e-03],\n",
              "       [1.26763619e-02, 9.87323701e-01],\n",
              "       [9.99996662e-01, 3.35988807e-06],\n",
              "       [1.95312896e-04, 9.99804676e-01],\n",
              "       [1.92528329e-04, 9.99807537e-01],\n",
              "       [3.19279805e-02, 9.68071997e-01],\n",
              "       [9.99850631e-01, 1.49314234e-04],\n",
              "       [1.00000000e+00, 1.31269351e-08],\n",
              "       [9.99999881e-01, 7.44489057e-08],\n",
              "       [1.13607617e-04, 9.99886394e-01],\n",
              "       [9.06927407e-01, 9.30725709e-02],\n",
              "       [9.97294366e-01, 2.70567043e-03],\n",
              "       [9.99999523e-01, 4.82354380e-07],\n",
              "       [5.05392563e-06, 9.99994993e-01],\n",
              "       [6.20933366e-04, 9.99379039e-01],\n",
              "       [9.86099899e-01, 1.39000379e-02],\n",
              "       [2.95281084e-03, 9.97047246e-01],\n",
              "       [1.64996914e-03, 9.98350024e-01],\n",
              "       [2.37996061e-03, 9.97620046e-01],\n",
              "       [8.54128748e-02, 9.14587140e-01],\n",
              "       [9.99842405e-01, 1.57529968e-04],\n",
              "       [1.00000000e+00, 1.59247548e-08],\n",
              "       [9.99998331e-01, 1.70517808e-06],\n",
              "       [2.45750034e-05, 9.99975443e-01],\n",
              "       [1.00000000e+00, 3.81879559e-08],\n",
              "       [9.99960184e-01, 3.98185475e-05],\n",
              "       [9.99959826e-01, 4.02013175e-05],\n",
              "       [9.99997020e-01, 2.99987187e-06],\n",
              "       [7.55573046e-06, 9.99992490e-01],\n",
              "       [7.44076865e-03, 9.92559195e-01],\n",
              "       [9.70325887e-01, 2.96741072e-02],\n",
              "       [2.02885717e-01, 7.97114313e-01],\n",
              "       [4.11608592e-02, 9.58839178e-01],\n",
              "       [9.99999285e-01, 7.46613466e-07],\n",
              "       [3.81289534e-02, 9.61871028e-01],\n",
              "       [1.14937993e-02, 9.88506198e-01],\n",
              "       [1.59352217e-02, 9.84064758e-01],\n",
              "       [9.94053304e-01, 5.94673259e-03],\n",
              "       [1.31476996e-02, 9.86852348e-01],\n",
              "       [3.23258602e-04, 9.99676704e-01],\n",
              "       [9.99996305e-01, 3.65890514e-06],\n",
              "       [4.24539139e-05, 9.99957561e-01],\n",
              "       [1.00000000e+00, 1.94292626e-09],\n",
              "       [9.99996543e-01, 3.50584946e-06],\n",
              "       [3.11165482e-01, 6.88834548e-01],\n",
              "       [9.99479711e-01, 5.20343659e-04],\n",
              "       [2.98108444e-05, 9.99970198e-01],\n",
              "       [1.35686423e-04, 9.99864340e-01],\n",
              "       [9.96359885e-01, 3.64007778e-03],\n",
              "       [9.83164787e-01, 1.68351717e-02],\n",
              "       [2.34845523e-02, 9.76515532e-01],\n",
              "       [8.36205855e-02, 9.16379452e-01],\n",
              "       [9.99994874e-01, 5.13961186e-06],\n",
              "       [5.01256716e-03, 9.94987488e-01],\n",
              "       [6.48809850e-01, 3.51190090e-01],\n",
              "       [1.00000000e+00, 3.74249971e-11],\n",
              "       [9.84628320e-01, 1.53716980e-02],\n",
              "       [6.49509132e-01, 3.50490808e-01],\n",
              "       [9.68730569e-01, 3.12694386e-02],\n",
              "       [9.96254444e-01, 3.74559336e-03],\n",
              "       [1.00000000e+00, 1.55640865e-11],\n",
              "       [2.81818863e-03, 9.97181892e-01],\n",
              "       [1.11924695e-04, 9.99888062e-01],\n",
              "       [1.38728358e-02, 9.86127138e-01],\n",
              "       [1.84342684e-03, 9.98156607e-01],\n",
              "       [8.35066363e-02, 9.16493356e-01],\n",
              "       [1.32973287e-02, 9.86702681e-01],\n",
              "       [1.11761820e-02, 9.88823831e-01],\n",
              "       [4.73608176e-04, 9.99526381e-01],\n",
              "       [1.57135744e-02, 9.84286487e-01],\n",
              "       [6.04210468e-03, 9.93957877e-01],\n",
              "       [9.98382092e-01, 1.61789719e-03],\n",
              "       [1.66733369e-01, 8.33266675e-01],\n",
              "       [3.16471666e-01, 6.83528364e-01],\n",
              "       [1.31103825e-02, 9.86889601e-01],\n",
              "       [9.97895956e-01, 2.10407376e-03],\n",
              "       [3.43302934e-04, 9.99656677e-01],\n",
              "       [1.90160223e-04, 9.99809921e-01],\n",
              "       [4.04067192e-04, 9.99595940e-01],\n",
              "       [9.57725395e-04, 9.99042213e-01],\n",
              "       [5.49941324e-04, 9.99450028e-01],\n",
              "       [8.67359899e-03, 9.91326392e-01],\n",
              "       [9.99974728e-01, 2.52219543e-05],\n",
              "       [9.99975920e-01, 2.41174876e-05],\n",
              "       [2.50276495e-02, 9.74972308e-01],\n",
              "       [1.36308165e-06, 9.99998689e-01],\n",
              "       [9.99230027e-01, 7.70020182e-04],\n",
              "       [7.18072355e-02, 9.28192735e-01],\n",
              "       [3.00711789e-03, 9.96992826e-01],\n",
              "       [1.75595076e-07, 9.99999881e-01],\n",
              "       [2.25493358e-03, 9.97745037e-01],\n",
              "       [1.78581884e-03, 9.98214245e-01],\n",
              "       [9.99991417e-01, 8.56107727e-06],\n",
              "       [5.83577342e-03, 9.94164288e-01],\n",
              "       [6.70816880e-05, 9.99932885e-01],\n",
              "       [5.26134789e-01, 4.73865241e-01],\n",
              "       [2.00213209e-01, 7.99786806e-01],\n",
              "       [6.46165669e-01, 3.53834331e-01],\n",
              "       [9.99991775e-01, 8.17369983e-06],\n",
              "       [4.65489142e-02, 9.53451157e-01],\n",
              "       [2.19969638e-03, 9.97800291e-01],\n",
              "       [9.99939680e-01, 6.03101944e-05],\n",
              "       [5.12148945e-05, 9.99948740e-01],\n",
              "       [1.32167235e-03, 9.98678267e-01],\n",
              "       [1.99820031e-03, 9.98001754e-01],\n",
              "       [9.99769747e-01, 2.30305712e-04],\n",
              "       [4.58609648e-02, 9.54138994e-01],\n",
              "       [1.00140329e-02, 9.89985883e-01],\n",
              "       [4.03859513e-03, 9.95961368e-01],\n",
              "       [9.99975085e-01, 2.48928627e-05],\n",
              "       [2.36635897e-02, 9.76336360e-01],\n",
              "       [9.99999881e-01, 9.79876802e-08],\n",
              "       [1.28190713e-02, 9.87180889e-01],\n",
              "       [4.65548821e-02, 9.53445077e-01],\n",
              "       [8.69740761e-05, 9.99912977e-01],\n",
              "       [9.95149910e-01, 4.85011376e-03],\n",
              "       [8.55608463e-01, 1.44391552e-01],\n",
              "       [2.31023063e-03, 9.97689843e-01],\n",
              "       [1.00000000e+00, 1.49315011e-12],\n",
              "       [8.53564888e-02, 9.14643466e-01],\n",
              "       [2.77359155e-03, 9.97226417e-01],\n",
              "       [9.68026876e-01, 3.19731385e-02],\n",
              "       [5.98533332e-01, 4.01466668e-01],\n",
              "       [9.91597235e-01, 8.40278901e-03],\n",
              "       [9.99617934e-01, 3.81991907e-04],\n",
              "       [2.43506511e-03, 9.97564912e-01],\n",
              "       [9.99999881e-01, 7.10304207e-08],\n",
              "       [1.35676783e-05, 9.99986410e-01],\n",
              "       [9.99126732e-01, 8.73310666e-04],\n",
              "       [6.43181801e-02, 9.35681760e-01],\n",
              "       [4.16324947e-05, 9.99958396e-01],\n",
              "       [1.16776843e-02, 9.88322318e-01],\n",
              "       [9.75053199e-03, 9.90249455e-01],\n",
              "       [3.16465856e-04, 9.99683499e-01],\n",
              "       [1.00000000e+00, 1.72066841e-08],\n",
              "       [5.93507684e-05, 9.99940634e-01],\n",
              "       [1.16356117e-04, 9.99883652e-01],\n",
              "       [3.80185642e-03, 9.96198118e-01],\n",
              "       [7.79861748e-01, 2.20138192e-01],\n",
              "       [1.76645666e-02, 9.82335389e-01],\n",
              "       [9.69308615e-01, 3.06913778e-02],\n",
              "       [1.52566165e-01, 8.47433805e-01],\n",
              "       [9.94882703e-01, 5.11736469e-03],\n",
              "       [9.99909401e-01, 9.06155619e-05],\n",
              "       [8.09679627e-01, 1.90320343e-01],\n",
              "       [9.98815298e-01, 1.18472334e-03],\n",
              "       [1.80849656e-06, 9.99998212e-01],\n",
              "       [1.60609037e-04, 9.99839306e-01],\n",
              "       [1.00000000e+00, 3.47199935e-10],\n",
              "       [5.60944864e-05, 9.99943852e-01],\n",
              "       [9.89105523e-01, 1.08944317e-02],\n",
              "       [9.99834657e-01, 1.65357502e-04],\n",
              "       [9.85526573e-03, 9.90144730e-01],\n",
              "       [8.05674568e-02, 9.19432521e-01],\n",
              "       [1.12994712e-04, 9.99886990e-01],\n",
              "       [2.06854269e-02, 9.79314566e-01],\n",
              "       [9.99954939e-01, 4.50574844e-05],\n",
              "       [9.52131377e-05, 9.99904752e-01],\n",
              "       [4.50623661e-01, 5.49376309e-01],\n",
              "       [1.83858443e-02, 9.81614232e-01],\n",
              "       [7.09107369e-02, 9.29089308e-01],\n",
              "       [9.99771297e-01, 2.28753008e-04],\n",
              "       [7.68678010e-01, 2.31322005e-01],\n",
              "       [6.14715856e-04, 9.99385238e-01],\n",
              "       [9.99969125e-01, 3.09101961e-05],\n",
              "       [9.93320882e-01, 6.67910418e-03],\n",
              "       [3.33148688e-01, 6.66851282e-01],\n",
              "       [7.47167617e-02, 9.25283253e-01],\n",
              "       [9.84572172e-01, 1.54277962e-02],\n",
              "       [1.53468847e-01, 8.46531153e-01],\n",
              "       [8.66923988e-01, 1.33076042e-01],\n",
              "       [3.10726520e-02, 9.68927383e-01],\n",
              "       [8.73597741e-01, 1.26402214e-01],\n",
              "       [4.11307701e-05, 9.99958873e-01],\n",
              "       [3.94772366e-03, 9.96052265e-01],\n",
              "       [6.84766273e-04, 9.99315262e-01],\n",
              "       [9.77552891e-01, 2.24471856e-02],\n",
              "       [9.99993086e-01, 6.94049913e-06],\n",
              "       [8.79565906e-03, 9.91204321e-01]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XhBP5d3To-m8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "19d23faf-2c37-4fe2-accf-35c66a295902"
      },
      "source": [
        "# v = np.argmax(Yp, axis=1, keepdims=True)\n",
        "# v\n",
        "v = np.round(Yp)\n",
        "\n",
        "C = 0\n",
        "for real, pred in zip(Y_test, v):\n",
        "    if real[0] == pred[0] and real[1] == pred[1]:\n",
        "        C += 1\n",
        "\n",
        "print(C/len(v)) "
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9787234042553191\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9_Z12mdn74cm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b9b54ab1-f639-4126-f8e6-bd4aec7bd4b1"
      },
      "source": [
        ""
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6fHdVzXQ8Dvw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "f9bd8fe8-f1f1-42df-cedc-3fb9cb77ebd4"
      },
      "source": [
        "u = np.array([0, 1], dtype=np.float)\n",
        "v = np.array([0, 1], dtype=np.float)\n",
        "print(u, v)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0. 1.] [0. 1.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dE0F8-539SNF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a175d054-7daa-4772-9ed3-8bc872c79132"
      },
      "source": [
        "u == v"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ True,  True])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IijlByZO9fu_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}