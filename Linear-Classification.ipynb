{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Linear-Classification.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mrzResearchArena/TF-2.X/blob/master/Linear-Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "51CB8bMaQG3t",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "6515b50d-862d-44fc-dc0c-6b52229644e2"
      },
      "source": [
        "try:\n",
        "    %tensorflow_version 2.x  # Colab only.\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "import tensorflow as tf\n",
        "import sklearn\n",
        "import numpy as np\n",
        "print(tf.__version__)"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "`%tensorflow_version` only switches the major version: `1.x` or `2.x`.\n",
            "You set: `2.x  # Colab only.`. This will be interpreted as: `2.x`.\n",
            "\n",
            "\n",
            "TensorFlow is already loaded. Please restart the runtime to change versions.\n",
            "2.1.0-rc1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iYfAz4yvQcMV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.datasets import load_breast_cancer \n",
        "D = load_breast_cancer()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IhKGwF7cRaEH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "b569fad6-abc7-4159-f0a4-53b6b2a0794c"
      },
      "source": [
        "D.keys()"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['data', 'target', 'target_names', 'DESCR', 'feature_names', 'filename'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cc9gTDtsRiUW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 249
        },
        "outputId": "f89f1062-f11b-4cd1-e894-d4d52b5ab6b0"
      },
      "source": [
        "X = D['data']\n",
        "# X.shape # --> (569, 30)\n",
        "X"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2.654e-01, 4.601e-01,\n",
              "        1.189e-01],\n",
              "       [2.057e+01, 1.777e+01, 1.329e+02, ..., 1.860e-01, 2.750e-01,\n",
              "        8.902e-02],\n",
              "       [1.969e+01, 2.125e+01, 1.300e+02, ..., 2.430e-01, 3.613e-01,\n",
              "        8.758e-02],\n",
              "       ...,\n",
              "       [1.660e+01, 2.808e+01, 1.083e+02, ..., 1.418e-01, 2.218e-01,\n",
              "        7.820e-02],\n",
              "       [2.060e+01, 2.933e+01, 1.401e+02, ..., 2.650e-01, 4.087e-01,\n",
              "        1.240e-01],\n",
              "       [7.760e+00, 2.454e+01, 4.792e+01, ..., 0.000e+00, 2.871e-01,\n",
              "        7.039e-02]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Xq9_NzRRofW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 482
        },
        "outputId": "cfd50d3f-a9e2-40da-dba4-12defbc0bc52"
      },
      "source": [
        "Y = D['target']\n",
        "# Y.shape # --> (569,)\n",
        "Y"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0,\n",
              "       1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "       1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
              "       0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1,\n",
              "       1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0,\n",
              "       0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0,\n",
              "       1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n",
              "       1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0,\n",
              "       0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0,\n",
              "       0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
              "       1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1,\n",
              "       1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1,\n",
              "       1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
              "       1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
              "       1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1,\n",
              "       1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TZX_ohg1TBLC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 482
        },
        "outputId": "61f58cb0-2778-4e27-cfbc-f243d5870390"
      },
      "source": [
        "# from sklearn.utils import shuffle\n",
        "X, Y = sklearn.utils.shuffle(X, Y)\n",
        "Y"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1,\n",
              "       1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0,\n",
              "       1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0,\n",
              "       0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0,\n",
              "       1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1,\n",
              "       0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0,\n",
              "       1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0,\n",
              "       1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1,\n",
              "       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1,\n",
              "       0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0,\n",
              "       0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1,\n",
              "       1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1,\n",
              "       0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0,\n",
              "       0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1,\n",
              "       1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1,\n",
              "       1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1,\n",
              "       1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1,\n",
              "       1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0,\n",
              "       0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
              "       1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
              "       0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1,\n",
              "       0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1,\n",
              "       1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FOJASsacjolG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Label(Y):\n",
        "    v = np.zeros(shape=(len(Y), len(set(Y))))\n",
        "    for i in range(len(Y)):\n",
        "        v[i, Y[i]] = 1\n",
        "    \n",
        "    return v\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ayO54lWzlHDh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "outputId": "ca3a19a1-22c3-4e1e-c953-1724c6374df2"
      },
      "source": [
        "Y = Label(Y)\n",
        "Y"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       ...,\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TdUls1VhR2l4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "5a4e2b3b-cad4-466f-b970-b6e89225cd99"
      },
      "source": [
        "D['target_names'] # malignant --> 0 and benign --> 1"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['malignant', 'benign'], dtype='<U9')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cLGXSnbRSQJ5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.33, random_state=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VpJktftRa9Sy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "z = StandardScaler()\n",
        "\n",
        "X_train = z.fit_transform(X_train)\n",
        "X_test = z.transform(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jtoMxc-WSrDG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "e929b08c-1105-43cf-da9c-affb05773ad8"
      },
      "source": [
        "N, D = X_train.shape\n",
        "print(N, D)"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "381 30\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JYA6tUGcS7Mo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Input(shape=(D)),\n",
        "    tf.keras.layers.Dense(units=2, activation='softmax')                             \n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p9pVoxcGUS3Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'],\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q4_888LkU31C",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3bb46b8c-5d12-4c23-ab59-06ca9e9a7a39"
      },
      "source": [
        "result = model.fit(X_train, Y_train, validation_data=(X_test, Y_test), epochs=500)"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 381 samples, validate on 188 samples\n",
            "Epoch 1/500\n",
            "381/381 [==============================] - 0s 1ms/sample - loss: 0.5065 - accuracy: 0.7507 - val_loss: 0.5002 - val_accuracy: 0.7713\n",
            "Epoch 2/500\n",
            "381/381 [==============================] - 0s 129us/sample - loss: 0.4370 - accuracy: 0.8110 - val_loss: 0.4336 - val_accuracy: 0.8404\n",
            "Epoch 3/500\n",
            "381/381 [==============================] - 0s 120us/sample - loss: 0.3863 - accuracy: 0.8451 - val_loss: 0.3811 - val_accuracy: 0.8511\n",
            "Epoch 4/500\n",
            "381/381 [==============================] - 0s 116us/sample - loss: 0.3436 - accuracy: 0.8635 - val_loss: 0.3423 - val_accuracy: 0.8670\n",
            "Epoch 5/500\n",
            "381/381 [==============================] - 0s 125us/sample - loss: 0.3100 - accuracy: 0.8845 - val_loss: 0.3123 - val_accuracy: 0.8723\n",
            "Epoch 6/500\n",
            "381/381 [==============================] - 0s 118us/sample - loss: 0.2846 - accuracy: 0.8924 - val_loss: 0.2866 - val_accuracy: 0.8830\n",
            "Epoch 7/500\n",
            "381/381 [==============================] - 0s 141us/sample - loss: 0.2628 - accuracy: 0.9029 - val_loss: 0.2657 - val_accuracy: 0.8830\n",
            "Epoch 8/500\n",
            "381/381 [==============================] - 0s 117us/sample - loss: 0.2455 - accuracy: 0.9134 - val_loss: 0.2473 - val_accuracy: 0.8936\n",
            "Epoch 9/500\n",
            "381/381 [==============================] - 0s 127us/sample - loss: 0.2296 - accuracy: 0.9265 - val_loss: 0.2321 - val_accuracy: 0.9043\n",
            "Epoch 10/500\n",
            "381/381 [==============================] - 0s 135us/sample - loss: 0.2168 - accuracy: 0.9344 - val_loss: 0.2191 - val_accuracy: 0.9096\n",
            "Epoch 11/500\n",
            "381/381 [==============================] - 0s 123us/sample - loss: 0.2061 - accuracy: 0.9423 - val_loss: 0.2063 - val_accuracy: 0.9149\n",
            "Epoch 12/500\n",
            "381/381 [==============================] - 0s 123us/sample - loss: 0.1962 - accuracy: 0.9449 - val_loss: 0.1956 - val_accuracy: 0.9202\n",
            "Epoch 13/500\n",
            "381/381 [==============================] - 0s 126us/sample - loss: 0.1877 - accuracy: 0.9423 - val_loss: 0.1862 - val_accuracy: 0.9202\n",
            "Epoch 14/500\n",
            "381/381 [==============================] - 0s 122us/sample - loss: 0.1800 - accuracy: 0.9449 - val_loss: 0.1775 - val_accuracy: 0.9309\n",
            "Epoch 15/500\n",
            "381/381 [==============================] - 0s 114us/sample - loss: 0.1736 - accuracy: 0.9475 - val_loss: 0.1689 - val_accuracy: 0.9362\n",
            "Epoch 16/500\n",
            "381/381 [==============================] - 0s 115us/sample - loss: 0.1670 - accuracy: 0.9554 - val_loss: 0.1619 - val_accuracy: 0.9415\n",
            "Epoch 17/500\n",
            "381/381 [==============================] - 0s 129us/sample - loss: 0.1618 - accuracy: 0.9554 - val_loss: 0.1554 - val_accuracy: 0.9574\n",
            "Epoch 18/500\n",
            "381/381 [==============================] - 0s 120us/sample - loss: 0.1565 - accuracy: 0.9554 - val_loss: 0.1495 - val_accuracy: 0.9628\n",
            "Epoch 19/500\n",
            "381/381 [==============================] - 0s 111us/sample - loss: 0.1519 - accuracy: 0.9606 - val_loss: 0.1440 - val_accuracy: 0.9628\n",
            "Epoch 20/500\n",
            "381/381 [==============================] - 0s 111us/sample - loss: 0.1477 - accuracy: 0.9659 - val_loss: 0.1394 - val_accuracy: 0.9628\n",
            "Epoch 21/500\n",
            "381/381 [==============================] - 0s 109us/sample - loss: 0.1442 - accuracy: 0.9659 - val_loss: 0.1346 - val_accuracy: 0.9734\n",
            "Epoch 22/500\n",
            "381/381 [==============================] - 0s 110us/sample - loss: 0.1401 - accuracy: 0.9659 - val_loss: 0.1304 - val_accuracy: 0.9734\n",
            "Epoch 23/500\n",
            "381/381 [==============================] - 0s 111us/sample - loss: 0.1369 - accuracy: 0.9685 - val_loss: 0.1263 - val_accuracy: 0.9787\n",
            "Epoch 24/500\n",
            "381/381 [==============================] - 0s 116us/sample - loss: 0.1336 - accuracy: 0.9685 - val_loss: 0.1229 - val_accuracy: 0.9787\n",
            "Epoch 25/500\n",
            "381/381 [==============================] - 0s 120us/sample - loss: 0.1310 - accuracy: 0.9685 - val_loss: 0.1197 - val_accuracy: 0.9787\n",
            "Epoch 26/500\n",
            "381/381 [==============================] - 0s 124us/sample - loss: 0.1278 - accuracy: 0.9685 - val_loss: 0.1167 - val_accuracy: 0.9787\n",
            "Epoch 27/500\n",
            "381/381 [==============================] - 0s 118us/sample - loss: 0.1258 - accuracy: 0.9685 - val_loss: 0.1138 - val_accuracy: 0.9840\n",
            "Epoch 28/500\n",
            "381/381 [==============================] - 0s 133us/sample - loss: 0.1231 - accuracy: 0.9685 - val_loss: 0.1109 - val_accuracy: 0.9840\n",
            "Epoch 29/500\n",
            "381/381 [==============================] - 0s 153us/sample - loss: 0.1208 - accuracy: 0.9711 - val_loss: 0.1085 - val_accuracy: 0.9840\n",
            "Epoch 30/500\n",
            "381/381 [==============================] - 0s 128us/sample - loss: 0.1187 - accuracy: 0.9711 - val_loss: 0.1066 - val_accuracy: 0.9840\n",
            "Epoch 31/500\n",
            "381/381 [==============================] - 0s 115us/sample - loss: 0.1167 - accuracy: 0.9711 - val_loss: 0.1043 - val_accuracy: 0.9840\n",
            "Epoch 32/500\n",
            "381/381 [==============================] - 0s 115us/sample - loss: 0.1147 - accuracy: 0.9711 - val_loss: 0.1022 - val_accuracy: 0.9840\n",
            "Epoch 33/500\n",
            "381/381 [==============================] - 0s 121us/sample - loss: 0.1130 - accuracy: 0.9711 - val_loss: 0.1004 - val_accuracy: 0.9840\n",
            "Epoch 34/500\n",
            "381/381 [==============================] - 0s 119us/sample - loss: 0.1113 - accuracy: 0.9711 - val_loss: 0.0987 - val_accuracy: 0.9840\n",
            "Epoch 35/500\n",
            "381/381 [==============================] - 0s 123us/sample - loss: 0.1096 - accuracy: 0.9738 - val_loss: 0.0969 - val_accuracy: 0.9840\n",
            "Epoch 36/500\n",
            "381/381 [==============================] - 0s 124us/sample - loss: 0.1083 - accuracy: 0.9738 - val_loss: 0.0952 - val_accuracy: 0.9840\n",
            "Epoch 37/500\n",
            "381/381 [==============================] - 0s 118us/sample - loss: 0.1068 - accuracy: 0.9764 - val_loss: 0.0936 - val_accuracy: 0.9840\n",
            "Epoch 38/500\n",
            "381/381 [==============================] - 0s 122us/sample - loss: 0.1054 - accuracy: 0.9764 - val_loss: 0.0923 - val_accuracy: 0.9787\n",
            "Epoch 39/500\n",
            "381/381 [==============================] - 0s 118us/sample - loss: 0.1042 - accuracy: 0.9764 - val_loss: 0.0908 - val_accuracy: 0.9787\n",
            "Epoch 40/500\n",
            "381/381 [==============================] - 0s 128us/sample - loss: 0.1029 - accuracy: 0.9790 - val_loss: 0.0896 - val_accuracy: 0.9787\n",
            "Epoch 41/500\n",
            "381/381 [==============================] - 0s 110us/sample - loss: 0.1017 - accuracy: 0.9790 - val_loss: 0.0881 - val_accuracy: 0.9787\n",
            "Epoch 42/500\n",
            "381/381 [==============================] - 0s 109us/sample - loss: 0.1007 - accuracy: 0.9790 - val_loss: 0.0866 - val_accuracy: 0.9787\n",
            "Epoch 43/500\n",
            "381/381 [==============================] - 0s 111us/sample - loss: 0.0996 - accuracy: 0.9790 - val_loss: 0.0857 - val_accuracy: 0.9787\n",
            "Epoch 44/500\n",
            "381/381 [==============================] - 0s 114us/sample - loss: 0.0986 - accuracy: 0.9816 - val_loss: 0.0847 - val_accuracy: 0.9787\n",
            "Epoch 45/500\n",
            "381/381 [==============================] - 0s 120us/sample - loss: 0.0976 - accuracy: 0.9816 - val_loss: 0.0836 - val_accuracy: 0.9787\n",
            "Epoch 46/500\n",
            "381/381 [==============================] - 0s 113us/sample - loss: 0.0967 - accuracy: 0.9816 - val_loss: 0.0827 - val_accuracy: 0.9840\n",
            "Epoch 47/500\n",
            "381/381 [==============================] - 0s 119us/sample - loss: 0.0959 - accuracy: 0.9816 - val_loss: 0.0817 - val_accuracy: 0.9840\n",
            "Epoch 48/500\n",
            "381/381 [==============================] - 0s 116us/sample - loss: 0.0950 - accuracy: 0.9816 - val_loss: 0.0809 - val_accuracy: 0.9840\n",
            "Epoch 49/500\n",
            "381/381 [==============================] - 0s 118us/sample - loss: 0.0942 - accuracy: 0.9816 - val_loss: 0.0799 - val_accuracy: 0.9840\n",
            "Epoch 50/500\n",
            "381/381 [==============================] - 0s 134us/sample - loss: 0.0934 - accuracy: 0.9816 - val_loss: 0.0791 - val_accuracy: 0.9840\n",
            "Epoch 51/500\n",
            "381/381 [==============================] - 0s 130us/sample - loss: 0.0928 - accuracy: 0.9816 - val_loss: 0.0783 - val_accuracy: 0.9840\n",
            "Epoch 52/500\n",
            "381/381 [==============================] - 0s 114us/sample - loss: 0.0920 - accuracy: 0.9816 - val_loss: 0.0776 - val_accuracy: 0.9840\n",
            "Epoch 53/500\n",
            "381/381 [==============================] - 0s 113us/sample - loss: 0.0913 - accuracy: 0.9816 - val_loss: 0.0768 - val_accuracy: 0.9840\n",
            "Epoch 54/500\n",
            "381/381 [==============================] - 0s 116us/sample - loss: 0.0906 - accuracy: 0.9816 - val_loss: 0.0760 - val_accuracy: 0.9840\n",
            "Epoch 55/500\n",
            "381/381 [==============================] - 0s 115us/sample - loss: 0.0900 - accuracy: 0.9816 - val_loss: 0.0753 - val_accuracy: 0.9840\n",
            "Epoch 56/500\n",
            "381/381 [==============================] - 0s 116us/sample - loss: 0.0894 - accuracy: 0.9816 - val_loss: 0.0744 - val_accuracy: 0.9840\n",
            "Epoch 57/500\n",
            "381/381 [==============================] - 0s 111us/sample - loss: 0.0888 - accuracy: 0.9816 - val_loss: 0.0739 - val_accuracy: 0.9840\n",
            "Epoch 58/500\n",
            "381/381 [==============================] - 0s 120us/sample - loss: 0.0883 - accuracy: 0.9816 - val_loss: 0.0731 - val_accuracy: 0.9840\n",
            "Epoch 59/500\n",
            "381/381 [==============================] - 0s 115us/sample - loss: 0.0876 - accuracy: 0.9816 - val_loss: 0.0726 - val_accuracy: 0.9840\n",
            "Epoch 60/500\n",
            "381/381 [==============================] - 0s 124us/sample - loss: 0.0871 - accuracy: 0.9816 - val_loss: 0.0720 - val_accuracy: 0.9840\n",
            "Epoch 61/500\n",
            "381/381 [==============================] - 0s 114us/sample - loss: 0.0866 - accuracy: 0.9816 - val_loss: 0.0714 - val_accuracy: 0.9840\n",
            "Epoch 62/500\n",
            "381/381 [==============================] - 0s 118us/sample - loss: 0.0861 - accuracy: 0.9816 - val_loss: 0.0709 - val_accuracy: 0.9840\n",
            "Epoch 63/500\n",
            "381/381 [==============================] - 0s 117us/sample - loss: 0.0856 - accuracy: 0.9816 - val_loss: 0.0705 - val_accuracy: 0.9840\n",
            "Epoch 64/500\n",
            "381/381 [==============================] - 0s 111us/sample - loss: 0.0852 - accuracy: 0.9816 - val_loss: 0.0700 - val_accuracy: 0.9840\n",
            "Epoch 65/500\n",
            "381/381 [==============================] - 0s 122us/sample - loss: 0.0847 - accuracy: 0.9816 - val_loss: 0.0695 - val_accuracy: 0.9840\n",
            "Epoch 66/500\n",
            "381/381 [==============================] - 0s 121us/sample - loss: 0.0842 - accuracy: 0.9816 - val_loss: 0.0690 - val_accuracy: 0.9840\n",
            "Epoch 67/500\n",
            "381/381 [==============================] - 0s 116us/sample - loss: 0.0839 - accuracy: 0.9816 - val_loss: 0.0689 - val_accuracy: 0.9840\n",
            "Epoch 68/500\n",
            "381/381 [==============================] - 0s 129us/sample - loss: 0.0833 - accuracy: 0.9816 - val_loss: 0.0681 - val_accuracy: 0.9840\n",
            "Epoch 69/500\n",
            "381/381 [==============================] - 0s 117us/sample - loss: 0.0829 - accuracy: 0.9816 - val_loss: 0.0677 - val_accuracy: 0.9840\n",
            "Epoch 70/500\n",
            "381/381 [==============================] - 0s 115us/sample - loss: 0.0825 - accuracy: 0.9816 - val_loss: 0.0672 - val_accuracy: 0.9840\n",
            "Epoch 71/500\n",
            "381/381 [==============================] - 0s 117us/sample - loss: 0.0822 - accuracy: 0.9816 - val_loss: 0.0668 - val_accuracy: 0.9840\n",
            "Epoch 72/500\n",
            "381/381 [==============================] - 0s 138us/sample - loss: 0.0817 - accuracy: 0.9816 - val_loss: 0.0664 - val_accuracy: 0.9840\n",
            "Epoch 73/500\n",
            "381/381 [==============================] - 0s 122us/sample - loss: 0.0814 - accuracy: 0.9816 - val_loss: 0.0661 - val_accuracy: 0.9840\n",
            "Epoch 74/500\n",
            "381/381 [==============================] - 0s 129us/sample - loss: 0.0810 - accuracy: 0.9816 - val_loss: 0.0656 - val_accuracy: 0.9840\n",
            "Epoch 75/500\n",
            "381/381 [==============================] - 0s 139us/sample - loss: 0.0807 - accuracy: 0.9816 - val_loss: 0.0653 - val_accuracy: 0.9840\n",
            "Epoch 76/500\n",
            "381/381 [==============================] - 0s 123us/sample - loss: 0.0803 - accuracy: 0.9816 - val_loss: 0.0650 - val_accuracy: 0.9840\n",
            "Epoch 77/500\n",
            "381/381 [==============================] - 0s 126us/sample - loss: 0.0800 - accuracy: 0.9816 - val_loss: 0.0646 - val_accuracy: 0.9840\n",
            "Epoch 78/500\n",
            "381/381 [==============================] - 0s 122us/sample - loss: 0.0796 - accuracy: 0.9816 - val_loss: 0.0643 - val_accuracy: 0.9840\n",
            "Epoch 79/500\n",
            "381/381 [==============================] - 0s 131us/sample - loss: 0.0793 - accuracy: 0.9843 - val_loss: 0.0640 - val_accuracy: 0.9840\n",
            "Epoch 80/500\n",
            "381/381 [==============================] - 0s 126us/sample - loss: 0.0790 - accuracy: 0.9843 - val_loss: 0.0637 - val_accuracy: 0.9840\n",
            "Epoch 81/500\n",
            "381/381 [==============================] - 0s 139us/sample - loss: 0.0787 - accuracy: 0.9843 - val_loss: 0.0636 - val_accuracy: 0.9840\n",
            "Epoch 82/500\n",
            "381/381 [==============================] - 0s 137us/sample - loss: 0.0785 - accuracy: 0.9843 - val_loss: 0.0629 - val_accuracy: 0.9840\n",
            "Epoch 83/500\n",
            "381/381 [==============================] - 0s 116us/sample - loss: 0.0781 - accuracy: 0.9843 - val_loss: 0.0629 - val_accuracy: 0.9840\n",
            "Epoch 84/500\n",
            "381/381 [==============================] - 0s 132us/sample - loss: 0.0778 - accuracy: 0.9843 - val_loss: 0.0625 - val_accuracy: 0.9840\n",
            "Epoch 85/500\n",
            "381/381 [==============================] - 0s 119us/sample - loss: 0.0776 - accuracy: 0.9843 - val_loss: 0.0624 - val_accuracy: 0.9840\n",
            "Epoch 86/500\n",
            "381/381 [==============================] - 0s 120us/sample - loss: 0.0772 - accuracy: 0.9843 - val_loss: 0.0622 - val_accuracy: 0.9840\n",
            "Epoch 87/500\n",
            "381/381 [==============================] - 0s 115us/sample - loss: 0.0770 - accuracy: 0.9843 - val_loss: 0.0621 - val_accuracy: 0.9840\n",
            "Epoch 88/500\n",
            "381/381 [==============================] - 0s 119us/sample - loss: 0.0767 - accuracy: 0.9843 - val_loss: 0.0618 - val_accuracy: 0.9840\n",
            "Epoch 89/500\n",
            "381/381 [==============================] - 0s 132us/sample - loss: 0.0764 - accuracy: 0.9843 - val_loss: 0.0616 - val_accuracy: 0.9840\n",
            "Epoch 90/500\n",
            "381/381 [==============================] - 0s 117us/sample - loss: 0.0762 - accuracy: 0.9843 - val_loss: 0.0613 - val_accuracy: 0.9840\n",
            "Epoch 91/500\n",
            "381/381 [==============================] - 0s 116us/sample - loss: 0.0759 - accuracy: 0.9843 - val_loss: 0.0612 - val_accuracy: 0.9840\n",
            "Epoch 92/500\n",
            "381/381 [==============================] - 0s 131us/sample - loss: 0.0757 - accuracy: 0.9843 - val_loss: 0.0608 - val_accuracy: 0.9840\n",
            "Epoch 93/500\n",
            "381/381 [==============================] - 0s 139us/sample - loss: 0.0754 - accuracy: 0.9843 - val_loss: 0.0607 - val_accuracy: 0.9840\n",
            "Epoch 94/500\n",
            "381/381 [==============================] - 0s 121us/sample - loss: 0.0752 - accuracy: 0.9843 - val_loss: 0.0605 - val_accuracy: 0.9840\n",
            "Epoch 95/500\n",
            "381/381 [==============================] - 0s 128us/sample - loss: 0.0750 - accuracy: 0.9843 - val_loss: 0.0601 - val_accuracy: 0.9840\n",
            "Epoch 96/500\n",
            "381/381 [==============================] - 0s 118us/sample - loss: 0.0747 - accuracy: 0.9843 - val_loss: 0.0599 - val_accuracy: 0.9840\n",
            "Epoch 97/500\n",
            "381/381 [==============================] - 0s 133us/sample - loss: 0.0745 - accuracy: 0.9843 - val_loss: 0.0600 - val_accuracy: 0.9840\n",
            "Epoch 98/500\n",
            "381/381 [==============================] - 0s 118us/sample - loss: 0.0743 - accuracy: 0.9843 - val_loss: 0.0596 - val_accuracy: 0.9840\n",
            "Epoch 99/500\n",
            "381/381 [==============================] - 0s 128us/sample - loss: 0.0741 - accuracy: 0.9843 - val_loss: 0.0597 - val_accuracy: 0.9840\n",
            "Epoch 100/500\n",
            "381/381 [==============================] - 0s 126us/sample - loss: 0.0738 - accuracy: 0.9843 - val_loss: 0.0597 - val_accuracy: 0.9840\n",
            "Epoch 101/500\n",
            "381/381 [==============================] - 0s 126us/sample - loss: 0.0737 - accuracy: 0.9843 - val_loss: 0.0592 - val_accuracy: 0.9840\n",
            "Epoch 102/500\n",
            "381/381 [==============================] - 0s 126us/sample - loss: 0.0734 - accuracy: 0.9843 - val_loss: 0.0592 - val_accuracy: 0.9840\n",
            "Epoch 103/500\n",
            "381/381 [==============================] - 0s 120us/sample - loss: 0.0732 - accuracy: 0.9843 - val_loss: 0.0591 - val_accuracy: 0.9840\n",
            "Epoch 104/500\n",
            "381/381 [==============================] - 0s 131us/sample - loss: 0.0730 - accuracy: 0.9843 - val_loss: 0.0592 - val_accuracy: 0.9840\n",
            "Epoch 105/500\n",
            "381/381 [==============================] - 0s 127us/sample - loss: 0.0728 - accuracy: 0.9843 - val_loss: 0.0587 - val_accuracy: 0.9840\n",
            "Epoch 106/500\n",
            "381/381 [==============================] - 0s 120us/sample - loss: 0.0726 - accuracy: 0.9843 - val_loss: 0.0588 - val_accuracy: 0.9840\n",
            "Epoch 107/500\n",
            "381/381 [==============================] - 0s 118us/sample - loss: 0.0724 - accuracy: 0.9843 - val_loss: 0.0586 - val_accuracy: 0.9840\n",
            "Epoch 108/500\n",
            "381/381 [==============================] - 0s 110us/sample - loss: 0.0723 - accuracy: 0.9843 - val_loss: 0.0582 - val_accuracy: 0.9840\n",
            "Epoch 109/500\n",
            "381/381 [==============================] - 0s 121us/sample - loss: 0.0721 - accuracy: 0.9843 - val_loss: 0.0581 - val_accuracy: 0.9840\n",
            "Epoch 110/500\n",
            "381/381 [==============================] - 0s 114us/sample - loss: 0.0719 - accuracy: 0.9843 - val_loss: 0.0585 - val_accuracy: 0.9787\n",
            "Epoch 111/500\n",
            "381/381 [==============================] - 0s 115us/sample - loss: 0.0717 - accuracy: 0.9843 - val_loss: 0.0582 - val_accuracy: 0.9787\n",
            "Epoch 112/500\n",
            "381/381 [==============================] - 0s 115us/sample - loss: 0.0715 - accuracy: 0.9843 - val_loss: 0.0583 - val_accuracy: 0.9787\n",
            "Epoch 113/500\n",
            "381/381 [==============================] - 0s 122us/sample - loss: 0.0713 - accuracy: 0.9843 - val_loss: 0.0581 - val_accuracy: 0.9787\n",
            "Epoch 114/500\n",
            "381/381 [==============================] - 0s 146us/sample - loss: 0.0711 - accuracy: 0.9843 - val_loss: 0.0580 - val_accuracy: 0.9787\n",
            "Epoch 115/500\n",
            "381/381 [==============================] - 0s 118us/sample - loss: 0.0710 - accuracy: 0.9843 - val_loss: 0.0578 - val_accuracy: 0.9787\n",
            "Epoch 116/500\n",
            "381/381 [==============================] - 0s 122us/sample - loss: 0.0708 - accuracy: 0.9843 - val_loss: 0.0576 - val_accuracy: 0.9787\n",
            "Epoch 117/500\n",
            "381/381 [==============================] - 0s 122us/sample - loss: 0.0706 - accuracy: 0.9843 - val_loss: 0.0579 - val_accuracy: 0.9787\n",
            "Epoch 118/500\n",
            "381/381 [==============================] - 0s 123us/sample - loss: 0.0705 - accuracy: 0.9843 - val_loss: 0.0575 - val_accuracy: 0.9787\n",
            "Epoch 119/500\n",
            "381/381 [==============================] - 0s 128us/sample - loss: 0.0703 - accuracy: 0.9843 - val_loss: 0.0577 - val_accuracy: 0.9787\n",
            "Epoch 120/500\n",
            "381/381 [==============================] - 0s 124us/sample - loss: 0.0701 - accuracy: 0.9843 - val_loss: 0.0578 - val_accuracy: 0.9787\n",
            "Epoch 121/500\n",
            "381/381 [==============================] - 0s 131us/sample - loss: 0.0699 - accuracy: 0.9843 - val_loss: 0.0576 - val_accuracy: 0.9787\n",
            "Epoch 122/500\n",
            "381/381 [==============================] - 0s 135us/sample - loss: 0.0698 - accuracy: 0.9843 - val_loss: 0.0574 - val_accuracy: 0.9787\n",
            "Epoch 123/500\n",
            "381/381 [==============================] - 0s 122us/sample - loss: 0.0696 - accuracy: 0.9843 - val_loss: 0.0573 - val_accuracy: 0.9787\n",
            "Epoch 124/500\n",
            "381/381 [==============================] - 0s 119us/sample - loss: 0.0695 - accuracy: 0.9843 - val_loss: 0.0570 - val_accuracy: 0.9787\n",
            "Epoch 125/500\n",
            "381/381 [==============================] - 0s 125us/sample - loss: 0.0693 - accuracy: 0.9843 - val_loss: 0.0573 - val_accuracy: 0.9787\n",
            "Epoch 126/500\n",
            "381/381 [==============================] - 0s 118us/sample - loss: 0.0692 - accuracy: 0.9843 - val_loss: 0.0571 - val_accuracy: 0.9787\n",
            "Epoch 127/500\n",
            "381/381 [==============================] - 0s 113us/sample - loss: 0.0690 - accuracy: 0.9843 - val_loss: 0.0572 - val_accuracy: 0.9787\n",
            "Epoch 128/500\n",
            "381/381 [==============================] - 0s 115us/sample - loss: 0.0689 - accuracy: 0.9843 - val_loss: 0.0571 - val_accuracy: 0.9787\n",
            "Epoch 129/500\n",
            "381/381 [==============================] - 0s 111us/sample - loss: 0.0687 - accuracy: 0.9843 - val_loss: 0.0567 - val_accuracy: 0.9787\n",
            "Epoch 130/500\n",
            "381/381 [==============================] - 0s 114us/sample - loss: 0.0687 - accuracy: 0.9843 - val_loss: 0.0564 - val_accuracy: 0.9787\n",
            "Epoch 131/500\n",
            "381/381 [==============================] - 0s 118us/sample - loss: 0.0685 - accuracy: 0.9843 - val_loss: 0.0570 - val_accuracy: 0.9787\n",
            "Epoch 132/500\n",
            "381/381 [==============================] - 0s 118us/sample - loss: 0.0683 - accuracy: 0.9843 - val_loss: 0.0570 - val_accuracy: 0.9787\n",
            "Epoch 133/500\n",
            "381/381 [==============================] - 0s 113us/sample - loss: 0.0681 - accuracy: 0.9843 - val_loss: 0.0570 - val_accuracy: 0.9787\n",
            "Epoch 134/500\n",
            "381/381 [==============================] - 0s 108us/sample - loss: 0.0681 - accuracy: 0.9843 - val_loss: 0.0568 - val_accuracy: 0.9787\n",
            "Epoch 135/500\n",
            "381/381 [==============================] - 0s 135us/sample - loss: 0.0679 - accuracy: 0.9843 - val_loss: 0.0568 - val_accuracy: 0.9787\n",
            "Epoch 136/500\n",
            "381/381 [==============================] - 0s 112us/sample - loss: 0.0678 - accuracy: 0.9843 - val_loss: 0.0569 - val_accuracy: 0.9787\n",
            "Epoch 137/500\n",
            "381/381 [==============================] - 0s 111us/sample - loss: 0.0676 - accuracy: 0.9843 - val_loss: 0.0567 - val_accuracy: 0.9787\n",
            "Epoch 138/500\n",
            "381/381 [==============================] - 0s 119us/sample - loss: 0.0675 - accuracy: 0.9843 - val_loss: 0.0565 - val_accuracy: 0.9787\n",
            "Epoch 139/500\n",
            "381/381 [==============================] - 0s 118us/sample - loss: 0.0673 - accuracy: 0.9843 - val_loss: 0.0568 - val_accuracy: 0.9787\n",
            "Epoch 140/500\n",
            "381/381 [==============================] - 0s 118us/sample - loss: 0.0672 - accuracy: 0.9843 - val_loss: 0.0567 - val_accuracy: 0.9787\n",
            "Epoch 141/500\n",
            "381/381 [==============================] - 0s 123us/sample - loss: 0.0671 - accuracy: 0.9843 - val_loss: 0.0566 - val_accuracy: 0.9787\n",
            "Epoch 142/500\n",
            "381/381 [==============================] - 0s 118us/sample - loss: 0.0669 - accuracy: 0.9843 - val_loss: 0.0567 - val_accuracy: 0.9787\n",
            "Epoch 143/500\n",
            "381/381 [==============================] - 0s 127us/sample - loss: 0.0669 - accuracy: 0.9843 - val_loss: 0.0571 - val_accuracy: 0.9787\n",
            "Epoch 144/500\n",
            "381/381 [==============================] - 0s 110us/sample - loss: 0.0668 - accuracy: 0.9843 - val_loss: 0.0566 - val_accuracy: 0.9787\n",
            "Epoch 145/500\n",
            "381/381 [==============================] - 0s 116us/sample - loss: 0.0666 - accuracy: 0.9843 - val_loss: 0.0568 - val_accuracy: 0.9787\n",
            "Epoch 146/500\n",
            "381/381 [==============================] - 0s 115us/sample - loss: 0.0664 - accuracy: 0.9843 - val_loss: 0.0568 - val_accuracy: 0.9787\n",
            "Epoch 147/500\n",
            "381/381 [==============================] - 0s 113us/sample - loss: 0.0664 - accuracy: 0.9843 - val_loss: 0.0571 - val_accuracy: 0.9787\n",
            "Epoch 148/500\n",
            "381/381 [==============================] - 0s 110us/sample - loss: 0.0663 - accuracy: 0.9843 - val_loss: 0.0567 - val_accuracy: 0.9787\n",
            "Epoch 149/500\n",
            "381/381 [==============================] - 0s 108us/sample - loss: 0.0661 - accuracy: 0.9843 - val_loss: 0.0568 - val_accuracy: 0.9787\n",
            "Epoch 150/500\n",
            "381/381 [==============================] - 0s 111us/sample - loss: 0.0660 - accuracy: 0.9843 - val_loss: 0.0568 - val_accuracy: 0.9787\n",
            "Epoch 151/500\n",
            "381/381 [==============================] - 0s 119us/sample - loss: 0.0658 - accuracy: 0.9843 - val_loss: 0.0568 - val_accuracy: 0.9787\n",
            "Epoch 152/500\n",
            "381/381 [==============================] - 0s 121us/sample - loss: 0.0657 - accuracy: 0.9843 - val_loss: 0.0570 - val_accuracy: 0.9787\n",
            "Epoch 153/500\n",
            "381/381 [==============================] - 0s 107us/sample - loss: 0.0656 - accuracy: 0.9843 - val_loss: 0.0571 - val_accuracy: 0.9787\n",
            "Epoch 154/500\n",
            "381/381 [==============================] - 0s 112us/sample - loss: 0.0655 - accuracy: 0.9843 - val_loss: 0.0573 - val_accuracy: 0.9787\n",
            "Epoch 155/500\n",
            "381/381 [==============================] - 0s 115us/sample - loss: 0.0654 - accuracy: 0.9843 - val_loss: 0.0570 - val_accuracy: 0.9787\n",
            "Epoch 156/500\n",
            "381/381 [==============================] - 0s 117us/sample - loss: 0.0653 - accuracy: 0.9843 - val_loss: 0.0573 - val_accuracy: 0.9787\n",
            "Epoch 157/500\n",
            "381/381 [==============================] - 0s 174us/sample - loss: 0.0652 - accuracy: 0.9843 - val_loss: 0.0571 - val_accuracy: 0.9787\n",
            "Epoch 158/500\n",
            "381/381 [==============================] - 0s 161us/sample - loss: 0.0651 - accuracy: 0.9843 - val_loss: 0.0571 - val_accuracy: 0.9787\n",
            "Epoch 159/500\n",
            "381/381 [==============================] - 0s 128us/sample - loss: 0.0649 - accuracy: 0.9843 - val_loss: 0.0571 - val_accuracy: 0.9787\n",
            "Epoch 160/500\n",
            "381/381 [==============================] - 0s 156us/sample - loss: 0.0648 - accuracy: 0.9843 - val_loss: 0.0571 - val_accuracy: 0.9787\n",
            "Epoch 161/500\n",
            "381/381 [==============================] - 0s 119us/sample - loss: 0.0648 - accuracy: 0.9843 - val_loss: 0.0576 - val_accuracy: 0.9787\n",
            "Epoch 162/500\n",
            "381/381 [==============================] - 0s 121us/sample - loss: 0.0646 - accuracy: 0.9843 - val_loss: 0.0577 - val_accuracy: 0.9787\n",
            "Epoch 163/500\n",
            "381/381 [==============================] - 0s 113us/sample - loss: 0.0645 - accuracy: 0.9843 - val_loss: 0.0576 - val_accuracy: 0.9787\n",
            "Epoch 164/500\n",
            "381/381 [==============================] - 0s 107us/sample - loss: 0.0644 - accuracy: 0.9843 - val_loss: 0.0574 - val_accuracy: 0.9787\n",
            "Epoch 165/500\n",
            "381/381 [==============================] - 0s 115us/sample - loss: 0.0643 - accuracy: 0.9843 - val_loss: 0.0576 - val_accuracy: 0.9787\n",
            "Epoch 166/500\n",
            "381/381 [==============================] - 0s 118us/sample - loss: 0.0642 - accuracy: 0.9843 - val_loss: 0.0576 - val_accuracy: 0.9787\n",
            "Epoch 167/500\n",
            "381/381 [==============================] - 0s 119us/sample - loss: 0.0641 - accuracy: 0.9843 - val_loss: 0.0573 - val_accuracy: 0.9787\n",
            "Epoch 168/500\n",
            "381/381 [==============================] - 0s 111us/sample - loss: 0.0641 - accuracy: 0.9843 - val_loss: 0.0575 - val_accuracy: 0.9787\n",
            "Epoch 169/500\n",
            "381/381 [==============================] - 0s 124us/sample - loss: 0.0639 - accuracy: 0.9843 - val_loss: 0.0576 - val_accuracy: 0.9787\n",
            "Epoch 170/500\n",
            "381/381 [==============================] - 0s 135us/sample - loss: 0.0638 - accuracy: 0.9843 - val_loss: 0.0575 - val_accuracy: 0.9787\n",
            "Epoch 171/500\n",
            "381/381 [==============================] - 0s 116us/sample - loss: 0.0637 - accuracy: 0.9843 - val_loss: 0.0574 - val_accuracy: 0.9787\n",
            "Epoch 172/500\n",
            "381/381 [==============================] - 0s 120us/sample - loss: 0.0636 - accuracy: 0.9869 - val_loss: 0.0579 - val_accuracy: 0.9787\n",
            "Epoch 173/500\n",
            "381/381 [==============================] - 0s 117us/sample - loss: 0.0635 - accuracy: 0.9869 - val_loss: 0.0580 - val_accuracy: 0.9787\n",
            "Epoch 174/500\n",
            "381/381 [==============================] - 0s 113us/sample - loss: 0.0634 - accuracy: 0.9869 - val_loss: 0.0578 - val_accuracy: 0.9787\n",
            "Epoch 175/500\n",
            "381/381 [==============================] - 0s 118us/sample - loss: 0.0633 - accuracy: 0.9869 - val_loss: 0.0578 - val_accuracy: 0.9787\n",
            "Epoch 176/500\n",
            "381/381 [==============================] - 0s 114us/sample - loss: 0.0632 - accuracy: 0.9869 - val_loss: 0.0582 - val_accuracy: 0.9787\n",
            "Epoch 177/500\n",
            "381/381 [==============================] - 0s 114us/sample - loss: 0.0632 - accuracy: 0.9869 - val_loss: 0.0585 - val_accuracy: 0.9787\n",
            "Epoch 178/500\n",
            "381/381 [==============================] - 0s 125us/sample - loss: 0.0630 - accuracy: 0.9869 - val_loss: 0.0586 - val_accuracy: 0.9787\n",
            "Epoch 179/500\n",
            "381/381 [==============================] - 0s 127us/sample - loss: 0.0629 - accuracy: 0.9869 - val_loss: 0.0585 - val_accuracy: 0.9787\n",
            "Epoch 180/500\n",
            "381/381 [==============================] - 0s 121us/sample - loss: 0.0628 - accuracy: 0.9869 - val_loss: 0.0585 - val_accuracy: 0.9787\n",
            "Epoch 181/500\n",
            "381/381 [==============================] - 0s 127us/sample - loss: 0.0628 - accuracy: 0.9869 - val_loss: 0.0590 - val_accuracy: 0.9787\n",
            "Epoch 182/500\n",
            "381/381 [==============================] - 0s 125us/sample - loss: 0.0627 - accuracy: 0.9869 - val_loss: 0.0586 - val_accuracy: 0.9787\n",
            "Epoch 183/500\n",
            "381/381 [==============================] - 0s 119us/sample - loss: 0.0625 - accuracy: 0.9869 - val_loss: 0.0587 - val_accuracy: 0.9787\n",
            "Epoch 184/500\n",
            "381/381 [==============================] - 0s 118us/sample - loss: 0.0625 - accuracy: 0.9869 - val_loss: 0.0584 - val_accuracy: 0.9787\n",
            "Epoch 185/500\n",
            "381/381 [==============================] - 0s 138us/sample - loss: 0.0625 - accuracy: 0.9869 - val_loss: 0.0593 - val_accuracy: 0.9787\n",
            "Epoch 186/500\n",
            "381/381 [==============================] - 0s 122us/sample - loss: 0.0623 - accuracy: 0.9869 - val_loss: 0.0593 - val_accuracy: 0.9787\n",
            "Epoch 187/500\n",
            "381/381 [==============================] - 0s 113us/sample - loss: 0.0622 - accuracy: 0.9869 - val_loss: 0.0594 - val_accuracy: 0.9787\n",
            "Epoch 188/500\n",
            "381/381 [==============================] - 0s 119us/sample - loss: 0.0621 - accuracy: 0.9869 - val_loss: 0.0592 - val_accuracy: 0.9787\n",
            "Epoch 189/500\n",
            "381/381 [==============================] - 0s 111us/sample - loss: 0.0620 - accuracy: 0.9869 - val_loss: 0.0590 - val_accuracy: 0.9840\n",
            "Epoch 190/500\n",
            "381/381 [==============================] - 0s 116us/sample - loss: 0.0619 - accuracy: 0.9869 - val_loss: 0.0592 - val_accuracy: 0.9840\n",
            "Epoch 191/500\n",
            "381/381 [==============================] - 0s 118us/sample - loss: 0.0618 - accuracy: 0.9869 - val_loss: 0.0596 - val_accuracy: 0.9840\n",
            "Epoch 192/500\n",
            "381/381 [==============================] - 0s 111us/sample - loss: 0.0618 - accuracy: 0.9869 - val_loss: 0.0597 - val_accuracy: 0.9840\n",
            "Epoch 193/500\n",
            "381/381 [==============================] - 0s 113us/sample - loss: 0.0617 - accuracy: 0.9869 - val_loss: 0.0596 - val_accuracy: 0.9840\n",
            "Epoch 194/500\n",
            "381/381 [==============================] - 0s 109us/sample - loss: 0.0616 - accuracy: 0.9869 - val_loss: 0.0601 - val_accuracy: 0.9787\n",
            "Epoch 195/500\n",
            "381/381 [==============================] - 0s 116us/sample - loss: 0.0615 - accuracy: 0.9869 - val_loss: 0.0599 - val_accuracy: 0.9840\n",
            "Epoch 196/500\n",
            "381/381 [==============================] - 0s 109us/sample - loss: 0.0614 - accuracy: 0.9869 - val_loss: 0.0599 - val_accuracy: 0.9840\n",
            "Epoch 197/500\n",
            "381/381 [==============================] - 0s 115us/sample - loss: 0.0614 - accuracy: 0.9869 - val_loss: 0.0597 - val_accuracy: 0.9840\n",
            "Epoch 198/500\n",
            "381/381 [==============================] - 0s 112us/sample - loss: 0.0612 - accuracy: 0.9869 - val_loss: 0.0599 - val_accuracy: 0.9840\n",
            "Epoch 199/500\n",
            "381/381 [==============================] - 0s 113us/sample - loss: 0.0612 - accuracy: 0.9869 - val_loss: 0.0605 - val_accuracy: 0.9787\n",
            "Epoch 200/500\n",
            "381/381 [==============================] - 0s 126us/sample - loss: 0.0611 - accuracy: 0.9869 - val_loss: 0.0607 - val_accuracy: 0.9840\n",
            "Epoch 201/500\n",
            "381/381 [==============================] - 0s 130us/sample - loss: 0.0611 - accuracy: 0.9869 - val_loss: 0.0604 - val_accuracy: 0.9840\n",
            "Epoch 202/500\n",
            "381/381 [==============================] - 0s 136us/sample - loss: 0.0610 - accuracy: 0.9869 - val_loss: 0.0608 - val_accuracy: 0.9787\n",
            "Epoch 203/500\n",
            "381/381 [==============================] - 0s 125us/sample - loss: 0.0608 - accuracy: 0.9869 - val_loss: 0.0606 - val_accuracy: 0.9840\n",
            "Epoch 204/500\n",
            "381/381 [==============================] - 0s 119us/sample - loss: 0.0608 - accuracy: 0.9869 - val_loss: 0.0603 - val_accuracy: 0.9840\n",
            "Epoch 205/500\n",
            "381/381 [==============================] - 0s 152us/sample - loss: 0.0607 - accuracy: 0.9869 - val_loss: 0.0605 - val_accuracy: 0.9840\n",
            "Epoch 206/500\n",
            "381/381 [==============================] - 0s 118us/sample - loss: 0.0606 - accuracy: 0.9869 - val_loss: 0.0607 - val_accuracy: 0.9840\n",
            "Epoch 207/500\n",
            "381/381 [==============================] - 0s 117us/sample - loss: 0.0605 - accuracy: 0.9869 - val_loss: 0.0609 - val_accuracy: 0.9840\n",
            "Epoch 208/500\n",
            "381/381 [==============================] - 0s 118us/sample - loss: 0.0605 - accuracy: 0.9869 - val_loss: 0.0615 - val_accuracy: 0.9840\n",
            "Epoch 209/500\n",
            "381/381 [==============================] - 0s 123us/sample - loss: 0.0603 - accuracy: 0.9869 - val_loss: 0.0613 - val_accuracy: 0.9840\n",
            "Epoch 210/500\n",
            "381/381 [==============================] - 0s 119us/sample - loss: 0.0603 - accuracy: 0.9869 - val_loss: 0.0615 - val_accuracy: 0.9840\n",
            "Epoch 211/500\n",
            "381/381 [==============================] - 0s 116us/sample - loss: 0.0602 - accuracy: 0.9869 - val_loss: 0.0615 - val_accuracy: 0.9840\n",
            "Epoch 212/500\n",
            "381/381 [==============================] - 0s 111us/sample - loss: 0.0602 - accuracy: 0.9869 - val_loss: 0.0616 - val_accuracy: 0.9840\n",
            "Epoch 213/500\n",
            "381/381 [==============================] - 0s 117us/sample - loss: 0.0601 - accuracy: 0.9869 - val_loss: 0.0614 - val_accuracy: 0.9840\n",
            "Epoch 214/500\n",
            "381/381 [==============================] - 0s 110us/sample - loss: 0.0600 - accuracy: 0.9869 - val_loss: 0.0615 - val_accuracy: 0.9840\n",
            "Epoch 215/500\n",
            "381/381 [==============================] - 0s 118us/sample - loss: 0.0599 - accuracy: 0.9869 - val_loss: 0.0619 - val_accuracy: 0.9840\n",
            "Epoch 216/500\n",
            "381/381 [==============================] - 0s 115us/sample - loss: 0.0599 - accuracy: 0.9869 - val_loss: 0.0626 - val_accuracy: 0.9840\n",
            "Epoch 217/500\n",
            "381/381 [==============================] - 0s 124us/sample - loss: 0.0598 - accuracy: 0.9869 - val_loss: 0.0622 - val_accuracy: 0.9840\n",
            "Epoch 218/500\n",
            "381/381 [==============================] - 0s 122us/sample - loss: 0.0597 - accuracy: 0.9869 - val_loss: 0.0622 - val_accuracy: 0.9840\n",
            "Epoch 219/500\n",
            "381/381 [==============================] - 0s 116us/sample - loss: 0.0596 - accuracy: 0.9869 - val_loss: 0.0624 - val_accuracy: 0.9840\n",
            "Epoch 220/500\n",
            "381/381 [==============================] - 0s 122us/sample - loss: 0.0595 - accuracy: 0.9869 - val_loss: 0.0626 - val_accuracy: 0.9840\n",
            "Epoch 221/500\n",
            "381/381 [==============================] - 0s 116us/sample - loss: 0.0594 - accuracy: 0.9869 - val_loss: 0.0628 - val_accuracy: 0.9840\n",
            "Epoch 222/500\n",
            "381/381 [==============================] - 0s 150us/sample - loss: 0.0594 - accuracy: 0.9869 - val_loss: 0.0624 - val_accuracy: 0.9840\n",
            "Epoch 223/500\n",
            "381/381 [==============================] - 0s 125us/sample - loss: 0.0593 - accuracy: 0.9869 - val_loss: 0.0630 - val_accuracy: 0.9840\n",
            "Epoch 224/500\n",
            "381/381 [==============================] - 0s 123us/sample - loss: 0.0592 - accuracy: 0.9869 - val_loss: 0.0630 - val_accuracy: 0.9840\n",
            "Epoch 225/500\n",
            "381/381 [==============================] - 0s 113us/sample - loss: 0.0591 - accuracy: 0.9869 - val_loss: 0.0631 - val_accuracy: 0.9840\n",
            "Epoch 226/500\n",
            "381/381 [==============================] - 0s 118us/sample - loss: 0.0591 - accuracy: 0.9869 - val_loss: 0.0631 - val_accuracy: 0.9840\n",
            "Epoch 227/500\n",
            "381/381 [==============================] - 0s 115us/sample - loss: 0.0591 - accuracy: 0.9869 - val_loss: 0.0638 - val_accuracy: 0.9840\n",
            "Epoch 228/500\n",
            "381/381 [==============================] - 0s 116us/sample - loss: 0.0589 - accuracy: 0.9869 - val_loss: 0.0637 - val_accuracy: 0.9840\n",
            "Epoch 229/500\n",
            "381/381 [==============================] - 0s 115us/sample - loss: 0.0589 - accuracy: 0.9869 - val_loss: 0.0636 - val_accuracy: 0.9840\n",
            "Epoch 230/500\n",
            "381/381 [==============================] - 0s 123us/sample - loss: 0.0588 - accuracy: 0.9869 - val_loss: 0.0640 - val_accuracy: 0.9840\n",
            "Epoch 231/500\n",
            "381/381 [==============================] - 0s 132us/sample - loss: 0.0587 - accuracy: 0.9869 - val_loss: 0.0636 - val_accuracy: 0.9840\n",
            "Epoch 232/500\n",
            "381/381 [==============================] - 0s 128us/sample - loss: 0.0587 - accuracy: 0.9869 - val_loss: 0.0640 - val_accuracy: 0.9840\n",
            "Epoch 233/500\n",
            "381/381 [==============================] - 0s 121us/sample - loss: 0.0586 - accuracy: 0.9869 - val_loss: 0.0645 - val_accuracy: 0.9840\n",
            "Epoch 234/500\n",
            "381/381 [==============================] - 0s 120us/sample - loss: 0.0585 - accuracy: 0.9869 - val_loss: 0.0641 - val_accuracy: 0.9840\n",
            "Epoch 235/500\n",
            "381/381 [==============================] - 0s 120us/sample - loss: 0.0584 - accuracy: 0.9869 - val_loss: 0.0642 - val_accuracy: 0.9840\n",
            "Epoch 236/500\n",
            "381/381 [==============================] - 0s 114us/sample - loss: 0.0584 - accuracy: 0.9869 - val_loss: 0.0642 - val_accuracy: 0.9840\n",
            "Epoch 237/500\n",
            "381/381 [==============================] - 0s 109us/sample - loss: 0.0583 - accuracy: 0.9869 - val_loss: 0.0644 - val_accuracy: 0.9840\n",
            "Epoch 238/500\n",
            "381/381 [==============================] - 0s 113us/sample - loss: 0.0582 - accuracy: 0.9869 - val_loss: 0.0650 - val_accuracy: 0.9840\n",
            "Epoch 239/500\n",
            "381/381 [==============================] - 0s 116us/sample - loss: 0.0581 - accuracy: 0.9869 - val_loss: 0.0649 - val_accuracy: 0.9840\n",
            "Epoch 240/500\n",
            "381/381 [==============================] - 0s 123us/sample - loss: 0.0581 - accuracy: 0.9869 - val_loss: 0.0654 - val_accuracy: 0.9840\n",
            "Epoch 241/500\n",
            "381/381 [==============================] - 0s 116us/sample - loss: 0.0580 - accuracy: 0.9869 - val_loss: 0.0653 - val_accuracy: 0.9840\n",
            "Epoch 242/500\n",
            "381/381 [==============================] - 0s 116us/sample - loss: 0.0580 - accuracy: 0.9869 - val_loss: 0.0651 - val_accuracy: 0.9840\n",
            "Epoch 243/500\n",
            "381/381 [==============================] - 0s 139us/sample - loss: 0.0579 - accuracy: 0.9869 - val_loss: 0.0655 - val_accuracy: 0.9840\n",
            "Epoch 244/500\n",
            "381/381 [==============================] - 0s 124us/sample - loss: 0.0578 - accuracy: 0.9869 - val_loss: 0.0657 - val_accuracy: 0.9840\n",
            "Epoch 245/500\n",
            "381/381 [==============================] - 0s 128us/sample - loss: 0.0578 - accuracy: 0.9869 - val_loss: 0.0652 - val_accuracy: 0.9840\n",
            "Epoch 246/500\n",
            "381/381 [==============================] - 0s 118us/sample - loss: 0.0579 - accuracy: 0.9895 - val_loss: 0.0661 - val_accuracy: 0.9840\n",
            "Epoch 247/500\n",
            "381/381 [==============================] - 0s 119us/sample - loss: 0.0577 - accuracy: 0.9869 - val_loss: 0.0667 - val_accuracy: 0.9840\n",
            "Epoch 248/500\n",
            "381/381 [==============================] - 0s 120us/sample - loss: 0.0576 - accuracy: 0.9869 - val_loss: 0.0663 - val_accuracy: 0.9840\n",
            "Epoch 249/500\n",
            "381/381 [==============================] - 0s 122us/sample - loss: 0.0575 - accuracy: 0.9869 - val_loss: 0.0667 - val_accuracy: 0.9840\n",
            "Epoch 250/500\n",
            "381/381 [==============================] - 0s 135us/sample - loss: 0.0574 - accuracy: 0.9869 - val_loss: 0.0668 - val_accuracy: 0.9840\n",
            "Epoch 251/500\n",
            "381/381 [==============================] - 0s 123us/sample - loss: 0.0574 - accuracy: 0.9869 - val_loss: 0.0664 - val_accuracy: 0.9840\n",
            "Epoch 252/500\n",
            "381/381 [==============================] - 0s 120us/sample - loss: 0.0572 - accuracy: 0.9895 - val_loss: 0.0666 - val_accuracy: 0.9840\n",
            "Epoch 253/500\n",
            "381/381 [==============================] - 0s 121us/sample - loss: 0.0573 - accuracy: 0.9895 - val_loss: 0.0671 - val_accuracy: 0.9840\n",
            "Epoch 254/500\n",
            "381/381 [==============================] - 0s 119us/sample - loss: 0.0571 - accuracy: 0.9895 - val_loss: 0.0670 - val_accuracy: 0.9840\n",
            "Epoch 255/500\n",
            "381/381 [==============================] - 0s 120us/sample - loss: 0.0571 - accuracy: 0.9895 - val_loss: 0.0671 - val_accuracy: 0.9840\n",
            "Epoch 256/500\n",
            "381/381 [==============================] - 0s 111us/sample - loss: 0.0571 - accuracy: 0.9895 - val_loss: 0.0669 - val_accuracy: 0.9840\n",
            "Epoch 257/500\n",
            "381/381 [==============================] - 0s 110us/sample - loss: 0.0569 - accuracy: 0.9895 - val_loss: 0.0673 - val_accuracy: 0.9840\n",
            "Epoch 258/500\n",
            "381/381 [==============================] - 0s 126us/sample - loss: 0.0569 - accuracy: 0.9895 - val_loss: 0.0670 - val_accuracy: 0.9840\n",
            "Epoch 259/500\n",
            "381/381 [==============================] - 0s 137us/sample - loss: 0.0568 - accuracy: 0.9869 - val_loss: 0.0677 - val_accuracy: 0.9840\n",
            "Epoch 260/500\n",
            "381/381 [==============================] - 0s 117us/sample - loss: 0.0567 - accuracy: 0.9869 - val_loss: 0.0681 - val_accuracy: 0.9840\n",
            "Epoch 261/500\n",
            "381/381 [==============================] - 0s 108us/sample - loss: 0.0567 - accuracy: 0.9869 - val_loss: 0.0683 - val_accuracy: 0.9840\n",
            "Epoch 262/500\n",
            "381/381 [==============================] - 0s 117us/sample - loss: 0.0567 - accuracy: 0.9869 - val_loss: 0.0687 - val_accuracy: 0.9840\n",
            "Epoch 263/500\n",
            "381/381 [==============================] - 0s 125us/sample - loss: 0.0566 - accuracy: 0.9869 - val_loss: 0.0686 - val_accuracy: 0.9840\n",
            "Epoch 264/500\n",
            "381/381 [==============================] - 0s 140us/sample - loss: 0.0565 - accuracy: 0.9869 - val_loss: 0.0686 - val_accuracy: 0.9840\n",
            "Epoch 265/500\n",
            "381/381 [==============================] - 0s 119us/sample - loss: 0.0564 - accuracy: 0.9869 - val_loss: 0.0685 - val_accuracy: 0.9840\n",
            "Epoch 266/500\n",
            "381/381 [==============================] - 0s 127us/sample - loss: 0.0564 - accuracy: 0.9869 - val_loss: 0.0687 - val_accuracy: 0.9840\n",
            "Epoch 267/500\n",
            "381/381 [==============================] - 0s 119us/sample - loss: 0.0563 - accuracy: 0.9869 - val_loss: 0.0683 - val_accuracy: 0.9840\n",
            "Epoch 268/500\n",
            "381/381 [==============================] - 0s 127us/sample - loss: 0.0563 - accuracy: 0.9869 - val_loss: 0.0690 - val_accuracy: 0.9840\n",
            "Epoch 269/500\n",
            "381/381 [==============================] - 0s 116us/sample - loss: 0.0562 - accuracy: 0.9869 - val_loss: 0.0692 - val_accuracy: 0.9840\n",
            "Epoch 270/500\n",
            "381/381 [==============================] - 0s 132us/sample - loss: 0.0561 - accuracy: 0.9895 - val_loss: 0.0687 - val_accuracy: 0.9840\n",
            "Epoch 271/500\n",
            "381/381 [==============================] - 0s 125us/sample - loss: 0.0561 - accuracy: 0.9895 - val_loss: 0.0693 - val_accuracy: 0.9840\n",
            "Epoch 272/500\n",
            "381/381 [==============================] - 0s 123us/sample - loss: 0.0560 - accuracy: 0.9869 - val_loss: 0.0697 - val_accuracy: 0.9840\n",
            "Epoch 273/500\n",
            "381/381 [==============================] - 0s 112us/sample - loss: 0.0559 - accuracy: 0.9869 - val_loss: 0.0697 - val_accuracy: 0.9840\n",
            "Epoch 274/500\n",
            "381/381 [==============================] - 0s 121us/sample - loss: 0.0559 - accuracy: 0.9869 - val_loss: 0.0699 - val_accuracy: 0.9840\n",
            "Epoch 275/500\n",
            "381/381 [==============================] - 0s 120us/sample - loss: 0.0558 - accuracy: 0.9869 - val_loss: 0.0696 - val_accuracy: 0.9840\n",
            "Epoch 276/500\n",
            "381/381 [==============================] - 0s 129us/sample - loss: 0.0559 - accuracy: 0.9869 - val_loss: 0.0703 - val_accuracy: 0.9840\n",
            "Epoch 277/500\n",
            "381/381 [==============================] - 0s 123us/sample - loss: 0.0558 - accuracy: 0.9869 - val_loss: 0.0704 - val_accuracy: 0.9840\n",
            "Epoch 278/500\n",
            "381/381 [==============================] - 0s 126us/sample - loss: 0.0556 - accuracy: 0.9869 - val_loss: 0.0704 - val_accuracy: 0.9840\n",
            "Epoch 279/500\n",
            "381/381 [==============================] - 0s 123us/sample - loss: 0.0556 - accuracy: 0.9869 - val_loss: 0.0704 - val_accuracy: 0.9840\n",
            "Epoch 280/500\n",
            "381/381 [==============================] - 0s 126us/sample - loss: 0.0556 - accuracy: 0.9869 - val_loss: 0.0703 - val_accuracy: 0.9840\n",
            "Epoch 281/500\n",
            "381/381 [==============================] - 0s 119us/sample - loss: 0.0555 - accuracy: 0.9869 - val_loss: 0.0706 - val_accuracy: 0.9840\n",
            "Epoch 282/500\n",
            "381/381 [==============================] - 0s 115us/sample - loss: 0.0554 - accuracy: 0.9869 - val_loss: 0.0705 - val_accuracy: 0.9840\n",
            "Epoch 283/500\n",
            "381/381 [==============================] - 0s 116us/sample - loss: 0.0555 - accuracy: 0.9869 - val_loss: 0.0713 - val_accuracy: 0.9840\n",
            "Epoch 284/500\n",
            "381/381 [==============================] - 0s 117us/sample - loss: 0.0553 - accuracy: 0.9869 - val_loss: 0.0714 - val_accuracy: 0.9840\n",
            "Epoch 285/500\n",
            "381/381 [==============================] - 0s 121us/sample - loss: 0.0553 - accuracy: 0.9869 - val_loss: 0.0710 - val_accuracy: 0.9840\n",
            "Epoch 286/500\n",
            "381/381 [==============================] - 0s 141us/sample - loss: 0.0554 - accuracy: 0.9869 - val_loss: 0.0704 - val_accuracy: 0.9840\n",
            "Epoch 287/500\n",
            "381/381 [==============================] - 0s 123us/sample - loss: 0.0552 - accuracy: 0.9869 - val_loss: 0.0715 - val_accuracy: 0.9840\n",
            "Epoch 288/500\n",
            "381/381 [==============================] - 0s 125us/sample - loss: 0.0551 - accuracy: 0.9869 - val_loss: 0.0718 - val_accuracy: 0.9840\n",
            "Epoch 289/500\n",
            "381/381 [==============================] - 0s 115us/sample - loss: 0.0551 - accuracy: 0.9869 - val_loss: 0.0719 - val_accuracy: 0.9840\n",
            "Epoch 290/500\n",
            "381/381 [==============================] - 0s 128us/sample - loss: 0.0549 - accuracy: 0.9869 - val_loss: 0.0719 - val_accuracy: 0.9840\n",
            "Epoch 291/500\n",
            "381/381 [==============================] - 0s 122us/sample - loss: 0.0549 - accuracy: 0.9869 - val_loss: 0.0724 - val_accuracy: 0.9840\n",
            "Epoch 292/500\n",
            "381/381 [==============================] - 0s 114us/sample - loss: 0.0548 - accuracy: 0.9869 - val_loss: 0.0723 - val_accuracy: 0.9840\n",
            "Epoch 293/500\n",
            "381/381 [==============================] - 0s 120us/sample - loss: 0.0548 - accuracy: 0.9869 - val_loss: 0.0720 - val_accuracy: 0.9840\n",
            "Epoch 294/500\n",
            "381/381 [==============================] - 0s 116us/sample - loss: 0.0547 - accuracy: 0.9869 - val_loss: 0.0722 - val_accuracy: 0.9840\n",
            "Epoch 295/500\n",
            "381/381 [==============================] - 0s 110us/sample - loss: 0.0547 - accuracy: 0.9869 - val_loss: 0.0726 - val_accuracy: 0.9840\n",
            "Epoch 296/500\n",
            "381/381 [==============================] - 0s 121us/sample - loss: 0.0546 - accuracy: 0.9869 - val_loss: 0.0730 - val_accuracy: 0.9840\n",
            "Epoch 297/500\n",
            "381/381 [==============================] - 0s 112us/sample - loss: 0.0546 - accuracy: 0.9869 - val_loss: 0.0732 - val_accuracy: 0.9840\n",
            "Epoch 298/500\n",
            "381/381 [==============================] - 0s 115us/sample - loss: 0.0545 - accuracy: 0.9869 - val_loss: 0.0733 - val_accuracy: 0.9840\n",
            "Epoch 299/500\n",
            "381/381 [==============================] - 0s 130us/sample - loss: 0.0545 - accuracy: 0.9869 - val_loss: 0.0729 - val_accuracy: 0.9840\n",
            "Epoch 300/500\n",
            "381/381 [==============================] - 0s 112us/sample - loss: 0.0544 - accuracy: 0.9869 - val_loss: 0.0733 - val_accuracy: 0.9840\n",
            "Epoch 301/500\n",
            "381/381 [==============================] - 0s 125us/sample - loss: 0.0544 - accuracy: 0.9869 - val_loss: 0.0737 - val_accuracy: 0.9840\n",
            "Epoch 302/500\n",
            "381/381 [==============================] - 0s 124us/sample - loss: 0.0544 - accuracy: 0.9869 - val_loss: 0.0742 - val_accuracy: 0.9840\n",
            "Epoch 303/500\n",
            "381/381 [==============================] - 0s 115us/sample - loss: 0.0543 - accuracy: 0.9869 - val_loss: 0.0735 - val_accuracy: 0.9840\n",
            "Epoch 304/500\n",
            "381/381 [==============================] - 0s 123us/sample - loss: 0.0542 - accuracy: 0.9869 - val_loss: 0.0736 - val_accuracy: 0.9840\n",
            "Epoch 305/500\n",
            "381/381 [==============================] - 0s 113us/sample - loss: 0.0543 - accuracy: 0.9869 - val_loss: 0.0746 - val_accuracy: 0.9840\n",
            "Epoch 306/500\n",
            "381/381 [==============================] - 0s 111us/sample - loss: 0.0541 - accuracy: 0.9869 - val_loss: 0.0743 - val_accuracy: 0.9840\n",
            "Epoch 307/500\n",
            "381/381 [==============================] - 0s 140us/sample - loss: 0.0540 - accuracy: 0.9869 - val_loss: 0.0744 - val_accuracy: 0.9840\n",
            "Epoch 308/500\n",
            "381/381 [==============================] - 0s 123us/sample - loss: 0.0539 - accuracy: 0.9869 - val_loss: 0.0746 - val_accuracy: 0.9840\n",
            "Epoch 309/500\n",
            "381/381 [==============================] - 0s 119us/sample - loss: 0.0540 - accuracy: 0.9869 - val_loss: 0.0741 - val_accuracy: 0.9840\n",
            "Epoch 310/500\n",
            "381/381 [==============================] - 0s 132us/sample - loss: 0.0539 - accuracy: 0.9869 - val_loss: 0.0744 - val_accuracy: 0.9840\n",
            "Epoch 311/500\n",
            "381/381 [==============================] - 0s 128us/sample - loss: 0.0538 - accuracy: 0.9869 - val_loss: 0.0749 - val_accuracy: 0.9840\n",
            "Epoch 312/500\n",
            "381/381 [==============================] - 0s 144us/sample - loss: 0.0537 - accuracy: 0.9869 - val_loss: 0.0749 - val_accuracy: 0.9840\n",
            "Epoch 313/500\n",
            "381/381 [==============================] - 0s 114us/sample - loss: 0.0538 - accuracy: 0.9869 - val_loss: 0.0743 - val_accuracy: 0.9840\n",
            "Epoch 314/500\n",
            "381/381 [==============================] - 0s 120us/sample - loss: 0.0537 - accuracy: 0.9869 - val_loss: 0.0756 - val_accuracy: 0.9840\n",
            "Epoch 315/500\n",
            "381/381 [==============================] - 0s 123us/sample - loss: 0.0536 - accuracy: 0.9869 - val_loss: 0.0758 - val_accuracy: 0.9840\n",
            "Epoch 316/500\n",
            "381/381 [==============================] - 0s 131us/sample - loss: 0.0536 - accuracy: 0.9869 - val_loss: 0.0759 - val_accuracy: 0.9840\n",
            "Epoch 317/500\n",
            "381/381 [==============================] - 0s 123us/sample - loss: 0.0535 - accuracy: 0.9869 - val_loss: 0.0759 - val_accuracy: 0.9840\n",
            "Epoch 318/500\n",
            "381/381 [==============================] - 0s 125us/sample - loss: 0.0535 - accuracy: 0.9869 - val_loss: 0.0763 - val_accuracy: 0.9840\n",
            "Epoch 319/500\n",
            "381/381 [==============================] - 0s 119us/sample - loss: 0.0534 - accuracy: 0.9869 - val_loss: 0.0767 - val_accuracy: 0.9840\n",
            "Epoch 320/500\n",
            "381/381 [==============================] - 0s 143us/sample - loss: 0.0534 - accuracy: 0.9869 - val_loss: 0.0760 - val_accuracy: 0.9840\n",
            "Epoch 321/500\n",
            "381/381 [==============================] - 0s 125us/sample - loss: 0.0533 - accuracy: 0.9869 - val_loss: 0.0767 - val_accuracy: 0.9840\n",
            "Epoch 322/500\n",
            "381/381 [==============================] - 0s 126us/sample - loss: 0.0533 - accuracy: 0.9869 - val_loss: 0.0763 - val_accuracy: 0.9840\n",
            "Epoch 323/500\n",
            "381/381 [==============================] - 0s 128us/sample - loss: 0.0532 - accuracy: 0.9869 - val_loss: 0.0771 - val_accuracy: 0.9840\n",
            "Epoch 324/500\n",
            "381/381 [==============================] - 0s 119us/sample - loss: 0.0532 - accuracy: 0.9869 - val_loss: 0.0772 - val_accuracy: 0.9840\n",
            "Epoch 325/500\n",
            "381/381 [==============================] - 0s 123us/sample - loss: 0.0531 - accuracy: 0.9869 - val_loss: 0.0766 - val_accuracy: 0.9840\n",
            "Epoch 326/500\n",
            "381/381 [==============================] - 0s 124us/sample - loss: 0.0531 - accuracy: 0.9869 - val_loss: 0.0775 - val_accuracy: 0.9840\n",
            "Epoch 327/500\n",
            "381/381 [==============================] - 0s 119us/sample - loss: 0.0530 - accuracy: 0.9869 - val_loss: 0.0770 - val_accuracy: 0.9840\n",
            "Epoch 328/500\n",
            "381/381 [==============================] - 0s 151us/sample - loss: 0.0530 - accuracy: 0.9869 - val_loss: 0.0778 - val_accuracy: 0.9840\n",
            "Epoch 329/500\n",
            "381/381 [==============================] - 0s 113us/sample - loss: 0.0529 - accuracy: 0.9869 - val_loss: 0.0773 - val_accuracy: 0.9840\n",
            "Epoch 330/500\n",
            "381/381 [==============================] - 0s 121us/sample - loss: 0.0528 - accuracy: 0.9869 - val_loss: 0.0778 - val_accuracy: 0.9840\n",
            "Epoch 331/500\n",
            "381/381 [==============================] - 0s 115us/sample - loss: 0.0528 - accuracy: 0.9869 - val_loss: 0.0787 - val_accuracy: 0.9840\n",
            "Epoch 332/500\n",
            "381/381 [==============================] - 0s 127us/sample - loss: 0.0527 - accuracy: 0.9869 - val_loss: 0.0784 - val_accuracy: 0.9840\n",
            "Epoch 333/500\n",
            "381/381 [==============================] - 0s 122us/sample - loss: 0.0527 - accuracy: 0.9869 - val_loss: 0.0789 - val_accuracy: 0.9840\n",
            "Epoch 334/500\n",
            "381/381 [==============================] - 0s 125us/sample - loss: 0.0527 - accuracy: 0.9869 - val_loss: 0.0791 - val_accuracy: 0.9840\n",
            "Epoch 335/500\n",
            "381/381 [==============================] - 0s 118us/sample - loss: 0.0527 - accuracy: 0.9869 - val_loss: 0.0784 - val_accuracy: 0.9787\n",
            "Epoch 336/500\n",
            "381/381 [==============================] - 0s 140us/sample - loss: 0.0526 - accuracy: 0.9869 - val_loss: 0.0786 - val_accuracy: 0.9787\n",
            "Epoch 337/500\n",
            "381/381 [==============================] - 0s 137us/sample - loss: 0.0525 - accuracy: 0.9869 - val_loss: 0.0790 - val_accuracy: 0.9787\n",
            "Epoch 338/500\n",
            "381/381 [==============================] - 0s 125us/sample - loss: 0.0524 - accuracy: 0.9869 - val_loss: 0.0792 - val_accuracy: 0.9840\n",
            "Epoch 339/500\n",
            "381/381 [==============================] - 0s 121us/sample - loss: 0.0524 - accuracy: 0.9869 - val_loss: 0.0797 - val_accuracy: 0.9840\n",
            "Epoch 340/500\n",
            "381/381 [==============================] - 0s 120us/sample - loss: 0.0524 - accuracy: 0.9869 - val_loss: 0.0795 - val_accuracy: 0.9787\n",
            "Epoch 341/500\n",
            "381/381 [==============================] - 0s 113us/sample - loss: 0.0523 - accuracy: 0.9869 - val_loss: 0.0800 - val_accuracy: 0.9787\n",
            "Epoch 342/500\n",
            "381/381 [==============================] - 0s 116us/sample - loss: 0.0522 - accuracy: 0.9869 - val_loss: 0.0799 - val_accuracy: 0.9787\n",
            "Epoch 343/500\n",
            "381/381 [==============================] - 0s 113us/sample - loss: 0.0522 - accuracy: 0.9869 - val_loss: 0.0802 - val_accuracy: 0.9787\n",
            "Epoch 344/500\n",
            "381/381 [==============================] - 0s 113us/sample - loss: 0.0521 - accuracy: 0.9869 - val_loss: 0.0804 - val_accuracy: 0.9787\n",
            "Epoch 345/500\n",
            "381/381 [==============================] - 0s 134us/sample - loss: 0.0522 - accuracy: 0.9869 - val_loss: 0.0799 - val_accuracy: 0.9787\n",
            "Epoch 346/500\n",
            "381/381 [==============================] - 0s 115us/sample - loss: 0.0521 - accuracy: 0.9869 - val_loss: 0.0810 - val_accuracy: 0.9787\n",
            "Epoch 347/500\n",
            "381/381 [==============================] - 0s 106us/sample - loss: 0.0519 - accuracy: 0.9869 - val_loss: 0.0807 - val_accuracy: 0.9787\n",
            "Epoch 348/500\n",
            "381/381 [==============================] - 0s 118us/sample - loss: 0.0520 - accuracy: 0.9869 - val_loss: 0.0813 - val_accuracy: 0.9787\n",
            "Epoch 349/500\n",
            "381/381 [==============================] - 0s 164us/sample - loss: 0.0519 - accuracy: 0.9869 - val_loss: 0.0811 - val_accuracy: 0.9787\n",
            "Epoch 350/500\n",
            "381/381 [==============================] - 0s 142us/sample - loss: 0.0519 - accuracy: 0.9869 - val_loss: 0.0806 - val_accuracy: 0.9787\n",
            "Epoch 351/500\n",
            "381/381 [==============================] - 0s 108us/sample - loss: 0.0518 - accuracy: 0.9869 - val_loss: 0.0808 - val_accuracy: 0.9787\n",
            "Epoch 352/500\n",
            "381/381 [==============================] - 0s 108us/sample - loss: 0.0519 - accuracy: 0.9869 - val_loss: 0.0815 - val_accuracy: 0.9787\n",
            "Epoch 353/500\n",
            "381/381 [==============================] - 0s 108us/sample - loss: 0.0517 - accuracy: 0.9869 - val_loss: 0.0814 - val_accuracy: 0.9787\n",
            "Epoch 354/500\n",
            "381/381 [==============================] - 0s 113us/sample - loss: 0.0516 - accuracy: 0.9869 - val_loss: 0.0815 - val_accuracy: 0.9787\n",
            "Epoch 355/500\n",
            "381/381 [==============================] - 0s 111us/sample - loss: 0.0516 - accuracy: 0.9869 - val_loss: 0.0821 - val_accuracy: 0.9787\n",
            "Epoch 356/500\n",
            "381/381 [==============================] - 0s 125us/sample - loss: 0.0516 - accuracy: 0.9869 - val_loss: 0.0818 - val_accuracy: 0.9787\n",
            "Epoch 357/500\n",
            "381/381 [==============================] - 0s 123us/sample - loss: 0.0515 - accuracy: 0.9869 - val_loss: 0.0818 - val_accuracy: 0.9787\n",
            "Epoch 358/500\n",
            "381/381 [==============================] - 0s 119us/sample - loss: 0.0515 - accuracy: 0.9869 - val_loss: 0.0817 - val_accuracy: 0.9787\n",
            "Epoch 359/500\n",
            "381/381 [==============================] - 0s 124us/sample - loss: 0.0514 - accuracy: 0.9869 - val_loss: 0.0819 - val_accuracy: 0.9734\n",
            "Epoch 360/500\n",
            "381/381 [==============================] - 0s 116us/sample - loss: 0.0514 - accuracy: 0.9869 - val_loss: 0.0821 - val_accuracy: 0.9734\n",
            "Epoch 361/500\n",
            "381/381 [==============================] - 0s 118us/sample - loss: 0.0513 - accuracy: 0.9869 - val_loss: 0.0822 - val_accuracy: 0.9734\n",
            "Epoch 362/500\n",
            "381/381 [==============================] - 0s 114us/sample - loss: 0.0513 - accuracy: 0.9869 - val_loss: 0.0830 - val_accuracy: 0.9734\n",
            "Epoch 363/500\n",
            "381/381 [==============================] - 0s 115us/sample - loss: 0.0512 - accuracy: 0.9869 - val_loss: 0.0829 - val_accuracy: 0.9734\n",
            "Epoch 364/500\n",
            "381/381 [==============================] - 0s 124us/sample - loss: 0.0512 - accuracy: 0.9869 - val_loss: 0.0828 - val_accuracy: 0.9734\n",
            "Epoch 365/500\n",
            "381/381 [==============================] - 0s 114us/sample - loss: 0.0512 - accuracy: 0.9869 - val_loss: 0.0836 - val_accuracy: 0.9734\n",
            "Epoch 366/500\n",
            "381/381 [==============================] - 0s 117us/sample - loss: 0.0512 - accuracy: 0.9869 - val_loss: 0.0831 - val_accuracy: 0.9734\n",
            "Epoch 367/500\n",
            "381/381 [==============================] - 0s 116us/sample - loss: 0.0510 - accuracy: 0.9869 - val_loss: 0.0832 - val_accuracy: 0.9734\n",
            "Epoch 368/500\n",
            "381/381 [==============================] - 0s 112us/sample - loss: 0.0511 - accuracy: 0.9869 - val_loss: 0.0834 - val_accuracy: 0.9734\n",
            "Epoch 369/500\n",
            "381/381 [==============================] - 0s 121us/sample - loss: 0.0510 - accuracy: 0.9869 - val_loss: 0.0832 - val_accuracy: 0.9734\n",
            "Epoch 370/500\n",
            "381/381 [==============================] - 0s 120us/sample - loss: 0.0510 - accuracy: 0.9869 - val_loss: 0.0835 - val_accuracy: 0.9734\n",
            "Epoch 371/500\n",
            "381/381 [==============================] - 0s 144us/sample - loss: 0.0510 - accuracy: 0.9869 - val_loss: 0.0845 - val_accuracy: 0.9734\n",
            "Epoch 372/500\n",
            "381/381 [==============================] - 0s 114us/sample - loss: 0.0508 - accuracy: 0.9869 - val_loss: 0.0843 - val_accuracy: 0.9734\n",
            "Epoch 373/500\n",
            "381/381 [==============================] - 0s 119us/sample - loss: 0.0508 - accuracy: 0.9869 - val_loss: 0.0846 - val_accuracy: 0.9734\n",
            "Epoch 374/500\n",
            "381/381 [==============================] - 0s 133us/sample - loss: 0.0508 - accuracy: 0.9869 - val_loss: 0.0844 - val_accuracy: 0.9734\n",
            "Epoch 375/500\n",
            "381/381 [==============================] - 0s 121us/sample - loss: 0.0507 - accuracy: 0.9869 - val_loss: 0.0846 - val_accuracy: 0.9734\n",
            "Epoch 376/500\n",
            "381/381 [==============================] - 0s 118us/sample - loss: 0.0507 - accuracy: 0.9869 - val_loss: 0.0846 - val_accuracy: 0.9734\n",
            "Epoch 377/500\n",
            "381/381 [==============================] - 0s 119us/sample - loss: 0.0506 - accuracy: 0.9869 - val_loss: 0.0844 - val_accuracy: 0.9734\n",
            "Epoch 378/500\n",
            "381/381 [==============================] - 0s 173us/sample - loss: 0.0506 - accuracy: 0.9869 - val_loss: 0.0849 - val_accuracy: 0.9734\n",
            "Epoch 379/500\n",
            "381/381 [==============================] - 0s 117us/sample - loss: 0.0505 - accuracy: 0.9869 - val_loss: 0.0853 - val_accuracy: 0.9734\n",
            "Epoch 380/500\n",
            "381/381 [==============================] - 0s 119us/sample - loss: 0.0506 - accuracy: 0.9869 - val_loss: 0.0846 - val_accuracy: 0.9734\n",
            "Epoch 381/500\n",
            "381/381 [==============================] - 0s 121us/sample - loss: 0.0506 - accuracy: 0.9869 - val_loss: 0.0858 - val_accuracy: 0.9734\n",
            "Epoch 382/500\n",
            "381/381 [==============================] - 0s 120us/sample - loss: 0.0504 - accuracy: 0.9869 - val_loss: 0.0862 - val_accuracy: 0.9734\n",
            "Epoch 383/500\n",
            "381/381 [==============================] - 0s 132us/sample - loss: 0.0505 - accuracy: 0.9869 - val_loss: 0.0852 - val_accuracy: 0.9734\n",
            "Epoch 384/500\n",
            "381/381 [==============================] - 0s 118us/sample - loss: 0.0503 - accuracy: 0.9869 - val_loss: 0.0855 - val_accuracy: 0.9734\n",
            "Epoch 385/500\n",
            "381/381 [==============================] - 0s 112us/sample - loss: 0.0503 - accuracy: 0.9869 - val_loss: 0.0863 - val_accuracy: 0.9734\n",
            "Epoch 386/500\n",
            "381/381 [==============================] - 0s 123us/sample - loss: 0.0503 - accuracy: 0.9869 - val_loss: 0.0857 - val_accuracy: 0.9734\n",
            "Epoch 387/500\n",
            "381/381 [==============================] - 0s 136us/sample - loss: 0.0502 - accuracy: 0.9869 - val_loss: 0.0858 - val_accuracy: 0.9734\n",
            "Epoch 388/500\n",
            "381/381 [==============================] - 0s 112us/sample - loss: 0.0502 - accuracy: 0.9869 - val_loss: 0.0861 - val_accuracy: 0.9734\n",
            "Epoch 389/500\n",
            "381/381 [==============================] - 0s 121us/sample - loss: 0.0502 - accuracy: 0.9869 - val_loss: 0.0873 - val_accuracy: 0.9734\n",
            "Epoch 390/500\n",
            "381/381 [==============================] - 0s 111us/sample - loss: 0.0501 - accuracy: 0.9869 - val_loss: 0.0873 - val_accuracy: 0.9734\n",
            "Epoch 391/500\n",
            "381/381 [==============================] - 0s 116us/sample - loss: 0.0500 - accuracy: 0.9869 - val_loss: 0.0871 - val_accuracy: 0.9734\n",
            "Epoch 392/500\n",
            "381/381 [==============================] - 0s 155us/sample - loss: 0.0500 - accuracy: 0.9869 - val_loss: 0.0871 - val_accuracy: 0.9734\n",
            "Epoch 393/500\n",
            "381/381 [==============================] - 0s 125us/sample - loss: 0.0500 - accuracy: 0.9869 - val_loss: 0.0870 - val_accuracy: 0.9734\n",
            "Epoch 394/500\n",
            "381/381 [==============================] - 0s 118us/sample - loss: 0.0500 - accuracy: 0.9869 - val_loss: 0.0875 - val_accuracy: 0.9734\n",
            "Epoch 395/500\n",
            "381/381 [==============================] - 0s 118us/sample - loss: 0.0499 - accuracy: 0.9869 - val_loss: 0.0875 - val_accuracy: 0.9734\n",
            "Epoch 396/500\n",
            "381/381 [==============================] - 0s 118us/sample - loss: 0.0498 - accuracy: 0.9869 - val_loss: 0.0877 - val_accuracy: 0.9734\n",
            "Epoch 397/500\n",
            "381/381 [==============================] - 0s 115us/sample - loss: 0.0498 - accuracy: 0.9869 - val_loss: 0.0874 - val_accuracy: 0.9734\n",
            "Epoch 398/500\n",
            "381/381 [==============================] - 0s 114us/sample - loss: 0.0498 - accuracy: 0.9869 - val_loss: 0.0878 - val_accuracy: 0.9734\n",
            "Epoch 399/500\n",
            "381/381 [==============================] - 0s 114us/sample - loss: 0.0497 - accuracy: 0.9869 - val_loss: 0.0879 - val_accuracy: 0.9734\n",
            "Epoch 400/500\n",
            "381/381 [==============================] - 0s 111us/sample - loss: 0.0497 - accuracy: 0.9869 - val_loss: 0.0881 - val_accuracy: 0.9734\n",
            "Epoch 401/500\n",
            "381/381 [==============================] - 0s 114us/sample - loss: 0.0496 - accuracy: 0.9869 - val_loss: 0.0880 - val_accuracy: 0.9734\n",
            "Epoch 402/500\n",
            "381/381 [==============================] - 0s 111us/sample - loss: 0.0496 - accuracy: 0.9869 - val_loss: 0.0885 - val_accuracy: 0.9734\n",
            "Epoch 403/500\n",
            "381/381 [==============================] - 0s 111us/sample - loss: 0.0496 - accuracy: 0.9869 - val_loss: 0.0883 - val_accuracy: 0.9734\n",
            "Epoch 404/500\n",
            "381/381 [==============================] - 0s 116us/sample - loss: 0.0495 - accuracy: 0.9869 - val_loss: 0.0889 - val_accuracy: 0.9734\n",
            "Epoch 405/500\n",
            "381/381 [==============================] - 0s 114us/sample - loss: 0.0495 - accuracy: 0.9869 - val_loss: 0.0890 - val_accuracy: 0.9734\n",
            "Epoch 406/500\n",
            "381/381 [==============================] - 0s 114us/sample - loss: 0.0494 - accuracy: 0.9869 - val_loss: 0.0888 - val_accuracy: 0.9734\n",
            "Epoch 407/500\n",
            "381/381 [==============================] - 0s 131us/sample - loss: 0.0494 - accuracy: 0.9869 - val_loss: 0.0884 - val_accuracy: 0.9734\n",
            "Epoch 408/500\n",
            "381/381 [==============================] - 0s 110us/sample - loss: 0.0493 - accuracy: 0.9869 - val_loss: 0.0886 - val_accuracy: 0.9734\n",
            "Epoch 409/500\n",
            "381/381 [==============================] - 0s 123us/sample - loss: 0.0494 - accuracy: 0.9869 - val_loss: 0.0897 - val_accuracy: 0.9734\n",
            "Epoch 410/500\n",
            "381/381 [==============================] - 0s 122us/sample - loss: 0.0493 - accuracy: 0.9869 - val_loss: 0.0896 - val_accuracy: 0.9734\n",
            "Epoch 411/500\n",
            "381/381 [==============================] - 0s 123us/sample - loss: 0.0493 - accuracy: 0.9869 - val_loss: 0.0900 - val_accuracy: 0.9734\n",
            "Epoch 412/500\n",
            "381/381 [==============================] - 0s 113us/sample - loss: 0.0492 - accuracy: 0.9869 - val_loss: 0.0897 - val_accuracy: 0.9734\n",
            "Epoch 413/500\n",
            "381/381 [==============================] - 0s 124us/sample - loss: 0.0491 - accuracy: 0.9869 - val_loss: 0.0901 - val_accuracy: 0.9734\n",
            "Epoch 414/500\n",
            "381/381 [==============================] - 0s 121us/sample - loss: 0.0491 - accuracy: 0.9869 - val_loss: 0.0898 - val_accuracy: 0.9734\n",
            "Epoch 415/500\n",
            "381/381 [==============================] - 0s 116us/sample - loss: 0.0491 - accuracy: 0.9869 - val_loss: 0.0901 - val_accuracy: 0.9734\n",
            "Epoch 416/500\n",
            "381/381 [==============================] - 0s 122us/sample - loss: 0.0490 - accuracy: 0.9869 - val_loss: 0.0900 - val_accuracy: 0.9734\n",
            "Epoch 417/500\n",
            "381/381 [==============================] - 0s 119us/sample - loss: 0.0490 - accuracy: 0.9869 - val_loss: 0.0901 - val_accuracy: 0.9734\n",
            "Epoch 418/500\n",
            "381/381 [==============================] - 0s 119us/sample - loss: 0.0490 - accuracy: 0.9869 - val_loss: 0.0905 - val_accuracy: 0.9734\n",
            "Epoch 419/500\n",
            "381/381 [==============================] - 0s 121us/sample - loss: 0.0489 - accuracy: 0.9869 - val_loss: 0.0909 - val_accuracy: 0.9734\n",
            "Epoch 420/500\n",
            "381/381 [==============================] - 0s 117us/sample - loss: 0.0489 - accuracy: 0.9869 - val_loss: 0.0908 - val_accuracy: 0.9734\n",
            "Epoch 421/500\n",
            "381/381 [==============================] - 0s 123us/sample - loss: 0.0488 - accuracy: 0.9869 - val_loss: 0.0910 - val_accuracy: 0.9734\n",
            "Epoch 422/500\n",
            "381/381 [==============================] - 0s 129us/sample - loss: 0.0488 - accuracy: 0.9869 - val_loss: 0.0914 - val_accuracy: 0.9734\n",
            "Epoch 423/500\n",
            "381/381 [==============================] - 0s 124us/sample - loss: 0.0488 - accuracy: 0.9869 - val_loss: 0.0912 - val_accuracy: 0.9734\n",
            "Epoch 424/500\n",
            "381/381 [==============================] - 0s 127us/sample - loss: 0.0489 - accuracy: 0.9869 - val_loss: 0.0906 - val_accuracy: 0.9734\n",
            "Epoch 425/500\n",
            "381/381 [==============================] - 0s 141us/sample - loss: 0.0487 - accuracy: 0.9869 - val_loss: 0.0911 - val_accuracy: 0.9734\n",
            "Epoch 426/500\n",
            "381/381 [==============================] - 0s 133us/sample - loss: 0.0488 - accuracy: 0.9869 - val_loss: 0.0921 - val_accuracy: 0.9734\n",
            "Epoch 427/500\n",
            "381/381 [==============================] - 0s 127us/sample - loss: 0.0486 - accuracy: 0.9869 - val_loss: 0.0924 - val_accuracy: 0.9734\n",
            "Epoch 428/500\n",
            "381/381 [==============================] - 0s 128us/sample - loss: 0.0486 - accuracy: 0.9869 - val_loss: 0.0918 - val_accuracy: 0.9734\n",
            "Epoch 429/500\n",
            "381/381 [==============================] - 0s 130us/sample - loss: 0.0486 - accuracy: 0.9869 - val_loss: 0.0917 - val_accuracy: 0.9734\n",
            "Epoch 430/500\n",
            "381/381 [==============================] - 0s 115us/sample - loss: 0.0485 - accuracy: 0.9869 - val_loss: 0.0921 - val_accuracy: 0.9734\n",
            "Epoch 431/500\n",
            "381/381 [==============================] - 0s 115us/sample - loss: 0.0484 - accuracy: 0.9869 - val_loss: 0.0922 - val_accuracy: 0.9734\n",
            "Epoch 432/500\n",
            "381/381 [==============================] - 0s 121us/sample - loss: 0.0485 - accuracy: 0.9869 - val_loss: 0.0918 - val_accuracy: 0.9734\n",
            "Epoch 433/500\n",
            "381/381 [==============================] - 0s 122us/sample - loss: 0.0484 - accuracy: 0.9869 - val_loss: 0.0925 - val_accuracy: 0.9734\n",
            "Epoch 434/500\n",
            "381/381 [==============================] - 0s 126us/sample - loss: 0.0484 - accuracy: 0.9869 - val_loss: 0.0922 - val_accuracy: 0.9734\n",
            "Epoch 435/500\n",
            "381/381 [==============================] - 0s 135us/sample - loss: 0.0484 - accuracy: 0.9869 - val_loss: 0.0925 - val_accuracy: 0.9734\n",
            "Epoch 436/500\n",
            "381/381 [==============================] - 0s 121us/sample - loss: 0.0484 - accuracy: 0.9869 - val_loss: 0.0931 - val_accuracy: 0.9734\n",
            "Epoch 437/500\n",
            "381/381 [==============================] - 0s 119us/sample - loss: 0.0483 - accuracy: 0.9869 - val_loss: 0.0929 - val_accuracy: 0.9734\n",
            "Epoch 438/500\n",
            "381/381 [==============================] - 0s 118us/sample - loss: 0.0483 - accuracy: 0.9869 - val_loss: 0.0938 - val_accuracy: 0.9734\n",
            "Epoch 439/500\n",
            "381/381 [==============================] - 0s 129us/sample - loss: 0.0483 - accuracy: 0.9869 - val_loss: 0.0941 - val_accuracy: 0.9734\n",
            "Epoch 440/500\n",
            "381/381 [==============================] - 0s 114us/sample - loss: 0.0481 - accuracy: 0.9869 - val_loss: 0.0937 - val_accuracy: 0.9734\n",
            "Epoch 441/500\n",
            "381/381 [==============================] - 0s 118us/sample - loss: 0.0482 - accuracy: 0.9869 - val_loss: 0.0933 - val_accuracy: 0.9734\n",
            "Epoch 442/500\n",
            "381/381 [==============================] - 0s 136us/sample - loss: 0.0481 - accuracy: 0.9869 - val_loss: 0.0937 - val_accuracy: 0.9734\n",
            "Epoch 443/500\n",
            "381/381 [==============================] - 0s 115us/sample - loss: 0.0480 - accuracy: 0.9869 - val_loss: 0.0939 - val_accuracy: 0.9734\n",
            "Epoch 444/500\n",
            "381/381 [==============================] - 0s 112us/sample - loss: 0.0480 - accuracy: 0.9869 - val_loss: 0.0939 - val_accuracy: 0.9734\n",
            "Epoch 445/500\n",
            "381/381 [==============================] - 0s 115us/sample - loss: 0.0480 - accuracy: 0.9869 - val_loss: 0.0937 - val_accuracy: 0.9734\n",
            "Epoch 446/500\n",
            "381/381 [==============================] - 0s 116us/sample - loss: 0.0479 - accuracy: 0.9869 - val_loss: 0.0940 - val_accuracy: 0.9734\n",
            "Epoch 447/500\n",
            "381/381 [==============================] - 0s 117us/sample - loss: 0.0479 - accuracy: 0.9869 - val_loss: 0.0943 - val_accuracy: 0.9734\n",
            "Epoch 448/500\n",
            "381/381 [==============================] - 0s 115us/sample - loss: 0.0479 - accuracy: 0.9869 - val_loss: 0.0947 - val_accuracy: 0.9734\n",
            "Epoch 449/500\n",
            "381/381 [==============================] - 0s 114us/sample - loss: 0.0478 - accuracy: 0.9869 - val_loss: 0.0948 - val_accuracy: 0.9734\n",
            "Epoch 450/500\n",
            "381/381 [==============================] - 0s 125us/sample - loss: 0.0478 - accuracy: 0.9869 - val_loss: 0.0949 - val_accuracy: 0.9734\n",
            "Epoch 451/500\n",
            "381/381 [==============================] - 0s 118us/sample - loss: 0.0478 - accuracy: 0.9869 - val_loss: 0.0950 - val_accuracy: 0.9734\n",
            "Epoch 452/500\n",
            "381/381 [==============================] - 0s 115us/sample - loss: 0.0477 - accuracy: 0.9869 - val_loss: 0.0952 - val_accuracy: 0.9734\n",
            "Epoch 453/500\n",
            "381/381 [==============================] - 0s 116us/sample - loss: 0.0477 - accuracy: 0.9869 - val_loss: 0.0956 - val_accuracy: 0.9734\n",
            "Epoch 454/500\n",
            "381/381 [==============================] - 0s 126us/sample - loss: 0.0476 - accuracy: 0.9869 - val_loss: 0.0955 - val_accuracy: 0.9681\n",
            "Epoch 455/500\n",
            "381/381 [==============================] - 0s 117us/sample - loss: 0.0476 - accuracy: 0.9869 - val_loss: 0.0956 - val_accuracy: 0.9681\n",
            "Epoch 456/500\n",
            "381/381 [==============================] - 0s 134us/sample - loss: 0.0476 - accuracy: 0.9869 - val_loss: 0.0957 - val_accuracy: 0.9681\n",
            "Epoch 457/500\n",
            "381/381 [==============================] - 0s 134us/sample - loss: 0.0475 - accuracy: 0.9869 - val_loss: 0.0956 - val_accuracy: 0.9681\n",
            "Epoch 458/500\n",
            "381/381 [==============================] - 0s 117us/sample - loss: 0.0476 - accuracy: 0.9869 - val_loss: 0.0955 - val_accuracy: 0.9681\n",
            "Epoch 459/500\n",
            "381/381 [==============================] - 0s 115us/sample - loss: 0.0475 - accuracy: 0.9869 - val_loss: 0.0954 - val_accuracy: 0.9681\n",
            "Epoch 460/500\n",
            "381/381 [==============================] - 0s 126us/sample - loss: 0.0474 - accuracy: 0.9869 - val_loss: 0.0958 - val_accuracy: 0.9681\n",
            "Epoch 461/500\n",
            "381/381 [==============================] - 0s 111us/sample - loss: 0.0474 - accuracy: 0.9869 - val_loss: 0.0955 - val_accuracy: 0.9681\n",
            "Epoch 462/500\n",
            "381/381 [==============================] - 0s 122us/sample - loss: 0.0473 - accuracy: 0.9869 - val_loss: 0.0962 - val_accuracy: 0.9681\n",
            "Epoch 463/500\n",
            "381/381 [==============================] - 0s 122us/sample - loss: 0.0473 - accuracy: 0.9869 - val_loss: 0.0966 - val_accuracy: 0.9681\n",
            "Epoch 464/500\n",
            "381/381 [==============================] - 0s 125us/sample - loss: 0.0473 - accuracy: 0.9869 - val_loss: 0.0968 - val_accuracy: 0.9681\n",
            "Epoch 465/500\n",
            "381/381 [==============================] - 0s 115us/sample - loss: 0.0473 - accuracy: 0.9869 - val_loss: 0.0962 - val_accuracy: 0.9681\n",
            "Epoch 466/500\n",
            "381/381 [==============================] - 0s 132us/sample - loss: 0.0472 - accuracy: 0.9869 - val_loss: 0.0967 - val_accuracy: 0.9681\n",
            "Epoch 467/500\n",
            "381/381 [==============================] - 0s 117us/sample - loss: 0.0472 - accuracy: 0.9869 - val_loss: 0.0967 - val_accuracy: 0.9681\n",
            "Epoch 468/500\n",
            "381/381 [==============================] - 0s 117us/sample - loss: 0.0472 - accuracy: 0.9869 - val_loss: 0.0964 - val_accuracy: 0.9681\n",
            "Epoch 469/500\n",
            "381/381 [==============================] - 0s 117us/sample - loss: 0.0474 - accuracy: 0.9869 - val_loss: 0.0981 - val_accuracy: 0.9681\n",
            "Epoch 470/500\n",
            "381/381 [==============================] - 0s 119us/sample - loss: 0.0471 - accuracy: 0.9869 - val_loss: 0.0975 - val_accuracy: 0.9681\n",
            "Epoch 471/500\n",
            "381/381 [==============================] - 0s 124us/sample - loss: 0.0471 - accuracy: 0.9869 - val_loss: 0.0978 - val_accuracy: 0.9681\n",
            "Epoch 472/500\n",
            "381/381 [==============================] - 0s 132us/sample - loss: 0.0470 - accuracy: 0.9869 - val_loss: 0.0977 - val_accuracy: 0.9681\n",
            "Epoch 473/500\n",
            "381/381 [==============================] - 0s 120us/sample - loss: 0.0470 - accuracy: 0.9869 - val_loss: 0.0973 - val_accuracy: 0.9681\n",
            "Epoch 474/500\n",
            "381/381 [==============================] - 0s 127us/sample - loss: 0.0471 - accuracy: 0.9869 - val_loss: 0.0983 - val_accuracy: 0.9681\n",
            "Epoch 475/500\n",
            "381/381 [==============================] - 0s 128us/sample - loss: 0.0469 - accuracy: 0.9869 - val_loss: 0.0980 - val_accuracy: 0.9681\n",
            "Epoch 476/500\n",
            "381/381 [==============================] - 0s 137us/sample - loss: 0.0469 - accuracy: 0.9869 - val_loss: 0.0983 - val_accuracy: 0.9681\n",
            "Epoch 477/500\n",
            "381/381 [==============================] - 0s 143us/sample - loss: 0.0469 - accuracy: 0.9869 - val_loss: 0.0981 - val_accuracy: 0.9681\n",
            "Epoch 478/500\n",
            "381/381 [==============================] - 0s 117us/sample - loss: 0.0469 - accuracy: 0.9869 - val_loss: 0.0990 - val_accuracy: 0.9681\n",
            "Epoch 479/500\n",
            "381/381 [==============================] - 0s 112us/sample - loss: 0.0468 - accuracy: 0.9869 - val_loss: 0.0988 - val_accuracy: 0.9681\n",
            "Epoch 480/500\n",
            "381/381 [==============================] - 0s 118us/sample - loss: 0.0468 - accuracy: 0.9869 - val_loss: 0.0986 - val_accuracy: 0.9681\n",
            "Epoch 481/500\n",
            "381/381 [==============================] - 0s 110us/sample - loss: 0.0468 - accuracy: 0.9869 - val_loss: 0.0992 - val_accuracy: 0.9681\n",
            "Epoch 482/500\n",
            "381/381 [==============================] - 0s 114us/sample - loss: 0.0467 - accuracy: 0.9869 - val_loss: 0.0989 - val_accuracy: 0.9681\n",
            "Epoch 483/500\n",
            "381/381 [==============================] - 0s 127us/sample - loss: 0.0467 - accuracy: 0.9869 - val_loss: 0.0993 - val_accuracy: 0.9681\n",
            "Epoch 484/500\n",
            "381/381 [==============================] - 0s 118us/sample - loss: 0.0466 - accuracy: 0.9869 - val_loss: 0.0993 - val_accuracy: 0.9681\n",
            "Epoch 485/500\n",
            "381/381 [==============================] - 0s 116us/sample - loss: 0.0467 - accuracy: 0.9869 - val_loss: 0.0988 - val_accuracy: 0.9681\n",
            "Epoch 486/500\n",
            "381/381 [==============================] - 0s 113us/sample - loss: 0.0466 - accuracy: 0.9869 - val_loss: 0.0993 - val_accuracy: 0.9681\n",
            "Epoch 487/500\n",
            "381/381 [==============================] - 0s 110us/sample - loss: 0.0466 - accuracy: 0.9869 - val_loss: 0.0987 - val_accuracy: 0.9681\n",
            "Epoch 488/500\n",
            "381/381 [==============================] - 0s 119us/sample - loss: 0.0465 - accuracy: 0.9869 - val_loss: 0.0994 - val_accuracy: 0.9681\n",
            "Epoch 489/500\n",
            "381/381 [==============================] - 0s 119us/sample - loss: 0.0466 - accuracy: 0.9869 - val_loss: 0.0995 - val_accuracy: 0.9681\n",
            "Epoch 490/500\n",
            "381/381 [==============================] - 0s 114us/sample - loss: 0.0465 - accuracy: 0.9869 - val_loss: 0.1001 - val_accuracy: 0.9681\n",
            "Epoch 491/500\n",
            "381/381 [==============================] - 0s 119us/sample - loss: 0.0465 - accuracy: 0.9869 - val_loss: 0.1004 - val_accuracy: 0.9681\n",
            "Epoch 492/500\n",
            "381/381 [==============================] - 0s 122us/sample - loss: 0.0464 - accuracy: 0.9869 - val_loss: 0.1004 - val_accuracy: 0.9681\n",
            "Epoch 493/500\n",
            "381/381 [==============================] - 0s 135us/sample - loss: 0.0464 - accuracy: 0.9869 - val_loss: 0.0998 - val_accuracy: 0.9681\n",
            "Epoch 494/500\n",
            "381/381 [==============================] - 0s 115us/sample - loss: 0.0463 - accuracy: 0.9869 - val_loss: 0.1001 - val_accuracy: 0.9681\n",
            "Epoch 495/500\n",
            "381/381 [==============================] - 0s 124us/sample - loss: 0.0464 - accuracy: 0.9869 - val_loss: 0.1010 - val_accuracy: 0.9681\n",
            "Epoch 496/500\n",
            "381/381 [==============================] - 0s 121us/sample - loss: 0.0463 - accuracy: 0.9869 - val_loss: 0.1008 - val_accuracy: 0.9681\n",
            "Epoch 497/500\n",
            "381/381 [==============================] - 0s 127us/sample - loss: 0.0463 - accuracy: 0.9869 - val_loss: 0.1015 - val_accuracy: 0.9681\n",
            "Epoch 498/500\n",
            "381/381 [==============================] - 0s 118us/sample - loss: 0.0462 - accuracy: 0.9869 - val_loss: 0.1009 - val_accuracy: 0.9681\n",
            "Epoch 499/500\n",
            "381/381 [==============================] - 0s 151us/sample - loss: 0.0462 - accuracy: 0.9869 - val_loss: 0.1015 - val_accuracy: 0.9681\n",
            "Epoch 500/500\n",
            "381/381 [==============================] - 0s 142us/sample - loss: 0.0462 - accuracy: 0.9869 - val_loss: 0.1014 - val_accuracy: 0.9681\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nl7GVx7ZVxa-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "ac447bbe-442b-4090-e305-21b0f024bf89"
      },
      "source": [
        "print('Training Accuracy: {}'.format(model.evaluate(X_train, Y_train)))\n",
        "print('Testing Accuracy: {}'.format(model.evaluate(X_test, Y_test)))\n",
        "\n",
        "# # Evaluate the model - evaluate() returns loss and accuracy\n",
        "# print(\"Train score:\", model.evaluate(X_train, Y_train))\n",
        "# print(\"Test score:\", model.evaluate(X_test, Y_test))"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "381/381 [==============================] - 0s 71us/sample - loss: 0.0460 - accuracy: 0.9869\n",
            "Training Accuracy: [0.04604372030168068, 0.98687667]\n",
            "188/188 [==============================] - 0s 74us/sample - loss: 0.1014 - accuracy: 0.9681\n",
            "Testing Accuracy: [0.1014460341093388, 0.9680851]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7D0VaZNrXev0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "e403c491-6b58-4fdf-d641-efe6c209dc55"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(result.history['loss'], label='loss')\n",
        "plt.plot(result.history['val_loss'], label='val_loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEGCAYAAABo25JHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RyhFsUefcjxh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "73c11f1e-401f-4086-a4f6-f9d141310f4b"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(result.history['accuracy'], label='accuracy')\n",
        "plt.plot(result.history['val_accuracy'], label='val_accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEJCAYAAACOr7BbAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nO90AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MoxHh_Exctpx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}