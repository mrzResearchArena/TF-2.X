{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Multi-Input-TF-Check.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOGQMovFVrlUEn4Eb918c64",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mrzResearchArena/TF-2.X/blob/master/Multi-Input-TF-Check.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TGnvhibSIA6o",
        "colab_type": "code",
        "outputId": "b90c72c2-7eb2-437c-c577-220a886b0ebc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sp4rVybRIELr",
        "colab_type": "code",
        "outputId": "6bf2df2a-c70b-48fb-bb9a-9bbcb2534679",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 675
        }
      },
      "source": [
        "ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0_FINAL_anti_peptide_model_AC240-tensorboard.ipynb\n",
            "0_FINAL_anti_peptide_model_ACP740-tensorboard.ipynb\n",
            "500-164.h5\n",
            "544_encoded_sequences_740.npy\n",
            "ACP164.npy\n",
            "ACP240_labels.npy\n",
            "acp240.txt\n",
            "ACP-500-164.h5\n",
            "ACP500.npy\n",
            "ACP740_labels.npy\n",
            "ACP-740-tensorboard.ipynb\n",
            "acp740.txt\n",
            "blosum-164.npy\n",
            "blosum-500.npy\n",
            "blosum62-acp240.npy\n",
            "blosum62-acp740.npy\n",
            "bpf-164.npy\n",
            "bpf-500.npy\n",
            "BPF_coded_ACP164_sequences.npy\n",
            "BPF_coded_ACP240_sequences.npy\n",
            "BPF_coded_ACP500_sequences.npy\n",
            "BPF_coded_ACP740_sequences.npy\n",
            "kmer_k_3_ACP240.npy\n",
            "kmer_k_3_ACP740.npy\n",
            "\u001b[0m\u001b[01;34mlogs\u001b[0m/\n",
            "mACP-240.ipynb\n",
            "mACP-740.ipynb\n",
            "model-240.png\n",
            "model-500-164.png\n",
            "model-740.png\n",
            "model.png\n",
            "multichannel.png\n",
            "physico_coded_ACP164_sequences.npy\n",
            "physico_coded_ACP240_sequences.npy\n",
            "physico_coded_ACP500_sequences.npy\n",
            "physico_coded_ACP740_sequences.npy\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MbbcEO-LINt-",
        "colab_type": "code",
        "outputId": "a985fd91-53ad-48b6-901e-bd991fb95259",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "cd 'drive/My Drive/Colab-Notebooks'"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Errno 2] No such file or directory: 'drive/My Drive/Colab-Notebooks'\n",
            "/content/drive/My Drive/Colab-Notebooks\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "By81lz6mida-",
        "colab_type": "code",
        "outputId": "6b6dacf6-f64b-40d2-f528-64cca1bd2cec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "pwd"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/My Drive/Colab-Notebooks'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vwj9rrDoIVkH",
        "colab_type": "code",
        "outputId": "c21e876e-0bbc-4a7d-954b-1af7f61e399e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 675
        }
      },
      "source": [
        "ls -1"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0_FINAL_anti_peptide_model_AC240-tensorboard.ipynb\n",
            "0_FINAL_anti_peptide_model_ACP740-tensorboard.ipynb\n",
            "500-164.h5\n",
            "544_encoded_sequences_740.npy\n",
            "ACP164.npy\n",
            "ACP240_labels.npy\n",
            "acp240.txt\n",
            "ACP-500-164.h5\n",
            "ACP500.npy\n",
            "ACP740_labels.npy\n",
            "ACP-740-tensorboard.ipynb\n",
            "acp740.txt\n",
            "blosum-164.npy\n",
            "blosum-500.npy\n",
            "blosum62-acp240.npy\n",
            "blosum62-acp740.npy\n",
            "bpf-164.npy\n",
            "bpf-500.npy\n",
            "BPF_coded_ACP164_sequences.npy\n",
            "BPF_coded_ACP240_sequences.npy\n",
            "BPF_coded_ACP500_sequences.npy\n",
            "BPF_coded_ACP740_sequences.npy\n",
            "kmer_k_3_ACP240.npy\n",
            "kmer_k_3_ACP740.npy\n",
            "\u001b[0m\u001b[01;34mlogs\u001b[0m/\n",
            "mACP-240.ipynb\n",
            "mACP-740.ipynb\n",
            "model-240.png\n",
            "model-500-164.png\n",
            "model-740.png\n",
            "model.png\n",
            "multichannel.png\n",
            "physico_coded_ACP164_sequences.npy\n",
            "physico_coded_ACP240_sequences.npy\n",
            "physico_coded_ACP500_sequences.npy\n",
            "physico_coded_ACP740_sequences.npy\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mHLZUD-ZIWiZ",
        "colab_type": "code",
        "outputId": "4ed9f2b2-3d1d-4646-bc41-881b3348f49c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        }
      },
      "source": [
        "# Initialize TF-2.x:\n",
        "try:\n",
        "    %tensorflow_version 2.x  # Colab only.\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "import tensorflow as tf\n",
        "print('We\\'re using TF-{}.'.format(tf.__version__))\n",
        "\n",
        "# Colab Auto Click: [https://paste.ubuntu.com/p/R78fGBJbjb/]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "`%tensorflow_version` only switches the major version: 1.x or 2.x.\n",
            "You set: `2.x  # Colab only.`. This will be interpreted as: `2.x`.\n",
            "\n",
            "\n",
            "TensorFlow is already loaded. Please restart the runtime to change versions.\n",
            "We're using TF-2.1.0.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CnOvHMSHIdCF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Deep Neural Networks:\n",
        "from tensorflow.keras.layers import (Input, Dense, Dropout, Flatten, BatchNormalization,\n",
        "                                     Conv1D, Conv2D, MaxPooling1D, MaxPooling2D,\n",
        "                                     LSTM, GRU, Embedding, Bidirectional, concatenate)\n",
        "from tensorflow.keras.regularizers import (l1, l2, l1_l2)\n",
        "from tensorflow.keras.optimizers import (RMSprop, Adam, SGD)\n",
        "from tensorflow.keras.models import (Sequential, Model)\n",
        "\n",
        "# Core:\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Performance:\n",
        "from sklearn.metrics import (confusion_matrix, classification_report, matthews_corrcoef, precision_score)\n",
        "\n",
        "#Utilities:\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.utils import to_categorical as labelEncoding   # Usages: Ytrain = labelEncoding(Ytrain, dtype=int)\n",
        "from tensorflow.keras.utils import plot_model                        # Usages: plot_model(model, to_file='model.png', show_shapes=True, show_layer_names=False, expand_nested=True)\n",
        "from sklearn.model_selection import (StratifiedKFold, KFold, train_test_split)\n",
        "#end-import"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gN_BfPY_ctFx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def lossPlot(results):\n",
        "    plt.title(label='Loss: Training and Validation')\n",
        "    plt.plot(results.history['loss'], label='Training Loss')\n",
        "    plt.plot(results.history['val_loss'], label='Validation Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "#end-def\n",
        "\n",
        "def accuracyPlot(results):\n",
        "    plt.title(label='Accuracy: Training and Validation')\n",
        "    plt.plot(results.history['accuracy'], label='Training Accuracy')\n",
        "    plt.plot(results.history['val_accuracy'], label='Validation Accuracy')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "#end-def"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M5DdY661I25F",
        "colab_type": "code",
        "outputId": "5e25b63f-130b-49e6-c26e-5be73a69b3fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 273
        }
      },
      "source": [
        "# D = 20    # terminus_length\n",
        "\n",
        "X1train = np.load('bpf-500.npy')\n",
        "X2train = np.load('physico_coded_ACP500_sequences.npy')\n",
        "X3train = np.load('blosum-500.npy')\n",
        "\n",
        "# X3train = X3train.reshape(-1, 20, 11)\n",
        "\n",
        "print(X1train.shape)\n",
        "print(X2train.shape)\n",
        "print(X3train.shape)\n",
        "print('### --- --- --- --- --- ###')\n",
        "\n",
        "X2train = X2train[:,:,0:20]\n",
        "\n",
        "print(X1train.shape)\n",
        "print(X2train.shape)\n",
        "print(X3train.shape)\n",
        "\n",
        "### -----------------------------------------------------\n",
        "X1test = np.load('bpf-164.npy')\n",
        "X2test = np.load('physico_coded_ACP164_sequences.npy')\n",
        "X3test = np.load('blosum-164.npy')\n",
        "\n",
        "print(X1test.shape)\n",
        "print(X2test.shape)\n",
        "print(X3test.shape)\n",
        "\n",
        "X2test = X2test[:,:,0:20]\n",
        "\n",
        "print(X1test.shape)\n",
        "print(X2test.shape)\n",
        "print(X3test.shape)\n",
        "\n",
        "print('### --- --- --- --- --- ###')\n",
        "\n",
        "# ACP {500, 164}\n",
        "Ytrain  = [0 for _ in range(250)]\n",
        "Ytrain += [1 for _ in range(250)]\n",
        "Ytrain  = np.array(Ytrain)\n",
        "\n",
        "Ytest  = [0 for _ in range(82)]\n",
        "Ytest += [1 for _ in range(82)]\n",
        "\n",
        "\n",
        "Ytrain = labelEncoding(Ytrain, dtype=int)\n",
        "Ytest  = labelEncoding(Ytest, dtype=int)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(500, 20, 25)\n",
            "(500, 7, 207)\n",
            "(500, 20, 25)\n",
            "### --- --- --- --- --- ###\n",
            "(500, 20, 25)\n",
            "(500, 7, 20)\n",
            "(500, 20, 25)\n",
            "(164, 20, 25)\n",
            "(164, 7, 207)\n",
            "(164, 20, 25)\n",
            "(164, 20, 25)\n",
            "(164, 7, 20)\n",
            "(164, 20, 25)\n",
            "### --- --- --- --- --- ###\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lkkFRE20Kxg6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# def Network():\n",
        "#     ### Head-1:\n",
        "#     input1 = Input(shape=(20, 25)) # T=20\n",
        "\n",
        "#     x = Conv1D(filters=8, kernel_size=3, padding='same', data_format='channels_first', activation='relu', kernel_regularizer=l2(l=0.01))(input1)\n",
        "#     x = BatchNormalization()(x)\n",
        "#     x = Dropout(rate=0.50)(x)\n",
        "\n",
        "#     x = Conv1D(filters=6, kernel_size=3, padding='same', data_format='channels_first', activation='relu', kernel_regularizer=l2(l=0.01))(x)\n",
        "#     x = BatchNormalization()(x)\n",
        "#     x = Dropout(rate=0.50)(x)\n",
        "\n",
        "#     head1 = Flatten()(x)\n",
        "\n",
        "\n",
        "#     # ### Head-2:\n",
        "#     input2 = Input(shape=(7, 20)) # T=7\n",
        "\n",
        "#     x = Conv1D(filters=8, kernel_size=3, padding='same', data_format='channels_first', activation='relu', kernel_regularizer=l2(l=0.01))(input2)\n",
        "#     x = BatchNormalization()(x)\n",
        "#     x = Dropout(rate=0.50)(x)\n",
        "\n",
        "#     x = Conv1D(filters=6, kernel_size=3, padding='same', data_format='channels_first', activation='relu', kernel_regularizer=l2(l=0.01))(x)\n",
        "#     x = BatchNormalization()(x)\n",
        "#     x = Dropout(rate=0.50)(x)\n",
        "\n",
        "#     head2 = Flatten()(x)\n",
        "\n",
        "\n",
        "#     # ### Head-3:\n",
        "#     input3 = Input(shape=(20, 25))\n",
        "\n",
        "#     x = Conv1D(filters=8, kernel_size=3, padding='same', data_format='channels_first', activation='relu', kernel_regularizer=l2(l=0.01))(x)\n",
        "#     x = BatchNormalization()(x)\n",
        "#     x = Dropout(rate=0.50)(x)\n",
        "\n",
        "#     x = Conv1D(filters=6, kernel_size=3, padding='same', data_format='channels_first', activation='relu', kernel_regularizer=l2(l=0.01))(x)\n",
        "#     x = BatchNormalization()(x)\n",
        "#     x = Dropout(rate=0.50)(x)\n",
        "\n",
        "#     head3 = Flatten()(x)\n",
        "\n",
        "#     # merge\n",
        "#     merge = concatenate(inputs=[head1, head2, head3])\n",
        "    \n",
        "#     #o = Dense(units=12, activation='relu',)(merge)\n",
        "#     #o = BatchNormalization()(o)\n",
        "#     #o = Dropout(rate=0.60)(o)\n",
        "    \n",
        "#     o = Dense(units=6, activation='relu',)(merge)\n",
        "#     o = BatchNormalization()(o)\n",
        "#     o = Dropout(rate=0.50)(o)\n",
        "\n",
        "#     output = Dense(units=2, activation='softmax')(o)\n",
        "\n",
        "#     return Model(inputs=[input1, input2, input3], outputs=[output])\n",
        "# #end-def\n",
        "\n",
        "\n",
        "def Network():\n",
        "    ### Head-1:\n",
        "    # input1 = Input(shape=(20, 25)) # T=20\n",
        "\n",
        "    # x = Conv1D(filters=8, kernel_size=3, padding='same', data_format='channels_first', activation='relu', kernel_regularizer=l2(l=0.01))(input1)\n",
        "    # x = BatchNormalization()(x)\n",
        "    # x = Dropout(rate=0.50)(x)\n",
        "\n",
        "    # x = Conv1D(filters=6, kernel_size=3, padding='same', data_format='channels_first', activation='relu', kernel_regularizer=l2(l=0.01))(x)\n",
        "    # x = BatchNormalization()(x)\n",
        "    # x = Dropout(rate=0.50)(x)\n",
        "\n",
        "    # head1 = Flatten()(x)\n",
        "\n",
        "\n",
        "    # # ### Head-2:\n",
        "    # input2 = Input(shape=(7, 20)) # T=7\n",
        "\n",
        "    # x = Conv1D(filters=8, kernel_size=3, padding='same', data_format='channels_first', activation='relu', kernel_regularizer=l2(l=0.01))(input2)\n",
        "    # x = BatchNormalization()(x)\n",
        "    # x = Dropout(rate=0.50)(x)\n",
        "\n",
        "    # x = Conv1D(filters=6, kernel_size=3, padding='same', data_format='channels_first', activation='relu', kernel_regularizer=l2(l=0.01))(x)\n",
        "    # x = BatchNormalization()(x)\n",
        "    # x = Dropout(rate=0.50)(x)\n",
        "\n",
        "    # head2 = Flatten()(x)\n",
        "\n",
        "\n",
        "    # ### Head-3:\n",
        "    input1 = Input(shape=(20, 25))\n",
        "\n",
        "    x = Conv1D(filters=10, kernel_size=3, padding='same', data_format='channels_first', activation='relu', kernel_regularizer=l2(l=0.01))(input1)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Dropout(rate=0.60)(x)\n",
        "\n",
        "\n",
        "    x = Conv1D(filters=8, kernel_size=3, padding='same', data_format='channels_first', activation='relu', kernel_regularizer=l2(l=0.01))(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Dropout(rate=0.60)(x)\n",
        "\n",
        "    x = Conv1D(filters=6, kernel_size=3, padding='same', data_format='channels_first', activation='relu', kernel_regularizer=l2(l=0.01))(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Dropout(rate=0.60)(x)\n",
        "\n",
        "    x = Flatten()(x)\n",
        "\n",
        "    output = Dense(units=2, activation='softmax')(x)\n",
        "\n",
        "    return Model(inputs=[input1], outputs=[output])\n",
        "#end-def"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ReDra35kLP5F",
        "colab_type": "code",
        "outputId": "18b01d97-41ca-454e-9a16-74b95d39ade2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model = Network()\n",
        "model.summary()\n",
        "plot_model(model, to_file='model-500-164.png', show_shapes=True, show_layer_names=False, expand_nested=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_10\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_28 (InputLayer)        [(None, 20, 25)]          0         \n",
            "_________________________________________________________________\n",
            "conv1d_71 (Conv1D)           (None, 10, 25)            610       \n",
            "_________________________________________________________________\n",
            "batch_normalization_87 (Batc (None, 10, 25)            100       \n",
            "_________________________________________________________________\n",
            "dropout_87 (Dropout)         (None, 10, 25)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_72 (Conv1D)           (None, 8, 25)             248       \n",
            "_________________________________________________________________\n",
            "batch_normalization_88 (Batc (None, 8, 25)             100       \n",
            "_________________________________________________________________\n",
            "dropout_88 (Dropout)         (None, 8, 25)             0         \n",
            "_________________________________________________________________\n",
            "conv1d_73 (Conv1D)           (None, 6, 25)             150       \n",
            "_________________________________________________________________\n",
            "batch_normalization_89 (Batc (None, 6, 25)             100       \n",
            "_________________________________________________________________\n",
            "dropout_89 (Dropout)         (None, 6, 25)             0         \n",
            "_________________________________________________________________\n",
            "flatten_27 (Flatten)         (None, 150)               0         \n",
            "_________________________________________________________________\n",
            "dense_27 (Dense)             (None, 2)                 302       \n",
            "=================================================================\n",
            "Total params: 1,610\n",
            "Trainable params: 1,460\n",
            "Non-trainable params: 150\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW0AAAULCAYAAADm4/N2AAAABmJLR0QA/wD/AP+gvaeTAAAgAElE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\nCCEezP8BXmCvT17y0oYAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tRKjAVPmLU54",
        "colab_type": "code",
        "outputId": "62625426-c200-4e4a-a15b-f0acffa472a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Setting epoch and batch number\n",
        "setEpochNumber     = 1000       ### 2,500 performed well!\n",
        "setBatchSizeNumber = 10\n",
        "\n",
        "# Compile Model:\n",
        "model = Network()\n",
        "model.compile(optimizer=Adam(lr=0.0005),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Run Model:\n",
        "# results = model.fit(x=[X1train, X2train, X3train],\n",
        "#                     y=[Ytrain], \n",
        "#                     validation_data=([X1test, X2test, X3test], [Ytest]),\n",
        "#                     epochs=setEpochNumber,\n",
        "#                     batch_size=setBatchSizeNumber,\n",
        "#                     verbose=1)\n",
        "\n",
        "\n",
        "# # Performance Metices:\n",
        "# Yactual = Ytest.argmax(axis=1)\n",
        "# Yp = model.predict([X1test, X2test, X3test])\n",
        "# Yp = Yp.argmax(axis=1)\n",
        "\n",
        "# CM = confusion_matrix(y_pred=Yp, y_true=Yactual)\n",
        "# TN, FP, FN, TP = CM.ravel()\n",
        "\n",
        "# print()\n",
        "# print('Accuracy: {:.2f}'.format(accuracy))\n",
        "# print('MCC: {:.2f}'.format(matthews_corrcoef(y_true=Yactual, y_pred=Yp)))\n",
        "# print('Sensitivity: {0:.4f}'.format(TP / (TP + FN)))\n",
        "# print('Specificity: {0:.4f}'.format(TN / (TN + FP)))\n",
        "# print('Precision: {0:.4f}'.format(precision_score(y_true=Yactual, y_pred=Yp)))\n",
        "# print()\n",
        "\n",
        "# # Performance Plot\n",
        "# lossPlot(results)\n",
        "# accuracyPlot(results)\n",
        "\n",
        "\n",
        "results = model.fit(x=[X3train],\n",
        "                    y=[Ytrain], \n",
        "                    validation_data=([X3test], [Ytest]),\n",
        "                    epochs=setEpochNumber,\n",
        "                    batch_size=setBatchSizeNumber,\n",
        "                    verbose=1)\n",
        "\n",
        "\n",
        "# Evaluate the Model:\n",
        "_, accuracy = model.evaluate(x=[X3test], y=Ytest, batch_size=setBatchSizeNumber)\n",
        "\n",
        "\n",
        "# Performance Metices:\n",
        "Yactual = Ytest.argmax(axis=1)\n",
        "Yp = model.predict([X3test])\n",
        "Yp = Yp.argmax(axis=1)\n",
        "\n",
        "CM = confusion_matrix(y_pred=Yp, y_true=Yactual)\n",
        "TN, FP, FN, TP = CM.ravel()\n",
        "\n",
        "print()\n",
        "print('Accuracy: {:.2f}'.format(accuracy))\n",
        "print('MCC: {:.2f}'.format(matthews_corrcoef(y_true=Yactual, y_pred=Yp)))\n",
        "print('Sensitivity: {0:.4f}'.format(TP / (TP + FN)))\n",
        "print('Specificity: {0:.4f}'.format(TN / (TN + FP)))\n",
        "print('Precision: {0:.4f}'.format(precision_score(y_true=Yactual, y_pred=Yp)))\n",
        "print()\n",
        "\n",
        "# Performance Plot\n",
        "lossPlot(results)\n",
        "accuracyPlot(results)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 500 samples, validate on 164 samples\n",
            "Epoch 1/1000\n",
            "500/500 [==============================] - 1s 3ms/sample - loss: 1.8208 - accuracy: 0.4960 - val_loss: 1.3009 - val_accuracy: 0.4451\n",
            "Epoch 2/1000\n",
            "500/500 [==============================] - 0s 548us/sample - loss: 1.6640 - accuracy: 0.5040 - val_loss: 1.1426 - val_accuracy: 0.4207\n",
            "Epoch 3/1000\n",
            "500/500 [==============================] - 0s 637us/sample - loss: 1.5203 - accuracy: 0.5280 - val_loss: 1.0818 - val_accuracy: 0.5000\n",
            "Epoch 4/1000\n",
            "500/500 [==============================] - 0s 619us/sample - loss: 1.5274 - accuracy: 0.5220 - val_loss: 1.0512 - val_accuracy: 0.5000\n",
            "Epoch 5/1000\n",
            "500/500 [==============================] - 0s 541us/sample - loss: 1.4633 - accuracy: 0.5120 - val_loss: 1.0335 - val_accuracy: 0.5061\n",
            "Epoch 6/1000\n",
            "500/500 [==============================] - 0s 612us/sample - loss: 1.3641 - accuracy: 0.5580 - val_loss: 1.0223 - val_accuracy: 0.5244\n",
            "Epoch 7/1000\n",
            "500/500 [==============================] - 0s 687us/sample - loss: 1.3777 - accuracy: 0.5020 - val_loss: 1.0127 - val_accuracy: 0.5244\n",
            "Epoch 8/1000\n",
            "500/500 [==============================] - 0s 559us/sample - loss: 1.3394 - accuracy: 0.5460 - val_loss: 1.0033 - val_accuracy: 0.5305\n",
            "Epoch 9/1000\n",
            "500/500 [==============================] - 0s 519us/sample - loss: 1.2736 - accuracy: 0.5220 - val_loss: 0.9933 - val_accuracy: 0.5244\n",
            "Epoch 10/1000\n",
            "500/500 [==============================] - 0s 539us/sample - loss: 1.2844 - accuracy: 0.5220 - val_loss: 0.9857 - val_accuracy: 0.5183\n",
            "Epoch 11/1000\n",
            "500/500 [==============================] - 0s 618us/sample - loss: 1.1370 - accuracy: 0.5340 - val_loss: 0.9774 - val_accuracy: 0.5488\n",
            "Epoch 12/1000\n",
            "500/500 [==============================] - 0s 526us/sample - loss: 1.2326 - accuracy: 0.5240 - val_loss: 0.9723 - val_accuracy: 0.5427\n",
            "Epoch 13/1000\n",
            "500/500 [==============================] - 0s 595us/sample - loss: 1.1830 - accuracy: 0.5280 - val_loss: 0.9660 - val_accuracy: 0.5305\n",
            "Epoch 14/1000\n",
            "500/500 [==============================] - 0s 667us/sample - loss: 1.1219 - accuracy: 0.5420 - val_loss: 0.9633 - val_accuracy: 0.5610\n",
            "Epoch 15/1000\n",
            "500/500 [==============================] - 0s 573us/sample - loss: 1.1445 - accuracy: 0.5320 - val_loss: 0.9595 - val_accuracy: 0.5488\n",
            "Epoch 16/1000\n",
            "500/500 [==============================] - 0s 674us/sample - loss: 1.0133 - accuracy: 0.5620 - val_loss: 0.9551 - val_accuracy: 0.5427\n",
            "Epoch 17/1000\n",
            "500/500 [==============================] - 0s 616us/sample - loss: 1.1094 - accuracy: 0.5520 - val_loss: 0.9478 - val_accuracy: 0.5427\n",
            "Epoch 18/1000\n",
            "500/500 [==============================] - 0s 660us/sample - loss: 1.0830 - accuracy: 0.5340 - val_loss: 0.9445 - val_accuracy: 0.5549\n",
            "Epoch 19/1000\n",
            "500/500 [==============================] - 0s 630us/sample - loss: 0.9811 - accuracy: 0.5880 - val_loss: 0.9381 - val_accuracy: 0.5671\n",
            "Epoch 20/1000\n",
            "500/500 [==============================] - 0s 628us/sample - loss: 1.0088 - accuracy: 0.5740 - val_loss: 0.9353 - val_accuracy: 0.5732\n",
            "Epoch 21/1000\n",
            "500/500 [==============================] - 0s 664us/sample - loss: 1.0454 - accuracy: 0.5340 - val_loss: 0.9314 - val_accuracy: 0.5732\n",
            "Epoch 22/1000\n",
            "500/500 [==============================] - 0s 507us/sample - loss: 0.9725 - accuracy: 0.5780 - val_loss: 0.9298 - val_accuracy: 0.5549\n",
            "Epoch 23/1000\n",
            "500/500 [==============================] - 0s 528us/sample - loss: 0.9789 - accuracy: 0.6000 - val_loss: 0.9242 - val_accuracy: 0.5549\n",
            "Epoch 24/1000\n",
            "500/500 [==============================] - 0s 593us/sample - loss: 0.9953 - accuracy: 0.5820 - val_loss: 0.9224 - val_accuracy: 0.5671\n",
            "Epoch 25/1000\n",
            "500/500 [==============================] - 0s 628us/sample - loss: 0.9741 - accuracy: 0.5560 - val_loss: 0.9228 - val_accuracy: 0.5488\n",
            "Epoch 26/1000\n",
            "500/500 [==============================] - 0s 607us/sample - loss: 0.9486 - accuracy: 0.5880 - val_loss: 0.9211 - val_accuracy: 0.5610\n",
            "Epoch 27/1000\n",
            "500/500 [==============================] - 0s 630us/sample - loss: 0.9525 - accuracy: 0.5760 - val_loss: 0.9179 - val_accuracy: 0.5671\n",
            "Epoch 28/1000\n",
            "500/500 [==============================] - 0s 576us/sample - loss: 0.9574 - accuracy: 0.5780 - val_loss: 0.9170 - val_accuracy: 0.5488\n",
            "Epoch 29/1000\n",
            "500/500 [==============================] - 0s 502us/sample - loss: 0.9295 - accuracy: 0.6040 - val_loss: 0.9114 - val_accuracy: 0.5976\n",
            "Epoch 30/1000\n",
            "500/500 [==============================] - 0s 497us/sample - loss: 0.9609 - accuracy: 0.5580 - val_loss: 0.9106 - val_accuracy: 0.5732\n",
            "Epoch 31/1000\n",
            "500/500 [==============================] - 0s 590us/sample - loss: 0.9238 - accuracy: 0.5820 - val_loss: 0.9106 - val_accuracy: 0.5671\n",
            "Epoch 32/1000\n",
            "500/500 [==============================] - 0s 576us/sample - loss: 0.9270 - accuracy: 0.5920 - val_loss: 0.9103 - val_accuracy: 0.5610\n",
            "Epoch 33/1000\n",
            "500/500 [==============================] - 0s 598us/sample - loss: 0.9134 - accuracy: 0.5800 - val_loss: 0.9055 - val_accuracy: 0.5610\n",
            "Epoch 34/1000\n",
            "500/500 [==============================] - 0s 620us/sample - loss: 0.9131 - accuracy: 0.6020 - val_loss: 0.8995 - val_accuracy: 0.5610\n",
            "Epoch 35/1000\n",
            "500/500 [==============================] - 0s 562us/sample - loss: 0.8891 - accuracy: 0.6200 - val_loss: 0.8947 - val_accuracy: 0.5610\n",
            "Epoch 36/1000\n",
            "500/500 [==============================] - 0s 499us/sample - loss: 0.9139 - accuracy: 0.5860 - val_loss: 0.8938 - val_accuracy: 0.5366\n",
            "Epoch 37/1000\n",
            "500/500 [==============================] - 0s 496us/sample - loss: 0.8926 - accuracy: 0.5960 - val_loss: 0.8967 - val_accuracy: 0.5549\n",
            "Epoch 38/1000\n",
            "500/500 [==============================] - 0s 558us/sample - loss: 0.8896 - accuracy: 0.5880 - val_loss: 0.8897 - val_accuracy: 0.5305\n",
            "Epoch 39/1000\n",
            "500/500 [==============================] - 0s 664us/sample - loss: 0.8739 - accuracy: 0.5980 - val_loss: 0.8883 - val_accuracy: 0.5488\n",
            "Epoch 40/1000\n",
            "500/500 [==============================] - 0s 631us/sample - loss: 0.8751 - accuracy: 0.6180 - val_loss: 0.8889 - val_accuracy: 0.5549\n",
            "Epoch 41/1000\n",
            "500/500 [==============================] - 0s 637us/sample - loss: 0.8639 - accuracy: 0.6340 - val_loss: 0.8861 - val_accuracy: 0.5427\n",
            "Epoch 42/1000\n",
            "500/500 [==============================] - 0s 652us/sample - loss: 0.8861 - accuracy: 0.5900 - val_loss: 0.8800 - val_accuracy: 0.5366\n",
            "Epoch 43/1000\n",
            "500/500 [==============================] - 0s 644us/sample - loss: 0.8697 - accuracy: 0.6280 - val_loss: 0.8728 - val_accuracy: 0.5427\n",
            "Epoch 44/1000\n",
            "500/500 [==============================] - 0s 640us/sample - loss: 0.8829 - accuracy: 0.5640 - val_loss: 0.8710 - val_accuracy: 0.5488\n",
            "Epoch 45/1000\n",
            "500/500 [==============================] - 0s 590us/sample - loss: 0.8644 - accuracy: 0.5940 - val_loss: 0.8695 - val_accuracy: 0.5366\n",
            "Epoch 46/1000\n",
            "500/500 [==============================] - 0s 554us/sample - loss: 0.8594 - accuracy: 0.6380 - val_loss: 0.8701 - val_accuracy: 0.5305\n",
            "Epoch 47/1000\n",
            "500/500 [==============================] - 0s 613us/sample - loss: 0.8463 - accuracy: 0.6300 - val_loss: 0.8679 - val_accuracy: 0.5305\n",
            "Epoch 48/1000\n",
            "500/500 [==============================] - 0s 547us/sample - loss: 0.8451 - accuracy: 0.6340 - val_loss: 0.8671 - val_accuracy: 0.5244\n",
            "Epoch 49/1000\n",
            "500/500 [==============================] - 0s 569us/sample - loss: 0.8322 - accuracy: 0.6420 - val_loss: 0.8615 - val_accuracy: 0.5305\n",
            "Epoch 50/1000\n",
            "500/500 [==============================] - 0s 599us/sample - loss: 0.8523 - accuracy: 0.5960 - val_loss: 0.8533 - val_accuracy: 0.5366\n",
            "Epoch 51/1000\n",
            "500/500 [==============================] - 0s 556us/sample - loss: 0.8360 - accuracy: 0.6220 - val_loss: 0.8479 - val_accuracy: 0.5427\n",
            "Epoch 52/1000\n",
            "500/500 [==============================] - 0s 612us/sample - loss: 0.8459 - accuracy: 0.6260 - val_loss: 0.8480 - val_accuracy: 0.5183\n",
            "Epoch 53/1000\n",
            "500/500 [==============================] - 0s 606us/sample - loss: 0.8203 - accuracy: 0.6320 - val_loss: 0.8455 - val_accuracy: 0.5305\n",
            "Epoch 54/1000\n",
            "500/500 [==============================] - 0s 502us/sample - loss: 0.8300 - accuracy: 0.6180 - val_loss: 0.8392 - val_accuracy: 0.5488\n",
            "Epoch 55/1000\n",
            "500/500 [==============================] - 0s 524us/sample - loss: 0.8268 - accuracy: 0.6340 - val_loss: 0.8313 - val_accuracy: 0.5488\n",
            "Epoch 56/1000\n",
            "500/500 [==============================] - 0s 587us/sample - loss: 0.8144 - accuracy: 0.6300 - val_loss: 0.8283 - val_accuracy: 0.5549\n",
            "Epoch 57/1000\n",
            "500/500 [==============================] - 0s 563us/sample - loss: 0.7954 - accuracy: 0.6260 - val_loss: 0.8216 - val_accuracy: 0.5610\n",
            "Epoch 58/1000\n",
            "500/500 [==============================] - 0s 583us/sample - loss: 0.7970 - accuracy: 0.6420 - val_loss: 0.8188 - val_accuracy: 0.5671\n",
            "Epoch 59/1000\n",
            "500/500 [==============================] - 0s 596us/sample - loss: 0.8066 - accuracy: 0.6220 - val_loss: 0.8148 - val_accuracy: 0.5549\n",
            "Epoch 60/1000\n",
            "500/500 [==============================] - 0s 536us/sample - loss: 0.8055 - accuracy: 0.6400 - val_loss: 0.8101 - val_accuracy: 0.5488\n",
            "Epoch 61/1000\n",
            "500/500 [==============================] - 0s 592us/sample - loss: 0.7950 - accuracy: 0.6440 - val_loss: 0.8010 - val_accuracy: 0.5854\n",
            "Epoch 62/1000\n",
            "500/500 [==============================] - 0s 517us/sample - loss: 0.7968 - accuracy: 0.6200 - val_loss: 0.7982 - val_accuracy: 0.5915\n",
            "Epoch 63/1000\n",
            "500/500 [==============================] - 0s 581us/sample - loss: 0.7847 - accuracy: 0.6480 - val_loss: 0.7980 - val_accuracy: 0.5976\n",
            "Epoch 64/1000\n",
            "500/500 [==============================] - 0s 635us/sample - loss: 0.7725 - accuracy: 0.6660 - val_loss: 0.7992 - val_accuracy: 0.5671\n",
            "Epoch 65/1000\n",
            "500/500 [==============================] - 0s 626us/sample - loss: 0.7853 - accuracy: 0.6220 - val_loss: 0.8032 - val_accuracy: 0.5610\n",
            "Epoch 66/1000\n",
            "500/500 [==============================] - 0s 551us/sample - loss: 0.7820 - accuracy: 0.6420 - val_loss: 0.8090 - val_accuracy: 0.5488\n",
            "Epoch 67/1000\n",
            "500/500 [==============================] - 0s 635us/sample - loss: 0.7730 - accuracy: 0.6520 - val_loss: 0.8081 - val_accuracy: 0.5427\n",
            "Epoch 68/1000\n",
            "500/500 [==============================] - 0s 643us/sample - loss: 0.7817 - accuracy: 0.6300 - val_loss: 0.8006 - val_accuracy: 0.5488\n",
            "Epoch 69/1000\n",
            "500/500 [==============================] - 0s 508us/sample - loss: 0.7818 - accuracy: 0.6320 - val_loss: 0.7889 - val_accuracy: 0.5732\n",
            "Epoch 70/1000\n",
            "500/500 [==============================] - 0s 667us/sample - loss: 0.7811 - accuracy: 0.6400 - val_loss: 0.7742 - val_accuracy: 0.5976\n",
            "Epoch 71/1000\n",
            "500/500 [==============================] - 0s 620us/sample - loss: 0.7708 - accuracy: 0.6540 - val_loss: 0.7705 - val_accuracy: 0.6037\n",
            "Epoch 72/1000\n",
            "500/500 [==============================] - 0s 539us/sample - loss: 0.7552 - accuracy: 0.6480 - val_loss: 0.7689 - val_accuracy: 0.5915\n",
            "Epoch 73/1000\n",
            "500/500 [==============================] - 0s 531us/sample - loss: 0.7471 - accuracy: 0.6260 - val_loss: 0.7649 - val_accuracy: 0.5854\n",
            "Epoch 74/1000\n",
            "500/500 [==============================] - 0s 615us/sample - loss: 0.7427 - accuracy: 0.6580 - val_loss: 0.7673 - val_accuracy: 0.5793\n",
            "Epoch 75/1000\n",
            "500/500 [==============================] - 0s 616us/sample - loss: 0.7476 - accuracy: 0.6620 - val_loss: 0.7602 - val_accuracy: 0.5915\n",
            "Epoch 76/1000\n",
            "500/500 [==============================] - 0s 630us/sample - loss: 0.7378 - accuracy: 0.6480 - val_loss: 0.7527 - val_accuracy: 0.5793\n",
            "Epoch 77/1000\n",
            "500/500 [==============================] - 0s 655us/sample - loss: 0.7404 - accuracy: 0.6380 - val_loss: 0.7553 - val_accuracy: 0.5915\n",
            "Epoch 78/1000\n",
            "500/500 [==============================] - 0s 591us/sample - loss: 0.7133 - accuracy: 0.6580 - val_loss: 0.7451 - val_accuracy: 0.5793\n",
            "Epoch 79/1000\n",
            "500/500 [==============================] - 0s 570us/sample - loss: 0.7076 - accuracy: 0.6700 - val_loss: 0.7458 - val_accuracy: 0.5854\n",
            "Epoch 80/1000\n",
            "500/500 [==============================] - 0s 513us/sample - loss: 0.7255 - accuracy: 0.6760 - val_loss: 0.7414 - val_accuracy: 0.5671\n",
            "Epoch 81/1000\n",
            "500/500 [==============================] - 0s 501us/sample - loss: 0.7071 - accuracy: 0.6900 - val_loss: 0.7270 - val_accuracy: 0.5671\n",
            "Epoch 82/1000\n",
            "500/500 [==============================] - 0s 525us/sample - loss: 0.7089 - accuracy: 0.6620 - val_loss: 0.7378 - val_accuracy: 0.5610\n",
            "Epoch 83/1000\n",
            "500/500 [==============================] - 0s 593us/sample - loss: 0.7154 - accuracy: 0.6500 - val_loss: 0.7385 - val_accuracy: 0.5854\n",
            "Epoch 84/1000\n",
            "500/500 [==============================] - 0s 517us/sample - loss: 0.7119 - accuracy: 0.6720 - val_loss: 0.7175 - val_accuracy: 0.5976\n",
            "Epoch 85/1000\n",
            "500/500 [==============================] - 0s 617us/sample - loss: 0.7315 - accuracy: 0.6700 - val_loss: 0.7102 - val_accuracy: 0.6098\n",
            "Epoch 86/1000\n",
            "500/500 [==============================] - 0s 626us/sample - loss: 0.7048 - accuracy: 0.6680 - val_loss: 0.7187 - val_accuracy: 0.6037\n",
            "Epoch 87/1000\n",
            "500/500 [==============================] - 0s 548us/sample - loss: 0.7154 - accuracy: 0.6540 - val_loss: 0.7138 - val_accuracy: 0.6037\n",
            "Epoch 88/1000\n",
            "500/500 [==============================] - 0s 531us/sample - loss: 0.6960 - accuracy: 0.6560 - val_loss: 0.7047 - val_accuracy: 0.6037\n",
            "Epoch 89/1000\n",
            "500/500 [==============================] - 0s 602us/sample - loss: 0.7102 - accuracy: 0.6400 - val_loss: 0.6910 - val_accuracy: 0.6463\n",
            "Epoch 90/1000\n",
            "500/500 [==============================] - 0s 622us/sample - loss: 0.6887 - accuracy: 0.6680 - val_loss: 0.6973 - val_accuracy: 0.6220\n",
            "Epoch 91/1000\n",
            "500/500 [==============================] - 0s 649us/sample - loss: 0.6683 - accuracy: 0.6680 - val_loss: 0.6933 - val_accuracy: 0.6341\n",
            "Epoch 92/1000\n",
            "500/500 [==============================] - 0s 582us/sample - loss: 0.6464 - accuracy: 0.7040 - val_loss: 0.6859 - val_accuracy: 0.6402\n",
            "Epoch 93/1000\n",
            "500/500 [==============================] - 0s 570us/sample - loss: 0.6801 - accuracy: 0.6980 - val_loss: 0.6767 - val_accuracy: 0.6463\n",
            "Epoch 94/1000\n",
            "500/500 [==============================] - 0s 588us/sample - loss: 0.6725 - accuracy: 0.6840 - val_loss: 0.6614 - val_accuracy: 0.6646\n",
            "Epoch 95/1000\n",
            "500/500 [==============================] - 0s 641us/sample - loss: 0.6665 - accuracy: 0.6740 - val_loss: 0.6700 - val_accuracy: 0.6585\n",
            "Epoch 96/1000\n",
            "500/500 [==============================] - 0s 525us/sample - loss: 0.6682 - accuracy: 0.6840 - val_loss: 0.6709 - val_accuracy: 0.6890\n",
            "Epoch 97/1000\n",
            "500/500 [==============================] - 0s 612us/sample - loss: 0.6577 - accuracy: 0.7060 - val_loss: 0.6634 - val_accuracy: 0.6707\n",
            "Epoch 98/1000\n",
            "500/500 [==============================] - 0s 649us/sample - loss: 0.6544 - accuracy: 0.6980 - val_loss: 0.6694 - val_accuracy: 0.6707\n",
            "Epoch 99/1000\n",
            "500/500 [==============================] - 0s 616us/sample - loss: 0.6659 - accuracy: 0.7080 - val_loss: 0.6700 - val_accuracy: 0.6585\n",
            "Epoch 100/1000\n",
            "500/500 [==============================] - 0s 631us/sample - loss: 0.6619 - accuracy: 0.7080 - val_loss: 0.6642 - val_accuracy: 0.6707\n",
            "Epoch 101/1000\n",
            "500/500 [==============================] - 0s 640us/sample - loss: 0.6188 - accuracy: 0.7200 - val_loss: 0.6624 - val_accuracy: 0.6524\n",
            "Epoch 102/1000\n",
            "500/500 [==============================] - 0s 623us/sample - loss: 0.6612 - accuracy: 0.6940 - val_loss: 0.6665 - val_accuracy: 0.6707\n",
            "Epoch 103/1000\n",
            "500/500 [==============================] - 0s 604us/sample - loss: 0.6630 - accuracy: 0.6640 - val_loss: 0.6686 - val_accuracy: 0.6646\n",
            "Epoch 104/1000\n",
            "500/500 [==============================] - 0s 645us/sample - loss: 0.6390 - accuracy: 0.7240 - val_loss: 0.6511 - val_accuracy: 0.6829\n",
            "Epoch 105/1000\n",
            "500/500 [==============================] - 0s 617us/sample - loss: 0.6533 - accuracy: 0.6820 - val_loss: 0.6537 - val_accuracy: 0.6524\n",
            "Epoch 106/1000\n",
            "500/500 [==============================] - 0s 619us/sample - loss: 0.6209 - accuracy: 0.7180 - val_loss: 0.6363 - val_accuracy: 0.7073\n",
            "Epoch 107/1000\n",
            "500/500 [==============================] - 0s 661us/sample - loss: 0.6412 - accuracy: 0.7000 - val_loss: 0.6355 - val_accuracy: 0.6951\n",
            "Epoch 108/1000\n",
            "500/500 [==============================] - 0s 639us/sample - loss: 0.6338 - accuracy: 0.7040 - val_loss: 0.6399 - val_accuracy: 0.7073\n",
            "Epoch 109/1000\n",
            "500/500 [==============================] - 0s 571us/sample - loss: 0.6439 - accuracy: 0.6920 - val_loss: 0.6278 - val_accuracy: 0.7073\n",
            "Epoch 110/1000\n",
            "500/500 [==============================] - 0s 577us/sample - loss: 0.6232 - accuracy: 0.7140 - val_loss: 0.6207 - val_accuracy: 0.7134\n",
            "Epoch 111/1000\n",
            "500/500 [==============================] - 0s 641us/sample - loss: 0.6467 - accuracy: 0.7020 - val_loss: 0.6193 - val_accuracy: 0.7195\n",
            "Epoch 112/1000\n",
            "500/500 [==============================] - 0s 546us/sample - loss: 0.6110 - accuracy: 0.7380 - val_loss: 0.6200 - val_accuracy: 0.7073\n",
            "Epoch 113/1000\n",
            "500/500 [==============================] - 0s 576us/sample - loss: 0.5664 - accuracy: 0.7520 - val_loss: 0.6277 - val_accuracy: 0.7012\n",
            "Epoch 114/1000\n",
            "500/500 [==============================] - 0s 636us/sample - loss: 0.6262 - accuracy: 0.7000 - val_loss: 0.6210 - val_accuracy: 0.7134\n",
            "Epoch 115/1000\n",
            "500/500 [==============================] - 0s 650us/sample - loss: 0.6231 - accuracy: 0.7280 - val_loss: 0.6173 - val_accuracy: 0.7134\n",
            "Epoch 116/1000\n",
            "500/500 [==============================] - 0s 594us/sample - loss: 0.6141 - accuracy: 0.7440 - val_loss: 0.6263 - val_accuracy: 0.7073\n",
            "Epoch 117/1000\n",
            "500/500 [==============================] - 0s 597us/sample - loss: 0.6195 - accuracy: 0.6920 - val_loss: 0.6210 - val_accuracy: 0.7134\n",
            "Epoch 118/1000\n",
            "500/500 [==============================] - 0s 631us/sample - loss: 0.6153 - accuracy: 0.7120 - val_loss: 0.6238 - val_accuracy: 0.7195\n",
            "Epoch 119/1000\n",
            "500/500 [==============================] - 0s 549us/sample - loss: 0.5808 - accuracy: 0.7320 - val_loss: 0.6297 - val_accuracy: 0.7073\n",
            "Epoch 120/1000\n",
            "500/500 [==============================] - 0s 563us/sample - loss: 0.5873 - accuracy: 0.7320 - val_loss: 0.5992 - val_accuracy: 0.7256\n",
            "Epoch 121/1000\n",
            "500/500 [==============================] - 0s 697us/sample - loss: 0.6154 - accuracy: 0.7200 - val_loss: 0.5943 - val_accuracy: 0.7256\n",
            "Epoch 122/1000\n",
            "500/500 [==============================] - 0s 658us/sample - loss: 0.5789 - accuracy: 0.7460 - val_loss: 0.5919 - val_accuracy: 0.7195\n",
            "Epoch 123/1000\n",
            "500/500 [==============================] - 0s 529us/sample - loss: 0.5886 - accuracy: 0.7340 - val_loss: 0.5942 - val_accuracy: 0.7012\n",
            "Epoch 124/1000\n",
            "500/500 [==============================] - 0s 618us/sample - loss: 0.5782 - accuracy: 0.7540 - val_loss: 0.5863 - val_accuracy: 0.7195\n",
            "Epoch 125/1000\n",
            "500/500 [==============================] - 0s 569us/sample - loss: 0.6070 - accuracy: 0.7200 - val_loss: 0.5843 - val_accuracy: 0.7195\n",
            "Epoch 126/1000\n",
            "500/500 [==============================] - 0s 607us/sample - loss: 0.5991 - accuracy: 0.7260 - val_loss: 0.5861 - val_accuracy: 0.7012\n",
            "Epoch 127/1000\n",
            "500/500 [==============================] - 0s 597us/sample - loss: 0.5949 - accuracy: 0.7540 - val_loss: 0.5894 - val_accuracy: 0.7073\n",
            "Epoch 128/1000\n",
            "500/500 [==============================] - 0s 661us/sample - loss: 0.5909 - accuracy: 0.7160 - val_loss: 0.5898 - val_accuracy: 0.7073\n",
            "Epoch 129/1000\n",
            "500/500 [==============================] - 0s 589us/sample - loss: 0.5817 - accuracy: 0.7200 - val_loss: 0.5960 - val_accuracy: 0.7073\n",
            "Epoch 130/1000\n",
            "500/500 [==============================] - 0s 611us/sample - loss: 0.5636 - accuracy: 0.7500 - val_loss: 0.5994 - val_accuracy: 0.7256\n",
            "Epoch 131/1000\n",
            "500/500 [==============================] - 0s 647us/sample - loss: 0.6017 - accuracy: 0.7280 - val_loss: 0.5972 - val_accuracy: 0.7073\n",
            "Epoch 132/1000\n",
            "500/500 [==============================] - 0s 528us/sample - loss: 0.5638 - accuracy: 0.7660 - val_loss: 0.5958 - val_accuracy: 0.7134\n",
            "Epoch 133/1000\n",
            "500/500 [==============================] - 0s 524us/sample - loss: 0.5400 - accuracy: 0.7680 - val_loss: 0.5967 - val_accuracy: 0.7134\n",
            "Epoch 134/1000\n",
            "500/500 [==============================] - 0s 634us/sample - loss: 0.5682 - accuracy: 0.7320 - val_loss: 0.5781 - val_accuracy: 0.7378\n",
            "Epoch 135/1000\n",
            "500/500 [==============================] - 0s 580us/sample - loss: 0.5505 - accuracy: 0.7720 - val_loss: 0.5827 - val_accuracy: 0.7134\n",
            "Epoch 136/1000\n",
            "500/500 [==============================] - 0s 488us/sample - loss: 0.5572 - accuracy: 0.7520 - val_loss: 0.5931 - val_accuracy: 0.7256\n",
            "Epoch 137/1000\n",
            "500/500 [==============================] - 0s 558us/sample - loss: 0.5536 - accuracy: 0.7580 - val_loss: 0.5900 - val_accuracy: 0.7256\n",
            "Epoch 138/1000\n",
            "500/500 [==============================] - 0s 606us/sample - loss: 0.5961 - accuracy: 0.7400 - val_loss: 0.5857 - val_accuracy: 0.7073\n",
            "Epoch 139/1000\n",
            "500/500 [==============================] - 0s 534us/sample - loss: 0.5744 - accuracy: 0.7520 - val_loss: 0.5809 - val_accuracy: 0.7378\n",
            "Epoch 140/1000\n",
            "500/500 [==============================] - 0s 491us/sample - loss: 0.5614 - accuracy: 0.7500 - val_loss: 0.5850 - val_accuracy: 0.7317\n",
            "Epoch 141/1000\n",
            "500/500 [==============================] - 0s 581us/sample - loss: 0.5155 - accuracy: 0.7660 - val_loss: 0.5705 - val_accuracy: 0.7378\n",
            "Epoch 142/1000\n",
            "500/500 [==============================] - 0s 643us/sample - loss: 0.5672 - accuracy: 0.7540 - val_loss: 0.5851 - val_accuracy: 0.7195\n",
            "Epoch 143/1000\n",
            "500/500 [==============================] - 0s 554us/sample - loss: 0.4976 - accuracy: 0.7800 - val_loss: 0.5673 - val_accuracy: 0.7256\n",
            "Epoch 144/1000\n",
            "500/500 [==============================] - 0s 636us/sample - loss: 0.5367 - accuracy: 0.7880 - val_loss: 0.5765 - val_accuracy: 0.7256\n",
            "Epoch 145/1000\n",
            "500/500 [==============================] - 0s 637us/sample - loss: 0.5653 - accuracy: 0.7560 - val_loss: 0.5721 - val_accuracy: 0.7378\n",
            "Epoch 146/1000\n",
            "500/500 [==============================] - 0s 601us/sample - loss: 0.5721 - accuracy: 0.7580 - val_loss: 0.5638 - val_accuracy: 0.7500\n",
            "Epoch 147/1000\n",
            "500/500 [==============================] - 0s 617us/sample - loss: 0.5610 - accuracy: 0.7620 - val_loss: 0.5705 - val_accuracy: 0.7317\n",
            "Epoch 148/1000\n",
            "500/500 [==============================] - 0s 617us/sample - loss: 0.5430 - accuracy: 0.7640 - val_loss: 0.5742 - val_accuracy: 0.7378\n",
            "Epoch 149/1000\n",
            "500/500 [==============================] - 0s 552us/sample - loss: 0.5354 - accuracy: 0.7720 - val_loss: 0.5755 - val_accuracy: 0.7256\n",
            "Epoch 150/1000\n",
            "500/500 [==============================] - 0s 529us/sample - loss: 0.5263 - accuracy: 0.7700 - val_loss: 0.5802 - val_accuracy: 0.7439\n",
            "Epoch 151/1000\n",
            "500/500 [==============================] - 0s 550us/sample - loss: 0.5342 - accuracy: 0.7740 - val_loss: 0.5885 - val_accuracy: 0.7378\n",
            "Epoch 152/1000\n",
            "500/500 [==============================] - 0s 543us/sample - loss: 0.5612 - accuracy: 0.7440 - val_loss: 0.5847 - val_accuracy: 0.7195\n",
            "Epoch 153/1000\n",
            "500/500 [==============================] - 0s 568us/sample - loss: 0.5227 - accuracy: 0.7700 - val_loss: 0.5705 - val_accuracy: 0.7256\n",
            "Epoch 154/1000\n",
            "500/500 [==============================] - 0s 517us/sample - loss: 0.5155 - accuracy: 0.7720 - val_loss: 0.5638 - val_accuracy: 0.7134\n",
            "Epoch 155/1000\n",
            "500/500 [==============================] - 0s 516us/sample - loss: 0.5271 - accuracy: 0.7640 - val_loss: 0.5653 - val_accuracy: 0.7500\n",
            "Epoch 156/1000\n",
            "500/500 [==============================] - 0s 538us/sample - loss: 0.5281 - accuracy: 0.7600 - val_loss: 0.5710 - val_accuracy: 0.7500\n",
            "Epoch 157/1000\n",
            "500/500 [==============================] - 0s 591us/sample - loss: 0.5367 - accuracy: 0.7700 - val_loss: 0.5560 - val_accuracy: 0.7500\n",
            "Epoch 158/1000\n",
            "500/500 [==============================] - 0s 617us/sample - loss: 0.5222 - accuracy: 0.7700 - val_loss: 0.5772 - val_accuracy: 0.7317\n",
            "Epoch 159/1000\n",
            "500/500 [==============================] - 0s 650us/sample - loss: 0.5080 - accuracy: 0.7920 - val_loss: 0.5575 - val_accuracy: 0.7378\n",
            "Epoch 160/1000\n",
            "500/500 [==============================] - 0s 519us/sample - loss: 0.4966 - accuracy: 0.7860 - val_loss: 0.5576 - val_accuracy: 0.7561\n",
            "Epoch 161/1000\n",
            "500/500 [==============================] - 0s 620us/sample - loss: 0.5057 - accuracy: 0.7960 - val_loss: 0.5531 - val_accuracy: 0.7439\n",
            "Epoch 162/1000\n",
            "500/500 [==============================] - 0s 624us/sample - loss: 0.5258 - accuracy: 0.7820 - val_loss: 0.5477 - val_accuracy: 0.7683\n",
            "Epoch 163/1000\n",
            "500/500 [==============================] - 0s 558us/sample - loss: 0.5270 - accuracy: 0.7540 - val_loss: 0.5675 - val_accuracy: 0.7317\n",
            "Epoch 164/1000\n",
            "500/500 [==============================] - 0s 562us/sample - loss: 0.5132 - accuracy: 0.7920 - val_loss: 0.5792 - val_accuracy: 0.7195\n",
            "Epoch 165/1000\n",
            "500/500 [==============================] - 0s 620us/sample - loss: 0.4892 - accuracy: 0.8020 - val_loss: 0.5581 - val_accuracy: 0.7439\n",
            "Epoch 166/1000\n",
            "500/500 [==============================] - 0s 583us/sample - loss: 0.5436 - accuracy: 0.7640 - val_loss: 0.5469 - val_accuracy: 0.7439\n",
            "Epoch 167/1000\n",
            "500/500 [==============================] - 0s 494us/sample - loss: 0.5217 - accuracy: 0.8000 - val_loss: 0.5457 - val_accuracy: 0.7439\n",
            "Epoch 168/1000\n",
            "500/500 [==============================] - 0s 608us/sample - loss: 0.5181 - accuracy: 0.7720 - val_loss: 0.5436 - val_accuracy: 0.7439\n",
            "Epoch 169/1000\n",
            "500/500 [==============================] - 0s 621us/sample - loss: 0.5204 - accuracy: 0.7780 - val_loss: 0.5370 - val_accuracy: 0.7500\n",
            "Epoch 170/1000\n",
            "500/500 [==============================] - 0s 621us/sample - loss: 0.4999 - accuracy: 0.7640 - val_loss: 0.5388 - val_accuracy: 0.7500\n",
            "Epoch 171/1000\n",
            "500/500 [==============================] - 0s 659us/sample - loss: 0.5363 - accuracy: 0.7780 - val_loss: 0.5391 - val_accuracy: 0.7317\n",
            "Epoch 172/1000\n",
            "500/500 [==============================] - 0s 611us/sample - loss: 0.4790 - accuracy: 0.8000 - val_loss: 0.5372 - val_accuracy: 0.7622\n",
            "Epoch 173/1000\n",
            "500/500 [==============================] - 0s 626us/sample - loss: 0.5051 - accuracy: 0.7740 - val_loss: 0.5315 - val_accuracy: 0.7439\n",
            "Epoch 174/1000\n",
            "500/500 [==============================] - 0s 529us/sample - loss: 0.5016 - accuracy: 0.7920 - val_loss: 0.5275 - val_accuracy: 0.7561\n",
            "Epoch 175/1000\n",
            "500/500 [==============================] - 0s 603us/sample - loss: 0.4890 - accuracy: 0.7880 - val_loss: 0.5323 - val_accuracy: 0.7622\n",
            "Epoch 176/1000\n",
            "500/500 [==============================] - 0s 595us/sample - loss: 0.4896 - accuracy: 0.7920 - val_loss: 0.5358 - val_accuracy: 0.7622\n",
            "Epoch 177/1000\n",
            "500/500 [==============================] - 0s 586us/sample - loss: 0.4745 - accuracy: 0.8020 - val_loss: 0.5282 - val_accuracy: 0.7622\n",
            "Epoch 178/1000\n",
            "500/500 [==============================] - 0s 603us/sample - loss: 0.4991 - accuracy: 0.7800 - val_loss: 0.5294 - val_accuracy: 0.7500\n",
            "Epoch 179/1000\n",
            "500/500 [==============================] - 0s 618us/sample - loss: 0.4956 - accuracy: 0.8040 - val_loss: 0.5259 - val_accuracy: 0.7500\n",
            "Epoch 180/1000\n",
            "500/500 [==============================] - 0s 588us/sample - loss: 0.4770 - accuracy: 0.7900 - val_loss: 0.5308 - val_accuracy: 0.7439\n",
            "Epoch 181/1000\n",
            "500/500 [==============================] - 0s 608us/sample - loss: 0.4937 - accuracy: 0.7760 - val_loss: 0.5250 - val_accuracy: 0.7439\n",
            "Epoch 182/1000\n",
            "500/500 [==============================] - 0s 618us/sample - loss: 0.4933 - accuracy: 0.7880 - val_loss: 0.5302 - val_accuracy: 0.7317\n",
            "Epoch 183/1000\n",
            "500/500 [==============================] - 0s 554us/sample - loss: 0.4791 - accuracy: 0.8100 - val_loss: 0.5175 - val_accuracy: 0.7561\n",
            "Epoch 184/1000\n",
            "500/500 [==============================] - 0s 509us/sample - loss: 0.4611 - accuracy: 0.8100 - val_loss: 0.5123 - val_accuracy: 0.7622\n",
            "Epoch 185/1000\n",
            "500/500 [==============================] - 0s 522us/sample - loss: 0.5034 - accuracy: 0.7760 - val_loss: 0.5292 - val_accuracy: 0.7500\n",
            "Epoch 186/1000\n",
            "500/500 [==============================] - 0s 626us/sample - loss: 0.4924 - accuracy: 0.7880 - val_loss: 0.5302 - val_accuracy: 0.7683\n",
            "Epoch 187/1000\n",
            "500/500 [==============================] - 0s 627us/sample - loss: 0.4608 - accuracy: 0.8220 - val_loss: 0.4996 - val_accuracy: 0.7805\n",
            "Epoch 188/1000\n",
            "500/500 [==============================] - 0s 637us/sample - loss: 0.4866 - accuracy: 0.7860 - val_loss: 0.4984 - val_accuracy: 0.8049\n",
            "Epoch 189/1000\n",
            "500/500 [==============================] - 0s 586us/sample - loss: 0.5029 - accuracy: 0.7800 - val_loss: 0.4983 - val_accuracy: 0.7805\n",
            "Epoch 190/1000\n",
            "500/500 [==============================] - 0s 547us/sample - loss: 0.4899 - accuracy: 0.7860 - val_loss: 0.4906 - val_accuracy: 0.7744\n",
            "Epoch 191/1000\n",
            "500/500 [==============================] - 0s 517us/sample - loss: 0.4856 - accuracy: 0.7920 - val_loss: 0.4800 - val_accuracy: 0.7805\n",
            "Epoch 192/1000\n",
            "500/500 [==============================] - 0s 501us/sample - loss: 0.4477 - accuracy: 0.8240 - val_loss: 0.4710 - val_accuracy: 0.8049\n",
            "Epoch 193/1000\n",
            "500/500 [==============================] - 0s 638us/sample - loss: 0.4777 - accuracy: 0.8120 - val_loss: 0.4722 - val_accuracy: 0.8049\n",
            "Epoch 194/1000\n",
            "500/500 [==============================] - 0s 512us/sample - loss: 0.4768 - accuracy: 0.7960 - val_loss: 0.4682 - val_accuracy: 0.7988\n",
            "Epoch 195/1000\n",
            "500/500 [==============================] - 0s 616us/sample - loss: 0.4628 - accuracy: 0.8080 - val_loss: 0.4746 - val_accuracy: 0.7927\n",
            "Epoch 196/1000\n",
            "500/500 [==============================] - 0s 622us/sample - loss: 0.4770 - accuracy: 0.8020 - val_loss: 0.4685 - val_accuracy: 0.8110\n",
            "Epoch 197/1000\n",
            "500/500 [==============================] - 0s 543us/sample - loss: 0.4510 - accuracy: 0.8180 - val_loss: 0.4613 - val_accuracy: 0.8049\n",
            "Epoch 198/1000\n",
            "500/500 [==============================] - 0s 540us/sample - loss: 0.4796 - accuracy: 0.7980 - val_loss: 0.4602 - val_accuracy: 0.8232\n",
            "Epoch 199/1000\n",
            "500/500 [==============================] - 0s 616us/sample - loss: 0.4490 - accuracy: 0.8080 - val_loss: 0.4625 - val_accuracy: 0.7866\n",
            "Epoch 200/1000\n",
            "500/500 [==============================] - 0s 619us/sample - loss: 0.4341 - accuracy: 0.8160 - val_loss: 0.4681 - val_accuracy: 0.8049\n",
            "Epoch 201/1000\n",
            "500/500 [==============================] - 0s 524us/sample - loss: 0.4691 - accuracy: 0.8060 - val_loss: 0.4502 - val_accuracy: 0.8110\n",
            "Epoch 202/1000\n",
            "500/500 [==============================] - 0s 587us/sample - loss: 0.4586 - accuracy: 0.7880 - val_loss: 0.4533 - val_accuracy: 0.8354\n",
            "Epoch 203/1000\n",
            "500/500 [==============================] - 0s 641us/sample - loss: 0.4657 - accuracy: 0.8100 - val_loss: 0.4566 - val_accuracy: 0.8110\n",
            "Epoch 204/1000\n",
            "500/500 [==============================] - 0s 539us/sample - loss: 0.4404 - accuracy: 0.8320 - val_loss: 0.4496 - val_accuracy: 0.8110\n",
            "Epoch 205/1000\n",
            "500/500 [==============================] - 0s 522us/sample - loss: 0.4568 - accuracy: 0.8060 - val_loss: 0.4497 - val_accuracy: 0.8293\n",
            "Epoch 206/1000\n",
            "500/500 [==============================] - 0s 603us/sample - loss: 0.4556 - accuracy: 0.8160 - val_loss: 0.4506 - val_accuracy: 0.8110\n",
            "Epoch 207/1000\n",
            "500/500 [==============================] - 0s 541us/sample - loss: 0.4508 - accuracy: 0.8280 - val_loss: 0.4501 - val_accuracy: 0.8049\n",
            "Epoch 208/1000\n",
            "500/500 [==============================] - 0s 604us/sample - loss: 0.4200 - accuracy: 0.8260 - val_loss: 0.4465 - val_accuracy: 0.7927\n",
            "Epoch 209/1000\n",
            "500/500 [==============================] - 0s 515us/sample - loss: 0.4425 - accuracy: 0.8180 - val_loss: 0.4493 - val_accuracy: 0.7988\n",
            "Epoch 210/1000\n",
            "500/500 [==============================] - 0s 498us/sample - loss: 0.4321 - accuracy: 0.8300 - val_loss: 0.4395 - val_accuracy: 0.8171\n",
            "Epoch 211/1000\n",
            "500/500 [==============================] - 0s 625us/sample - loss: 0.4250 - accuracy: 0.8260 - val_loss: 0.4377 - val_accuracy: 0.8293\n",
            "Epoch 212/1000\n",
            "500/500 [==============================] - 0s 551us/sample - loss: 0.4553 - accuracy: 0.8520 - val_loss: 0.4288 - val_accuracy: 0.8354\n",
            "Epoch 213/1000\n",
            "500/500 [==============================] - 0s 569us/sample - loss: 0.4071 - accuracy: 0.8300 - val_loss: 0.4404 - val_accuracy: 0.8354\n",
            "Epoch 214/1000\n",
            "500/500 [==============================] - 0s 579us/sample - loss: 0.4195 - accuracy: 0.8340 - val_loss: 0.4253 - val_accuracy: 0.8354\n",
            "Epoch 215/1000\n",
            "500/500 [==============================] - 0s 641us/sample - loss: 0.4516 - accuracy: 0.8140 - val_loss: 0.4276 - val_accuracy: 0.8415\n",
            "Epoch 216/1000\n",
            "500/500 [==============================] - 0s 623us/sample - loss: 0.4287 - accuracy: 0.8400 - val_loss: 0.4250 - val_accuracy: 0.8354\n",
            "Epoch 217/1000\n",
            "500/500 [==============================] - 0s 619us/sample - loss: 0.4292 - accuracy: 0.8380 - val_loss: 0.4218 - val_accuracy: 0.8171\n",
            "Epoch 218/1000\n",
            "500/500 [==============================] - 0s 595us/sample - loss: 0.4269 - accuracy: 0.8540 - val_loss: 0.4308 - val_accuracy: 0.8232\n",
            "Epoch 219/1000\n",
            "500/500 [==============================] - 0s 644us/sample - loss: 0.4773 - accuracy: 0.8120 - val_loss: 0.4328 - val_accuracy: 0.8110\n",
            "Epoch 220/1000\n",
            "500/500 [==============================] - 0s 625us/sample - loss: 0.4488 - accuracy: 0.8060 - val_loss: 0.4375 - val_accuracy: 0.8049\n",
            "Epoch 221/1000\n",
            "500/500 [==============================] - 0s 601us/sample - loss: 0.4149 - accuracy: 0.8420 - val_loss: 0.4365 - val_accuracy: 0.8232\n",
            "Epoch 222/1000\n",
            "500/500 [==============================] - 0s 640us/sample - loss: 0.4309 - accuracy: 0.8280 - val_loss: 0.4404 - val_accuracy: 0.8171\n",
            "Epoch 223/1000\n",
            "500/500 [==============================] - 0s 607us/sample - loss: 0.4231 - accuracy: 0.8260 - val_loss: 0.4311 - val_accuracy: 0.7927\n",
            "Epoch 224/1000\n",
            "500/500 [==============================] - 0s 664us/sample - loss: 0.4346 - accuracy: 0.8280 - val_loss: 0.4153 - val_accuracy: 0.8232\n",
            "Epoch 225/1000\n",
            "500/500 [==============================] - 0s 708us/sample - loss: 0.4294 - accuracy: 0.8240 - val_loss: 0.4083 - val_accuracy: 0.8537\n",
            "Epoch 226/1000\n",
            "500/500 [==============================] - 0s 671us/sample - loss: 0.3971 - accuracy: 0.8520 - val_loss: 0.3907 - val_accuracy: 0.8354\n",
            "Epoch 227/1000\n",
            "500/500 [==============================] - 0s 652us/sample - loss: 0.3887 - accuracy: 0.8560 - val_loss: 0.4019 - val_accuracy: 0.8354\n",
            "Epoch 228/1000\n",
            "500/500 [==============================] - 0s 583us/sample - loss: 0.4367 - accuracy: 0.8100 - val_loss: 0.4015 - val_accuracy: 0.8293\n",
            "Epoch 229/1000\n",
            "500/500 [==============================] - 0s 572us/sample - loss: 0.4023 - accuracy: 0.8620 - val_loss: 0.4189 - val_accuracy: 0.7988\n",
            "Epoch 230/1000\n",
            "500/500 [==============================] - 0s 548us/sample - loss: 0.3841 - accuracy: 0.8520 - val_loss: 0.4102 - val_accuracy: 0.7988\n",
            "Epoch 231/1000\n",
            "500/500 [==============================] - 0s 494us/sample - loss: 0.3701 - accuracy: 0.8580 - val_loss: 0.4002 - val_accuracy: 0.7988\n",
            "Epoch 232/1000\n",
            "500/500 [==============================] - 0s 640us/sample - loss: 0.4613 - accuracy: 0.7900 - val_loss: 0.4073 - val_accuracy: 0.8293\n",
            "Epoch 233/1000\n",
            "500/500 [==============================] - 0s 578us/sample - loss: 0.3782 - accuracy: 0.8600 - val_loss: 0.4040 - val_accuracy: 0.8232\n",
            "Epoch 234/1000\n",
            "500/500 [==============================] - 0s 605us/sample - loss: 0.4178 - accuracy: 0.8300 - val_loss: 0.4021 - val_accuracy: 0.8354\n",
            "Epoch 235/1000\n",
            "500/500 [==============================] - 0s 537us/sample - loss: 0.3972 - accuracy: 0.8740 - val_loss: 0.4006 - val_accuracy: 0.8476\n",
            "Epoch 236/1000\n",
            "500/500 [==============================] - 0s 610us/sample - loss: 0.4302 - accuracy: 0.8300 - val_loss: 0.3956 - val_accuracy: 0.8537\n",
            "Epoch 237/1000\n",
            "500/500 [==============================] - 0s 524us/sample - loss: 0.4238 - accuracy: 0.8360 - val_loss: 0.3815 - val_accuracy: 0.8659\n",
            "Epoch 238/1000\n",
            "500/500 [==============================] - 0s 614us/sample - loss: 0.4312 - accuracy: 0.8220 - val_loss: 0.3939 - val_accuracy: 0.8354\n",
            "Epoch 239/1000\n",
            "500/500 [==============================] - 0s 643us/sample - loss: 0.4056 - accuracy: 0.8320 - val_loss: 0.3814 - val_accuracy: 0.8659\n",
            "Epoch 240/1000\n",
            "500/500 [==============================] - 0s 572us/sample - loss: 0.4131 - accuracy: 0.8280 - val_loss: 0.3768 - val_accuracy: 0.8537\n",
            "Epoch 241/1000\n",
            "500/500 [==============================] - 0s 584us/sample - loss: 0.4198 - accuracy: 0.8220 - val_loss: 0.3807 - val_accuracy: 0.8476\n",
            "Epoch 242/1000\n",
            "500/500 [==============================] - 0s 542us/sample - loss: 0.4029 - accuracy: 0.8500 - val_loss: 0.3739 - val_accuracy: 0.8720\n",
            "Epoch 243/1000\n",
            "500/500 [==============================] - 0s 594us/sample - loss: 0.4078 - accuracy: 0.8420 - val_loss: 0.3912 - val_accuracy: 0.8537\n",
            "Epoch 244/1000\n",
            "500/500 [==============================] - 0s 503us/sample - loss: 0.3766 - accuracy: 0.8600 - val_loss: 0.3928 - val_accuracy: 0.8476\n",
            "Epoch 245/1000\n",
            "500/500 [==============================] - 0s 647us/sample - loss: 0.3918 - accuracy: 0.8660 - val_loss: 0.3796 - val_accuracy: 0.8537\n",
            "Epoch 246/1000\n",
            "500/500 [==============================] - 0s 594us/sample - loss: 0.3853 - accuracy: 0.8440 - val_loss: 0.3805 - val_accuracy: 0.8598\n",
            "Epoch 247/1000\n",
            "500/500 [==============================] - 0s 602us/sample - loss: 0.4129 - accuracy: 0.8060 - val_loss: 0.3912 - val_accuracy: 0.8537\n",
            "Epoch 248/1000\n",
            "500/500 [==============================] - 0s 534us/sample - loss: 0.3976 - accuracy: 0.8300 - val_loss: 0.3865 - val_accuracy: 0.8659\n",
            "Epoch 249/1000\n",
            "500/500 [==============================] - 0s 615us/sample - loss: 0.3655 - accuracy: 0.8580 - val_loss: 0.3979 - val_accuracy: 0.8354\n",
            "Epoch 250/1000\n",
            "500/500 [==============================] - 0s 635us/sample - loss: 0.4262 - accuracy: 0.8220 - val_loss: 0.3884 - val_accuracy: 0.8293\n",
            "Epoch 251/1000\n",
            "500/500 [==============================] - 0s 526us/sample - loss: 0.4173 - accuracy: 0.8340 - val_loss: 0.3845 - val_accuracy: 0.8415\n",
            "Epoch 252/1000\n",
            "500/500 [==============================] - 0s 613us/sample - loss: 0.3655 - accuracy: 0.8540 - val_loss: 0.3729 - val_accuracy: 0.8537\n",
            "Epoch 253/1000\n",
            "500/500 [==============================] - 0s 646us/sample - loss: 0.3805 - accuracy: 0.8500 - val_loss: 0.3772 - val_accuracy: 0.8720\n",
            "Epoch 254/1000\n",
            "500/500 [==============================] - 0s 579us/sample - loss: 0.4066 - accuracy: 0.8400 - val_loss: 0.3787 - val_accuracy: 0.8720\n",
            "Epoch 255/1000\n",
            "500/500 [==============================] - 0s 534us/sample - loss: 0.3901 - accuracy: 0.8500 - val_loss: 0.3737 - val_accuracy: 0.8720\n",
            "Epoch 256/1000\n",
            "500/500 [==============================] - 0s 639us/sample - loss: 0.4284 - accuracy: 0.8260 - val_loss: 0.3780 - val_accuracy: 0.8720\n",
            "Epoch 257/1000\n",
            "500/500 [==============================] - 0s 557us/sample - loss: 0.3871 - accuracy: 0.8660 - val_loss: 0.3752 - val_accuracy: 0.8476\n",
            "Epoch 258/1000\n",
            "500/500 [==============================] - 0s 504us/sample - loss: 0.4122 - accuracy: 0.8400 - val_loss: 0.3802 - val_accuracy: 0.8476\n",
            "Epoch 259/1000\n",
            "500/500 [==============================] - 0s 587us/sample - loss: 0.3997 - accuracy: 0.8540 - val_loss: 0.3735 - val_accuracy: 0.8598\n",
            "Epoch 260/1000\n",
            "500/500 [==============================] - 0s 647us/sample - loss: 0.3821 - accuracy: 0.8500 - val_loss: 0.3696 - val_accuracy: 0.8659\n",
            "Epoch 261/1000\n",
            "500/500 [==============================] - 0s 590us/sample - loss: 0.3759 - accuracy: 0.8320 - val_loss: 0.3737 - val_accuracy: 0.8537\n",
            "Epoch 262/1000\n",
            "500/500 [==============================] - 0s 538us/sample - loss: 0.3791 - accuracy: 0.8680 - val_loss: 0.3804 - val_accuracy: 0.8659\n",
            "Epoch 263/1000\n",
            "500/500 [==============================] - 0s 637us/sample - loss: 0.4006 - accuracy: 0.8460 - val_loss: 0.3878 - val_accuracy: 0.8354\n",
            "Epoch 264/1000\n",
            "500/500 [==============================] - 0s 548us/sample - loss: 0.3595 - accuracy: 0.8520 - val_loss: 0.3755 - val_accuracy: 0.8659\n",
            "Epoch 265/1000\n",
            "500/500 [==============================] - 0s 576us/sample - loss: 0.3652 - accuracy: 0.8620 - val_loss: 0.3763 - val_accuracy: 0.8659\n",
            "Epoch 266/1000\n",
            "500/500 [==============================] - 0s 563us/sample - loss: 0.3695 - accuracy: 0.8540 - val_loss: 0.3840 - val_accuracy: 0.8476\n",
            "Epoch 267/1000\n",
            "500/500 [==============================] - 0s 604us/sample - loss: 0.3684 - accuracy: 0.8680 - val_loss: 0.3821 - val_accuracy: 0.8598\n",
            "Epoch 268/1000\n",
            "500/500 [==============================] - 0s 590us/sample - loss: 0.4189 - accuracy: 0.8340 - val_loss: 0.3893 - val_accuracy: 0.8537\n",
            "Epoch 269/1000\n",
            "500/500 [==============================] - 0s 606us/sample - loss: 0.3638 - accuracy: 0.8540 - val_loss: 0.3774 - val_accuracy: 0.8537\n",
            "Epoch 270/1000\n",
            "500/500 [==============================] - 0s 659us/sample - loss: 0.4544 - accuracy: 0.8140 - val_loss: 0.3718 - val_accuracy: 0.8720\n",
            "Epoch 271/1000\n",
            "500/500 [==============================] - 0s 561us/sample - loss: 0.3780 - accuracy: 0.8500 - val_loss: 0.3644 - val_accuracy: 0.8720\n",
            "Epoch 272/1000\n",
            "500/500 [==============================] - 0s 629us/sample - loss: 0.4113 - accuracy: 0.8400 - val_loss: 0.3818 - val_accuracy: 0.8598\n",
            "Epoch 273/1000\n",
            "500/500 [==============================] - 0s 638us/sample - loss: 0.3773 - accuracy: 0.8640 - val_loss: 0.3881 - val_accuracy: 0.8659\n",
            "Epoch 274/1000\n",
            "500/500 [==============================] - 0s 536us/sample - loss: 0.3651 - accuracy: 0.8720 - val_loss: 0.3765 - val_accuracy: 0.8841\n",
            "Epoch 275/1000\n",
            "500/500 [==============================] - 0s 656us/sample - loss: 0.3959 - accuracy: 0.8300 - val_loss: 0.3791 - val_accuracy: 0.8598\n",
            "Epoch 276/1000\n",
            "500/500 [==============================] - 0s 623us/sample - loss: 0.3904 - accuracy: 0.8480 - val_loss: 0.3783 - val_accuracy: 0.8659\n",
            "Epoch 277/1000\n",
            "500/500 [==============================] - 0s 653us/sample - loss: 0.3880 - accuracy: 0.8540 - val_loss: 0.3702 - val_accuracy: 0.8476\n",
            "Epoch 278/1000\n",
            "500/500 [==============================] - 0s 615us/sample - loss: 0.4090 - accuracy: 0.8420 - val_loss: 0.3664 - val_accuracy: 0.8780\n",
            "Epoch 279/1000\n",
            "500/500 [==============================] - 0s 642us/sample - loss: 0.3904 - accuracy: 0.8500 - val_loss: 0.3685 - val_accuracy: 0.8841\n",
            "Epoch 280/1000\n",
            "500/500 [==============================] - 0s 606us/sample - loss: 0.4050 - accuracy: 0.8360 - val_loss: 0.3770 - val_accuracy: 0.8659\n",
            "Epoch 281/1000\n",
            "500/500 [==============================] - 0s 576us/sample - loss: 0.3928 - accuracy: 0.8300 - val_loss: 0.3659 - val_accuracy: 0.8902\n",
            "Epoch 282/1000\n",
            "500/500 [==============================] - 0s 576us/sample - loss: 0.3839 - accuracy: 0.8500 - val_loss: 0.3638 - val_accuracy: 0.8720\n",
            "Epoch 283/1000\n",
            "500/500 [==============================] - 0s 655us/sample - loss: 0.3872 - accuracy: 0.8480 - val_loss: 0.3560 - val_accuracy: 0.8780\n",
            "Epoch 284/1000\n",
            "500/500 [==============================] - 0s 560us/sample - loss: 0.3916 - accuracy: 0.8360 - val_loss: 0.3543 - val_accuracy: 0.8841\n",
            "Epoch 285/1000\n",
            "500/500 [==============================] - 0s 521us/sample - loss: 0.3528 - accuracy: 0.8720 - val_loss: 0.3469 - val_accuracy: 0.8841\n",
            "Epoch 286/1000\n",
            "500/500 [==============================] - 0s 605us/sample - loss: 0.3716 - accuracy: 0.8560 - val_loss: 0.3491 - val_accuracy: 0.8902\n",
            "Epoch 287/1000\n",
            "500/500 [==============================] - 0s 656us/sample - loss: 0.3467 - accuracy: 0.8660 - val_loss: 0.3481 - val_accuracy: 0.8841\n",
            "Epoch 288/1000\n",
            "500/500 [==============================] - 0s 641us/sample - loss: 0.3982 - accuracy: 0.8380 - val_loss: 0.3527 - val_accuracy: 0.8841\n",
            "Epoch 289/1000\n",
            "500/500 [==============================] - 0s 643us/sample - loss: 0.4001 - accuracy: 0.8520 - val_loss: 0.3553 - val_accuracy: 0.8902\n",
            "Epoch 290/1000\n",
            "500/500 [==============================] - 0s 635us/sample - loss: 0.3755 - accuracy: 0.8620 - val_loss: 0.3588 - val_accuracy: 0.8720\n",
            "Epoch 291/1000\n",
            "500/500 [==============================] - 0s 505us/sample - loss: 0.4052 - accuracy: 0.8460 - val_loss: 0.3446 - val_accuracy: 0.9024\n",
            "Epoch 292/1000\n",
            "500/500 [==============================] - 0s 612us/sample - loss: 0.3863 - accuracy: 0.8520 - val_loss: 0.3590 - val_accuracy: 0.8720\n",
            "Epoch 293/1000\n",
            "500/500 [==============================] - 0s 620us/sample - loss: 0.3666 - accuracy: 0.8460 - val_loss: 0.3672 - val_accuracy: 0.8841\n",
            "Epoch 294/1000\n",
            "500/500 [==============================] - 0s 569us/sample - loss: 0.3760 - accuracy: 0.8580 - val_loss: 0.3709 - val_accuracy: 0.8720\n",
            "Epoch 295/1000\n",
            "500/500 [==============================] - 0s 536us/sample - loss: 0.4043 - accuracy: 0.8460 - val_loss: 0.3627 - val_accuracy: 0.8841\n",
            "Epoch 296/1000\n",
            "500/500 [==============================] - 0s 639us/sample - loss: 0.3874 - accuracy: 0.8340 - val_loss: 0.3770 - val_accuracy: 0.8537\n",
            "Epoch 297/1000\n",
            "500/500 [==============================] - 0s 648us/sample - loss: 0.3801 - accuracy: 0.8480 - val_loss: 0.3726 - val_accuracy: 0.8659\n",
            "Epoch 298/1000\n",
            "500/500 [==============================] - 0s 593us/sample - loss: 0.3523 - accuracy: 0.8540 - val_loss: 0.3702 - val_accuracy: 0.8659\n",
            "Epoch 299/1000\n",
            "500/500 [==============================] - 0s 628us/sample - loss: 0.3513 - accuracy: 0.8580 - val_loss: 0.3474 - val_accuracy: 0.8720\n",
            "Epoch 300/1000\n",
            "500/500 [==============================] - 0s 613us/sample - loss: 0.3778 - accuracy: 0.8600 - val_loss: 0.3549 - val_accuracy: 0.8537\n",
            "Epoch 301/1000\n",
            "500/500 [==============================] - 0s 588us/sample - loss: 0.3516 - accuracy: 0.8600 - val_loss: 0.3565 - val_accuracy: 0.8780\n",
            "Epoch 302/1000\n",
            "500/500 [==============================] - 0s 517us/sample - loss: 0.3648 - accuracy: 0.8580 - val_loss: 0.3687 - val_accuracy: 0.8841\n",
            "Epoch 303/1000\n",
            "500/500 [==============================] - 0s 620us/sample - loss: 0.4321 - accuracy: 0.8260 - val_loss: 0.3862 - val_accuracy: 0.8476\n",
            "Epoch 304/1000\n",
            "500/500 [==============================] - 0s 606us/sample - loss: 0.3862 - accuracy: 0.8380 - val_loss: 0.3752 - val_accuracy: 0.8720\n",
            "Epoch 305/1000\n",
            "500/500 [==============================] - 0s 539us/sample - loss: 0.3445 - accuracy: 0.8640 - val_loss: 0.3687 - val_accuracy: 0.8659\n",
            "Epoch 306/1000\n",
            "500/500 [==============================] - 0s 602us/sample - loss: 0.3986 - accuracy: 0.8540 - val_loss: 0.3659 - val_accuracy: 0.8659\n",
            "Epoch 307/1000\n",
            "500/500 [==============================] - 0s 542us/sample - loss: 0.3612 - accuracy: 0.8520 - val_loss: 0.3488 - val_accuracy: 0.8841\n",
            "Epoch 308/1000\n",
            "500/500 [==============================] - 0s 568us/sample - loss: 0.3563 - accuracy: 0.8740 - val_loss: 0.3362 - val_accuracy: 0.8780\n",
            "Epoch 309/1000\n",
            "500/500 [==============================] - 0s 506us/sample - loss: 0.3540 - accuracy: 0.8800 - val_loss: 0.3415 - val_accuracy: 0.8780\n",
            "Epoch 310/1000\n",
            "500/500 [==============================] - 0s 675us/sample - loss: 0.3639 - accuracy: 0.8460 - val_loss: 0.3415 - val_accuracy: 0.8841\n",
            "Epoch 311/1000\n",
            "500/500 [==============================] - 0s 572us/sample - loss: 0.3337 - accuracy: 0.8740 - val_loss: 0.3413 - val_accuracy: 0.8902\n",
            "Epoch 312/1000\n",
            "500/500 [==============================] - 0s 631us/sample - loss: 0.4033 - accuracy: 0.8260 - val_loss: 0.3359 - val_accuracy: 0.8841\n",
            "Epoch 313/1000\n",
            "500/500 [==============================] - 0s 653us/sample - loss: 0.3943 - accuracy: 0.8500 - val_loss: 0.3393 - val_accuracy: 0.8963\n",
            "Epoch 314/1000\n",
            "500/500 [==============================] - 0s 610us/sample - loss: 0.3679 - accuracy: 0.8500 - val_loss: 0.3488 - val_accuracy: 0.9024\n",
            "Epoch 315/1000\n",
            "500/500 [==============================] - 0s 534us/sample - loss: 0.3563 - accuracy: 0.8720 - val_loss: 0.3528 - val_accuracy: 0.8902\n",
            "Epoch 316/1000\n",
            "500/500 [==============================] - 0s 632us/sample - loss: 0.3528 - accuracy: 0.8580 - val_loss: 0.3487 - val_accuracy: 0.8902\n",
            "Epoch 317/1000\n",
            "500/500 [==============================] - 0s 620us/sample - loss: 0.3527 - accuracy: 0.8840 - val_loss: 0.3500 - val_accuracy: 0.9085\n",
            "Epoch 318/1000\n",
            "500/500 [==============================] - 0s 524us/sample - loss: 0.3769 - accuracy: 0.8580 - val_loss: 0.3450 - val_accuracy: 0.8902\n",
            "Epoch 319/1000\n",
            "500/500 [==============================] - 0s 620us/sample - loss: 0.3326 - accuracy: 0.8740 - val_loss: 0.3488 - val_accuracy: 0.9085\n",
            "Epoch 320/1000\n",
            "500/500 [==============================] - 0s 614us/sample - loss: 0.3670 - accuracy: 0.8680 - val_loss: 0.3563 - val_accuracy: 0.8841\n",
            "Epoch 321/1000\n",
            "500/500 [==============================] - 0s 557us/sample - loss: 0.3483 - accuracy: 0.8640 - val_loss: 0.3636 - val_accuracy: 0.8902\n",
            "Epoch 322/1000\n",
            "500/500 [==============================] - 0s 550us/sample - loss: 0.3967 - accuracy: 0.8540 - val_loss: 0.3682 - val_accuracy: 0.8659\n",
            "Epoch 323/1000\n",
            "500/500 [==============================] - 0s 652us/sample - loss: 0.3495 - accuracy: 0.8480 - val_loss: 0.3692 - val_accuracy: 0.8841\n",
            "Epoch 324/1000\n",
            "500/500 [==============================] - 0s 660us/sample - loss: 0.3687 - accuracy: 0.8520 - val_loss: 0.3575 - val_accuracy: 0.8841\n",
            "Epoch 325/1000\n",
            "500/500 [==============================] - 0s 553us/sample - loss: 0.3317 - accuracy: 0.8840 - val_loss: 0.3567 - val_accuracy: 0.8720\n",
            "Epoch 326/1000\n",
            "500/500 [==============================] - 0s 649us/sample - loss: 0.3989 - accuracy: 0.8580 - val_loss: 0.3421 - val_accuracy: 0.8902\n",
            "Epoch 327/1000\n",
            "500/500 [==============================] - 0s 576us/sample - loss: 0.3482 - accuracy: 0.8600 - val_loss: 0.3499 - val_accuracy: 0.8841\n",
            "Epoch 328/1000\n",
            "500/500 [==============================] - 0s 575us/sample - loss: 0.3839 - accuracy: 0.8440 - val_loss: 0.3541 - val_accuracy: 0.8902\n",
            "Epoch 329/1000\n",
            "500/500 [==============================] - 0s 540us/sample - loss: 0.3728 - accuracy: 0.8720 - val_loss: 0.3623 - val_accuracy: 0.8902\n",
            "Epoch 330/1000\n",
            "500/500 [==============================] - 0s 625us/sample - loss: 0.3495 - accuracy: 0.8780 - val_loss: 0.3454 - val_accuracy: 0.8902\n",
            "Epoch 331/1000\n",
            "500/500 [==============================] - 0s 567us/sample - loss: 0.3622 - accuracy: 0.8580 - val_loss: 0.3481 - val_accuracy: 0.8841\n",
            "Epoch 332/1000\n",
            "500/500 [==============================] - 0s 506us/sample - loss: 0.3258 - accuracy: 0.8720 - val_loss: 0.3484 - val_accuracy: 0.8963\n",
            "Epoch 333/1000\n",
            "500/500 [==============================] - 0s 602us/sample - loss: 0.3473 - accuracy: 0.8680 - val_loss: 0.3433 - val_accuracy: 0.9146\n",
            "Epoch 334/1000\n",
            "500/500 [==============================] - 0s 540us/sample - loss: 0.3560 - accuracy: 0.8680 - val_loss: 0.3427 - val_accuracy: 0.8902\n",
            "Epoch 335/1000\n",
            "500/500 [==============================] - 0s 602us/sample - loss: 0.3688 - accuracy: 0.8480 - val_loss: 0.3393 - val_accuracy: 0.8902\n",
            "Epoch 336/1000\n",
            "500/500 [==============================] - 0s 593us/sample - loss: 0.3388 - accuracy: 0.8580 - val_loss: 0.3425 - val_accuracy: 0.8902\n",
            "Epoch 337/1000\n",
            "500/500 [==============================] - 0s 595us/sample - loss: 0.3361 - accuracy: 0.8580 - val_loss: 0.3512 - val_accuracy: 0.8902\n",
            "Epoch 338/1000\n",
            "500/500 [==============================] - 0s 611us/sample - loss: 0.3612 - accuracy: 0.8600 - val_loss: 0.3520 - val_accuracy: 0.8963\n",
            "Epoch 339/1000\n",
            "500/500 [==============================] - 0s 623us/sample - loss: 0.3748 - accuracy: 0.8640 - val_loss: 0.3351 - val_accuracy: 0.9146\n",
            "Epoch 340/1000\n",
            "500/500 [==============================] - 0s 615us/sample - loss: 0.3697 - accuracy: 0.8320 - val_loss: 0.3317 - val_accuracy: 0.9085\n",
            "Epoch 341/1000\n",
            "500/500 [==============================] - 0s 597us/sample - loss: 0.3400 - accuracy: 0.8760 - val_loss: 0.3341 - val_accuracy: 0.9024\n",
            "Epoch 342/1000\n",
            "500/500 [==============================] - 0s 611us/sample - loss: 0.3566 - accuracy: 0.8720 - val_loss: 0.3395 - val_accuracy: 0.9085\n",
            "Epoch 343/1000\n",
            "500/500 [==============================] - 0s 622us/sample - loss: 0.3430 - accuracy: 0.8700 - val_loss: 0.3360 - val_accuracy: 0.9085\n",
            "Epoch 344/1000\n",
            "500/500 [==============================] - 0s 598us/sample - loss: 0.3484 - accuracy: 0.8540 - val_loss: 0.3378 - val_accuracy: 0.8963\n",
            "Epoch 345/1000\n",
            "500/500 [==============================] - 0s 694us/sample - loss: 0.3336 - accuracy: 0.8680 - val_loss: 0.3370 - val_accuracy: 0.8963\n",
            "Epoch 346/1000\n",
            "500/500 [==============================] - 0s 619us/sample - loss: 0.3980 - accuracy: 0.8460 - val_loss: 0.3346 - val_accuracy: 0.8841\n",
            "Epoch 347/1000\n",
            "500/500 [==============================] - 0s 596us/sample - loss: 0.3131 - accuracy: 0.8740 - val_loss: 0.3503 - val_accuracy: 0.8902\n",
            "Epoch 348/1000\n",
            "500/500 [==============================] - 0s 550us/sample - loss: 0.3451 - accuracy: 0.8620 - val_loss: 0.3437 - val_accuracy: 0.8780\n",
            "Epoch 349/1000\n",
            "500/500 [==============================] - 0s 615us/sample - loss: 0.3451 - accuracy: 0.8700 - val_loss: 0.3517 - val_accuracy: 0.8720\n",
            "Epoch 350/1000\n",
            "500/500 [==============================] - 0s 624us/sample - loss: 0.3548 - accuracy: 0.8580 - val_loss: 0.3358 - val_accuracy: 0.8841\n",
            "Epoch 351/1000\n",
            "500/500 [==============================] - 0s 510us/sample - loss: 0.3686 - accuracy: 0.8460 - val_loss: 0.3334 - val_accuracy: 0.8963\n",
            "Epoch 352/1000\n",
            "500/500 [==============================] - 0s 618us/sample - loss: 0.3737 - accuracy: 0.8560 - val_loss: 0.3287 - val_accuracy: 0.8963\n",
            "Epoch 353/1000\n",
            "500/500 [==============================] - 0s 605us/sample - loss: 0.3410 - accuracy: 0.8620 - val_loss: 0.3359 - val_accuracy: 0.8963\n",
            "Epoch 354/1000\n",
            "500/500 [==============================] - 0s 596us/sample - loss: 0.3894 - accuracy: 0.8420 - val_loss: 0.3295 - val_accuracy: 0.9024\n",
            "Epoch 355/1000\n",
            "500/500 [==============================] - 0s 625us/sample - loss: 0.3746 - accuracy: 0.8740 - val_loss: 0.3297 - val_accuracy: 0.8841\n",
            "Epoch 356/1000\n",
            "500/500 [==============================] - 0s 624us/sample - loss: 0.3482 - accuracy: 0.8700 - val_loss: 0.3430 - val_accuracy: 0.8963\n",
            "Epoch 357/1000\n",
            "500/500 [==============================] - 0s 607us/sample - loss: 0.4034 - accuracy: 0.8420 - val_loss: 0.3528 - val_accuracy: 0.8963\n",
            "Epoch 358/1000\n",
            "500/500 [==============================] - 0s 588us/sample - loss: 0.3756 - accuracy: 0.8400 - val_loss: 0.3489 - val_accuracy: 0.8902\n",
            "Epoch 359/1000\n",
            "500/500 [==============================] - 0s 646us/sample - loss: 0.3501 - accuracy: 0.8480 - val_loss: 0.3449 - val_accuracy: 0.9085\n",
            "Epoch 360/1000\n",
            "500/500 [==============================] - 0s 663us/sample - loss: 0.3963 - accuracy: 0.8440 - val_loss: 0.3469 - val_accuracy: 0.8841\n",
            "Epoch 361/1000\n",
            "500/500 [==============================] - 0s 557us/sample - loss: 0.3485 - accuracy: 0.8620 - val_loss: 0.3436 - val_accuracy: 0.8963\n",
            "Epoch 362/1000\n",
            "500/500 [==============================] - 0s 595us/sample - loss: 0.3387 - accuracy: 0.8680 - val_loss: 0.3592 - val_accuracy: 0.8720\n",
            "Epoch 363/1000\n",
            "500/500 [==============================] - 0s 622us/sample - loss: 0.3593 - accuracy: 0.8680 - val_loss: 0.3518 - val_accuracy: 0.8780\n",
            "Epoch 364/1000\n",
            "500/500 [==============================] - 0s 601us/sample - loss: 0.3608 - accuracy: 0.8520 - val_loss: 0.3437 - val_accuracy: 0.8720\n",
            "Epoch 365/1000\n",
            "500/500 [==============================] - 0s 538us/sample - loss: 0.3218 - accuracy: 0.8880 - val_loss: 0.3461 - val_accuracy: 0.8720\n",
            "Epoch 366/1000\n",
            "500/500 [==============================] - 0s 625us/sample - loss: 0.3511 - accuracy: 0.8640 - val_loss: 0.3324 - val_accuracy: 0.9024\n",
            "Epoch 367/1000\n",
            "500/500 [==============================] - 0s 565us/sample - loss: 0.3044 - accuracy: 0.8780 - val_loss: 0.3387 - val_accuracy: 0.9024\n",
            "Epoch 368/1000\n",
            "500/500 [==============================] - 0s 558us/sample - loss: 0.3737 - accuracy: 0.8580 - val_loss: 0.3409 - val_accuracy: 0.8902\n",
            "Epoch 369/1000\n",
            "500/500 [==============================] - 0s 522us/sample - loss: 0.3524 - accuracy: 0.8620 - val_loss: 0.3448 - val_accuracy: 0.8902\n",
            "Epoch 370/1000\n",
            "500/500 [==============================] - 0s 570us/sample - loss: 0.3489 - accuracy: 0.8640 - val_loss: 0.3286 - val_accuracy: 0.8902\n",
            "Epoch 371/1000\n",
            "500/500 [==============================] - 0s 531us/sample - loss: 0.3450 - accuracy: 0.8540 - val_loss: 0.3360 - val_accuracy: 0.8720\n",
            "Epoch 372/1000\n",
            "500/500 [==============================] - 0s 629us/sample - loss: 0.3549 - accuracy: 0.8700 - val_loss: 0.3298 - val_accuracy: 0.8902\n",
            "Epoch 373/1000\n",
            "500/500 [==============================] - 0s 567us/sample - loss: 0.3470 - accuracy: 0.8640 - val_loss: 0.3351 - val_accuracy: 0.8963\n",
            "Epoch 374/1000\n",
            "500/500 [==============================] - 0s 620us/sample - loss: 0.3556 - accuracy: 0.8640 - val_loss: 0.3309 - val_accuracy: 0.8902\n",
            "Epoch 375/1000\n",
            "500/500 [==============================] - 0s 606us/sample - loss: 0.3408 - accuracy: 0.8720 - val_loss: 0.3288 - val_accuracy: 0.8902\n",
            "Epoch 376/1000\n",
            "500/500 [==============================] - 0s 652us/sample - loss: 0.3391 - accuracy: 0.8660 - val_loss: 0.3274 - val_accuracy: 0.8902\n",
            "Epoch 377/1000\n",
            "500/500 [==============================] - 0s 609us/sample - loss: 0.3395 - accuracy: 0.8800 - val_loss: 0.3299 - val_accuracy: 0.8841\n",
            "Epoch 378/1000\n",
            "500/500 [==============================] - 0s 516us/sample - loss: 0.3502 - accuracy: 0.8520 - val_loss: 0.3361 - val_accuracy: 0.8902\n",
            "Epoch 379/1000\n",
            "500/500 [==============================] - 0s 681us/sample - loss: 0.3520 - accuracy: 0.8700 - val_loss: 0.3374 - val_accuracy: 0.8963\n",
            "Epoch 380/1000\n",
            "500/500 [==============================] - 0s 609us/sample - loss: 0.3324 - accuracy: 0.8800 - val_loss: 0.3453 - val_accuracy: 0.8963\n",
            "Epoch 381/1000\n",
            "500/500 [==============================] - 0s 549us/sample - loss: 0.3679 - accuracy: 0.8580 - val_loss: 0.3336 - val_accuracy: 0.8963\n",
            "Epoch 382/1000\n",
            "500/500 [==============================] - 0s 586us/sample - loss: 0.3446 - accuracy: 0.8640 - val_loss: 0.3384 - val_accuracy: 0.8963\n",
            "Epoch 383/1000\n",
            "500/500 [==============================] - 0s 643us/sample - loss: 0.3140 - accuracy: 0.9040 - val_loss: 0.3499 - val_accuracy: 0.8963\n",
            "Epoch 384/1000\n",
            "500/500 [==============================] - 0s 540us/sample - loss: 0.3320 - accuracy: 0.8720 - val_loss: 0.3437 - val_accuracy: 0.8902\n",
            "Epoch 385/1000\n",
            "500/500 [==============================] - 0s 512us/sample - loss: 0.3277 - accuracy: 0.8700 - val_loss: 0.3392 - val_accuracy: 0.8902\n",
            "Epoch 386/1000\n",
            "500/500 [==============================] - 0s 584us/sample - loss: 0.3147 - accuracy: 0.8920 - val_loss: 0.3368 - val_accuracy: 0.8780\n",
            "Epoch 387/1000\n",
            "500/500 [==============================] - 0s 569us/sample - loss: 0.3672 - accuracy: 0.8640 - val_loss: 0.3357 - val_accuracy: 0.8841\n",
            "Epoch 388/1000\n",
            "500/500 [==============================] - 0s 624us/sample - loss: 0.3653 - accuracy: 0.8720 - val_loss: 0.3416 - val_accuracy: 0.8963\n",
            "Epoch 389/1000\n",
            "500/500 [==============================] - 0s 626us/sample - loss: 0.4030 - accuracy: 0.8300 - val_loss: 0.3533 - val_accuracy: 0.8902\n",
            "Epoch 390/1000\n",
            "500/500 [==============================] - 0s 639us/sample - loss: 0.3618 - accuracy: 0.8420 - val_loss: 0.3583 - val_accuracy: 0.8841\n",
            "Epoch 391/1000\n",
            "500/500 [==============================] - 0s 563us/sample - loss: 0.3585 - accuracy: 0.8480 - val_loss: 0.3474 - val_accuracy: 0.8780\n",
            "Epoch 392/1000\n",
            "500/500 [==============================] - 0s 516us/sample - loss: 0.3459 - accuracy: 0.8680 - val_loss: 0.3469 - val_accuracy: 0.8841\n",
            "Epoch 393/1000\n",
            "500/500 [==============================] - 0s 614us/sample - loss: 0.3262 - accuracy: 0.8720 - val_loss: 0.3486 - val_accuracy: 0.8902\n",
            "Epoch 394/1000\n",
            "500/500 [==============================] - 0s 555us/sample - loss: 0.3110 - accuracy: 0.8800 - val_loss: 0.3469 - val_accuracy: 0.8841\n",
            "Epoch 395/1000\n",
            "500/500 [==============================] - 0s 532us/sample - loss: 0.3314 - accuracy: 0.8520 - val_loss: 0.3514 - val_accuracy: 0.8902\n",
            "Epoch 396/1000\n",
            "500/500 [==============================] - 0s 611us/sample - loss: 0.3470 - accuracy: 0.8740 - val_loss: 0.3443 - val_accuracy: 0.8780\n",
            "Epoch 397/1000\n",
            "500/500 [==============================] - 0s 648us/sample - loss: 0.3542 - accuracy: 0.8660 - val_loss: 0.3433 - val_accuracy: 0.8963\n",
            "Epoch 398/1000\n",
            "500/500 [==============================] - 0s 608us/sample - loss: 0.3150 - accuracy: 0.8800 - val_loss: 0.3395 - val_accuracy: 0.8902\n",
            "Epoch 399/1000\n",
            "500/500 [==============================] - 0s 618us/sample - loss: 0.3408 - accuracy: 0.8700 - val_loss: 0.3460 - val_accuracy: 0.8841\n",
            "Epoch 400/1000\n",
            "500/500 [==============================] - 0s 677us/sample - loss: 0.3340 - accuracy: 0.8500 - val_loss: 0.3432 - val_accuracy: 0.9085\n",
            "Epoch 401/1000\n",
            "500/500 [==============================] - 0s 608us/sample - loss: 0.3506 - accuracy: 0.8620 - val_loss: 0.3351 - val_accuracy: 0.9085\n",
            "Epoch 402/1000\n",
            "500/500 [==============================] - 0s 579us/sample - loss: 0.3377 - accuracy: 0.8740 - val_loss: 0.3370 - val_accuracy: 0.8963\n",
            "Epoch 403/1000\n",
            "500/500 [==============================] - 0s 652us/sample - loss: 0.3390 - accuracy: 0.8860 - val_loss: 0.3414 - val_accuracy: 0.8963\n",
            "Epoch 404/1000\n",
            "500/500 [==============================] - 0s 589us/sample - loss: 0.3612 - accuracy: 0.8780 - val_loss: 0.3360 - val_accuracy: 0.8841\n",
            "Epoch 405/1000\n",
            "500/500 [==============================] - 0s 543us/sample - loss: 0.2984 - accuracy: 0.8840 - val_loss: 0.3430 - val_accuracy: 0.8902\n",
            "Epoch 406/1000\n",
            "500/500 [==============================] - 0s 613us/sample - loss: 0.3590 - accuracy: 0.8620 - val_loss: 0.3455 - val_accuracy: 0.8963\n",
            "Epoch 407/1000\n",
            "500/500 [==============================] - 0s 630us/sample - loss: 0.3331 - accuracy: 0.8560 - val_loss: 0.3457 - val_accuracy: 0.8902\n",
            "Epoch 408/1000\n",
            "500/500 [==============================] - 0s 561us/sample - loss: 0.3297 - accuracy: 0.8640 - val_loss: 0.3434 - val_accuracy: 0.8963\n",
            "Epoch 409/1000\n",
            "500/500 [==============================] - 0s 624us/sample - loss: 0.3755 - accuracy: 0.8280 - val_loss: 0.3542 - val_accuracy: 0.8902\n",
            "Epoch 410/1000\n",
            "500/500 [==============================] - 0s 592us/sample - loss: 0.3715 - accuracy: 0.8640 - val_loss: 0.3466 - val_accuracy: 0.8841\n",
            "Epoch 411/1000\n",
            "500/500 [==============================] - 0s 576us/sample - loss: 0.3626 - accuracy: 0.8560 - val_loss: 0.3350 - val_accuracy: 0.8780\n",
            "Epoch 412/1000\n",
            "500/500 [==============================] - 0s 627us/sample - loss: 0.3524 - accuracy: 0.8700 - val_loss: 0.3441 - val_accuracy: 0.8780\n",
            "Epoch 413/1000\n",
            "500/500 [==============================] - 0s 631us/sample - loss: 0.3539 - accuracy: 0.8660 - val_loss: 0.3310 - val_accuracy: 0.9024\n",
            "Epoch 414/1000\n",
            "500/500 [==============================] - 0s 613us/sample - loss: 0.3146 - accuracy: 0.8800 - val_loss: 0.3360 - val_accuracy: 0.8841\n",
            "Epoch 415/1000\n",
            "500/500 [==============================] - 0s 616us/sample - loss: 0.3073 - accuracy: 0.8780 - val_loss: 0.3457 - val_accuracy: 0.8841\n",
            "Epoch 416/1000\n",
            "500/500 [==============================] - 0s 611us/sample - loss: 0.3777 - accuracy: 0.8560 - val_loss: 0.3363 - val_accuracy: 0.8963\n",
            "Epoch 417/1000\n",
            "500/500 [==============================] - 0s 631us/sample - loss: 0.3441 - accuracy: 0.8740 - val_loss: 0.3343 - val_accuracy: 0.9024\n",
            "Epoch 418/1000\n",
            "500/500 [==============================] - 0s 632us/sample - loss: 0.3528 - accuracy: 0.8700 - val_loss: 0.3285 - val_accuracy: 0.9085\n",
            "Epoch 419/1000\n",
            "500/500 [==============================] - 0s 614us/sample - loss: 0.3082 - accuracy: 0.8780 - val_loss: 0.3246 - val_accuracy: 0.8841\n",
            "Epoch 420/1000\n",
            "500/500 [==============================] - 0s 588us/sample - loss: 0.3079 - accuracy: 0.8900 - val_loss: 0.3227 - val_accuracy: 0.8963\n",
            "Epoch 421/1000\n",
            "500/500 [==============================] - 0s 567us/sample - loss: 0.3550 - accuracy: 0.8560 - val_loss: 0.3212 - val_accuracy: 0.8902\n",
            "Epoch 422/1000\n",
            "500/500 [==============================] - 0s 574us/sample - loss: 0.3355 - accuracy: 0.8520 - val_loss: 0.3303 - val_accuracy: 0.8963\n",
            "Epoch 423/1000\n",
            "500/500 [==============================] - 0s 682us/sample - loss: 0.3678 - accuracy: 0.8560 - val_loss: 0.3297 - val_accuracy: 0.8963\n",
            "Epoch 424/1000\n",
            "500/500 [==============================] - 0s 605us/sample - loss: 0.3351 - accuracy: 0.8680 - val_loss: 0.3260 - val_accuracy: 0.8963\n",
            "Epoch 425/1000\n",
            "500/500 [==============================] - 0s 523us/sample - loss: 0.3382 - accuracy: 0.8720 - val_loss: 0.3327 - val_accuracy: 0.9024\n",
            "Epoch 426/1000\n",
            "500/500 [==============================] - 0s 649us/sample - loss: 0.3195 - accuracy: 0.8620 - val_loss: 0.3342 - val_accuracy: 0.9024\n",
            "Epoch 427/1000\n",
            "500/500 [==============================] - 0s 610us/sample - loss: 0.3137 - accuracy: 0.8900 - val_loss: 0.3398 - val_accuracy: 0.8902\n",
            "Epoch 428/1000\n",
            "500/500 [==============================] - 0s 606us/sample - loss: 0.3450 - accuracy: 0.8720 - val_loss: 0.3290 - val_accuracy: 0.8902\n",
            "Epoch 429/1000\n",
            "500/500 [==============================] - 0s 631us/sample - loss: 0.3404 - accuracy: 0.8800 - val_loss: 0.3310 - val_accuracy: 0.8841\n",
            "Epoch 430/1000\n",
            "500/500 [==============================] - 0s 629us/sample - loss: 0.3316 - accuracy: 0.8720 - val_loss: 0.3340 - val_accuracy: 0.9024\n",
            "Epoch 431/1000\n",
            "500/500 [==============================] - 0s 580us/sample - loss: 0.3249 - accuracy: 0.8800 - val_loss: 0.3301 - val_accuracy: 0.9024\n",
            "Epoch 432/1000\n",
            "500/500 [==============================] - 0s 614us/sample - loss: 0.3367 - accuracy: 0.8660 - val_loss: 0.3324 - val_accuracy: 0.8841\n",
            "Epoch 433/1000\n",
            "500/500 [==============================] - 0s 630us/sample - loss: 0.3473 - accuracy: 0.8660 - val_loss: 0.3342 - val_accuracy: 0.8902\n",
            "Epoch 434/1000\n",
            "500/500 [==============================] - 0s 592us/sample - loss: 0.3398 - accuracy: 0.8720 - val_loss: 0.3411 - val_accuracy: 0.8902\n",
            "Epoch 435/1000\n",
            "500/500 [==============================] - 0s 578us/sample - loss: 0.3183 - accuracy: 0.8740 - val_loss: 0.3492 - val_accuracy: 0.8902\n",
            "Epoch 436/1000\n",
            "500/500 [==============================] - 0s 623us/sample - loss: 0.3432 - accuracy: 0.8660 - val_loss: 0.3553 - val_accuracy: 0.8902\n",
            "Epoch 437/1000\n",
            "500/500 [==============================] - 0s 570us/sample - loss: 0.3580 - accuracy: 0.8660 - val_loss: 0.3543 - val_accuracy: 0.8963\n",
            "Epoch 438/1000\n",
            "500/500 [==============================] - 0s 590us/sample - loss: 0.3434 - accuracy: 0.8620 - val_loss: 0.3578 - val_accuracy: 0.8780\n",
            "Epoch 439/1000\n",
            "500/500 [==============================] - 0s 623us/sample - loss: 0.3301 - accuracy: 0.8700 - val_loss: 0.3541 - val_accuracy: 0.8902\n",
            "Epoch 440/1000\n",
            "500/500 [==============================] - 0s 608us/sample - loss: 0.3775 - accuracy: 0.8540 - val_loss: 0.3416 - val_accuracy: 0.8963\n",
            "Epoch 441/1000\n",
            "500/500 [==============================] - 0s 575us/sample - loss: 0.3358 - accuracy: 0.8780 - val_loss: 0.3394 - val_accuracy: 0.8963\n",
            "Epoch 442/1000\n",
            "500/500 [==============================] - 0s 608us/sample - loss: 0.3505 - accuracy: 0.8680 - val_loss: 0.3426 - val_accuracy: 0.8963\n",
            "Epoch 443/1000\n",
            "500/500 [==============================] - 0s 616us/sample - loss: 0.3626 - accuracy: 0.8800 - val_loss: 0.3306 - val_accuracy: 0.8963\n",
            "Epoch 444/1000\n",
            "500/500 [==============================] - 0s 606us/sample - loss: 0.3076 - accuracy: 0.8900 - val_loss: 0.3344 - val_accuracy: 0.8902\n",
            "Epoch 445/1000\n",
            "500/500 [==============================] - 0s 664us/sample - loss: 0.3043 - accuracy: 0.8900 - val_loss: 0.3369 - val_accuracy: 0.8963\n",
            "Epoch 446/1000\n",
            "500/500 [==============================] - 0s 655us/sample - loss: 0.3289 - accuracy: 0.8840 - val_loss: 0.3392 - val_accuracy: 0.9024\n",
            "Epoch 447/1000\n",
            "500/500 [==============================] - 0s 599us/sample - loss: 0.3499 - accuracy: 0.8700 - val_loss: 0.3421 - val_accuracy: 0.8963\n",
            "Epoch 448/1000\n",
            "500/500 [==============================] - 0s 565us/sample - loss: 0.3101 - accuracy: 0.8800 - val_loss: 0.3425 - val_accuracy: 0.8902\n",
            "Epoch 449/1000\n",
            "500/500 [==============================] - 0s 627us/sample - loss: 0.3282 - accuracy: 0.8740 - val_loss: 0.3491 - val_accuracy: 0.8780\n",
            "Epoch 450/1000\n",
            "500/500 [==============================] - 0s 633us/sample - loss: 0.3307 - accuracy: 0.8640 - val_loss: 0.3458 - val_accuracy: 0.8902\n",
            "Epoch 451/1000\n",
            "500/500 [==============================] - 0s 529us/sample - loss: 0.3199 - accuracy: 0.8640 - val_loss: 0.3507 - val_accuracy: 0.8902\n",
            "Epoch 452/1000\n",
            "500/500 [==============================] - 0s 658us/sample - loss: 0.3451 - accuracy: 0.8620 - val_loss: 0.3463 - val_accuracy: 0.8841\n",
            "Epoch 453/1000\n",
            "500/500 [==============================] - 0s 568us/sample - loss: 0.3218 - accuracy: 0.8680 - val_loss: 0.3384 - val_accuracy: 0.8902\n",
            "Epoch 454/1000\n",
            "500/500 [==============================] - 0s 577us/sample - loss: 0.3130 - accuracy: 0.8780 - val_loss: 0.3376 - val_accuracy: 0.8902\n",
            "Epoch 455/1000\n",
            "500/500 [==============================] - 0s 587us/sample - loss: 0.3101 - accuracy: 0.8640 - val_loss: 0.3303 - val_accuracy: 0.8902\n",
            "Epoch 456/1000\n",
            "500/500 [==============================] - 0s 639us/sample - loss: 0.3340 - accuracy: 0.8660 - val_loss: 0.3273 - val_accuracy: 0.8963\n",
            "Epoch 457/1000\n",
            "500/500 [==============================] - 0s 525us/sample - loss: 0.3433 - accuracy: 0.8480 - val_loss: 0.3230 - val_accuracy: 0.8963\n",
            "Epoch 458/1000\n",
            "500/500 [==============================] - 0s 509us/sample - loss: 0.3048 - accuracy: 0.8940 - val_loss: 0.3285 - val_accuracy: 0.9024\n",
            "Epoch 459/1000\n",
            "500/500 [==============================] - 0s 605us/sample - loss: 0.3648 - accuracy: 0.8600 - val_loss: 0.3336 - val_accuracy: 0.8841\n",
            "Epoch 460/1000\n",
            "500/500 [==============================] - 0s 607us/sample - loss: 0.3446 - accuracy: 0.8740 - val_loss: 0.3399 - val_accuracy: 0.8659\n",
            "Epoch 461/1000\n",
            "500/500 [==============================] - 0s 536us/sample - loss: 0.2999 - accuracy: 0.8860 - val_loss: 0.3513 - val_accuracy: 0.8720\n",
            "Epoch 462/1000\n",
            "500/500 [==============================] - 0s 617us/sample - loss: 0.3719 - accuracy: 0.8560 - val_loss: 0.3173 - val_accuracy: 0.8841\n",
            "Epoch 463/1000\n",
            "500/500 [==============================] - 0s 573us/sample - loss: 0.3329 - accuracy: 0.8580 - val_loss: 0.3202 - val_accuracy: 0.8841\n",
            "Epoch 464/1000\n",
            "500/500 [==============================] - 0s 607us/sample - loss: 0.3480 - accuracy: 0.8620 - val_loss: 0.3205 - val_accuracy: 0.8841\n",
            "Epoch 465/1000\n",
            "500/500 [==============================] - 0s 556us/sample - loss: 0.3268 - accuracy: 0.8880 - val_loss: 0.3225 - val_accuracy: 0.8841\n",
            "Epoch 466/1000\n",
            "500/500 [==============================] - 0s 636us/sample - loss: 0.3320 - accuracy: 0.8740 - val_loss: 0.3252 - val_accuracy: 0.8902\n",
            "Epoch 467/1000\n",
            "500/500 [==============================] - 0s 579us/sample - loss: 0.3468 - accuracy: 0.8620 - val_loss: 0.3255 - val_accuracy: 0.8902\n",
            "Epoch 468/1000\n",
            "500/500 [==============================] - 0s 549us/sample - loss: 0.3182 - accuracy: 0.8780 - val_loss: 0.3370 - val_accuracy: 0.8841\n",
            "Epoch 469/1000\n",
            "500/500 [==============================] - 0s 609us/sample - loss: 0.3245 - accuracy: 0.8640 - val_loss: 0.3361 - val_accuracy: 0.8780\n",
            "Epoch 470/1000\n",
            "500/500 [==============================] - 0s 615us/sample - loss: 0.3246 - accuracy: 0.8680 - val_loss: 0.3305 - val_accuracy: 0.8841\n",
            "Epoch 471/1000\n",
            "500/500 [==============================] - 0s 621us/sample - loss: 0.3106 - accuracy: 0.8800 - val_loss: 0.3419 - val_accuracy: 0.8780\n",
            "Epoch 472/1000\n",
            "500/500 [==============================] - 0s 565us/sample - loss: 0.3105 - accuracy: 0.8880 - val_loss: 0.3286 - val_accuracy: 0.8720\n",
            "Epoch 473/1000\n",
            "500/500 [==============================] - 0s 589us/sample - loss: 0.3309 - accuracy: 0.8720 - val_loss: 0.3242 - val_accuracy: 0.8841\n",
            "Epoch 474/1000\n",
            "500/500 [==============================] - 0s 614us/sample - loss: 0.3132 - accuracy: 0.8820 - val_loss: 0.3257 - val_accuracy: 0.8902\n",
            "Epoch 475/1000\n",
            "500/500 [==============================] - 0s 610us/sample - loss: 0.3080 - accuracy: 0.8960 - val_loss: 0.3286 - val_accuracy: 0.8963\n",
            "Epoch 476/1000\n",
            "500/500 [==============================] - 0s 629us/sample - loss: 0.3440 - accuracy: 0.8700 - val_loss: 0.3376 - val_accuracy: 0.8902\n",
            "Epoch 477/1000\n",
            "500/500 [==============================] - 0s 590us/sample - loss: 0.3477 - accuracy: 0.8620 - val_loss: 0.3392 - val_accuracy: 0.8841\n",
            "Epoch 478/1000\n",
            "500/500 [==============================] - 0s 612us/sample - loss: 0.3225 - accuracy: 0.8820 - val_loss: 0.3313 - val_accuracy: 0.8780\n",
            "Epoch 479/1000\n",
            "500/500 [==============================] - 0s 628us/sample - loss: 0.3200 - accuracy: 0.8760 - val_loss: 0.3468 - val_accuracy: 0.8720\n",
            "Epoch 480/1000\n",
            "500/500 [==============================] - 0s 628us/sample - loss: 0.3269 - accuracy: 0.8700 - val_loss: 0.3320 - val_accuracy: 0.8780\n",
            "Epoch 481/1000\n",
            "500/500 [==============================] - 0s 649us/sample - loss: 0.3314 - accuracy: 0.8780 - val_loss: 0.3257 - val_accuracy: 0.8780\n",
            "Epoch 482/1000\n",
            "500/500 [==============================] - 0s 623us/sample - loss: 0.3209 - accuracy: 0.8720 - val_loss: 0.3286 - val_accuracy: 0.8841\n",
            "Epoch 483/1000\n",
            "500/500 [==============================] - 0s 626us/sample - loss: 0.3337 - accuracy: 0.8740 - val_loss: 0.3195 - val_accuracy: 0.8902\n",
            "Epoch 484/1000\n",
            "500/500 [==============================] - 0s 616us/sample - loss: 0.2972 - accuracy: 0.8920 - val_loss: 0.3246 - val_accuracy: 0.8780\n",
            "Epoch 485/1000\n",
            "500/500 [==============================] - 0s 632us/sample - loss: 0.2903 - accuracy: 0.8920 - val_loss: 0.3256 - val_accuracy: 0.8780\n",
            "Epoch 486/1000\n",
            "500/500 [==============================] - 0s 682us/sample - loss: 0.3210 - accuracy: 0.8600 - val_loss: 0.3217 - val_accuracy: 0.8780\n",
            "Epoch 487/1000\n",
            "500/500 [==============================] - 0s 615us/sample - loss: 0.3151 - accuracy: 0.8920 - val_loss: 0.3197 - val_accuracy: 0.8720\n",
            "Epoch 488/1000\n",
            "500/500 [==============================] - 0s 570us/sample - loss: 0.3428 - accuracy: 0.8680 - val_loss: 0.3292 - val_accuracy: 0.8841\n",
            "Epoch 489/1000\n",
            "500/500 [==============================] - 0s 616us/sample - loss: 0.3389 - accuracy: 0.8580 - val_loss: 0.3303 - val_accuracy: 0.8780\n",
            "Epoch 490/1000\n",
            "500/500 [==============================] - 0s 621us/sample - loss: 0.3346 - accuracy: 0.8580 - val_loss: 0.3314 - val_accuracy: 0.8841\n",
            "Epoch 491/1000\n",
            "500/500 [==============================] - 0s 642us/sample - loss: 0.3374 - accuracy: 0.8580 - val_loss: 0.3295 - val_accuracy: 0.8902\n",
            "Epoch 492/1000\n",
            "500/500 [==============================] - 0s 609us/sample - loss: 0.3235 - accuracy: 0.8820 - val_loss: 0.3274 - val_accuracy: 0.8902\n",
            "Epoch 493/1000\n",
            "500/500 [==============================] - 0s 640us/sample - loss: 0.3237 - accuracy: 0.8780 - val_loss: 0.3263 - val_accuracy: 0.9085\n",
            "Epoch 494/1000\n",
            "500/500 [==============================] - 0s 647us/sample - loss: 0.3214 - accuracy: 0.8860 - val_loss: 0.3182 - val_accuracy: 0.9146\n",
            "Epoch 495/1000\n",
            "500/500 [==============================] - 0s 538us/sample - loss: 0.3513 - accuracy: 0.8460 - val_loss: 0.3142 - val_accuracy: 0.8780\n",
            "Epoch 496/1000\n",
            "500/500 [==============================] - 0s 543us/sample - loss: 0.2879 - accuracy: 0.8860 - val_loss: 0.3177 - val_accuracy: 0.8780\n",
            "Epoch 497/1000\n",
            "500/500 [==============================] - 0s 601us/sample - loss: 0.3045 - accuracy: 0.8700 - val_loss: 0.3306 - val_accuracy: 0.8902\n",
            "Epoch 498/1000\n",
            "500/500 [==============================] - 0s 648us/sample - loss: 0.3103 - accuracy: 0.8780 - val_loss: 0.3385 - val_accuracy: 0.8841\n",
            "Epoch 499/1000\n",
            "500/500 [==============================] - 0s 577us/sample - loss: 0.3311 - accuracy: 0.8780 - val_loss: 0.3535 - val_accuracy: 0.8659\n",
            "Epoch 500/1000\n",
            "500/500 [==============================] - 0s 626us/sample - loss: 0.3331 - accuracy: 0.8660 - val_loss: 0.3571 - val_accuracy: 0.8720\n",
            "Epoch 501/1000\n",
            "500/500 [==============================] - 0s 660us/sample - loss: 0.3634 - accuracy: 0.8620 - val_loss: 0.3557 - val_accuracy: 0.8659\n",
            "Epoch 502/1000\n",
            "500/500 [==============================] - 0s 640us/sample - loss: 0.3379 - accuracy: 0.8720 - val_loss: 0.3571 - val_accuracy: 0.8720\n",
            "Epoch 503/1000\n",
            "500/500 [==============================] - 0s 617us/sample - loss: 0.3050 - accuracy: 0.9000 - val_loss: 0.3412 - val_accuracy: 0.8902\n",
            "Epoch 504/1000\n",
            "500/500 [==============================] - 0s 638us/sample - loss: 0.3258 - accuracy: 0.8840 - val_loss: 0.3604 - val_accuracy: 0.8720\n",
            "Epoch 505/1000\n",
            "500/500 [==============================] - 0s 572us/sample - loss: 0.3325 - accuracy: 0.8740 - val_loss: 0.3476 - val_accuracy: 0.8841\n",
            "Epoch 506/1000\n",
            "500/500 [==============================] - 0s 511us/sample - loss: 0.3324 - accuracy: 0.8740 - val_loss: 0.3162 - val_accuracy: 0.8963\n",
            "Epoch 507/1000\n",
            "500/500 [==============================] - 0s 550us/sample - loss: 0.3467 - accuracy: 0.8680 - val_loss: 0.3145 - val_accuracy: 0.9024\n",
            "Epoch 508/1000\n",
            "500/500 [==============================] - 0s 658us/sample - loss: 0.3360 - accuracy: 0.8740 - val_loss: 0.3235 - val_accuracy: 0.9085\n",
            "Epoch 509/1000\n",
            "500/500 [==============================] - 0s 609us/sample - loss: 0.3018 - accuracy: 0.8740 - val_loss: 0.3324 - val_accuracy: 0.8841\n",
            "Epoch 510/1000\n",
            "500/500 [==============================] - 0s 573us/sample - loss: 0.3216 - accuracy: 0.8740 - val_loss: 0.3546 - val_accuracy: 0.8780\n",
            "Epoch 511/1000\n",
            "500/500 [==============================] - 0s 640us/sample - loss: 0.2979 - accuracy: 0.8960 - val_loss: 0.3530 - val_accuracy: 0.8780\n",
            "Epoch 512/1000\n",
            "500/500 [==============================] - 0s 623us/sample - loss: 0.3451 - accuracy: 0.8780 - val_loss: 0.3201 - val_accuracy: 0.8902\n",
            "Epoch 513/1000\n",
            "500/500 [==============================] - 0s 607us/sample - loss: 0.3400 - accuracy: 0.8660 - val_loss: 0.3204 - val_accuracy: 0.8902\n",
            "Epoch 514/1000\n",
            "500/500 [==============================] - 0s 588us/sample - loss: 0.3281 - accuracy: 0.8620 - val_loss: 0.3155 - val_accuracy: 0.9085\n",
            "Epoch 515/1000\n",
            "500/500 [==============================] - 0s 620us/sample - loss: 0.3647 - accuracy: 0.8480 - val_loss: 0.3320 - val_accuracy: 0.8720\n",
            "Epoch 516/1000\n",
            "500/500 [==============================] - 0s 563us/sample - loss: 0.3255 - accuracy: 0.8700 - val_loss: 0.3478 - val_accuracy: 0.8780\n",
            "Epoch 517/1000\n",
            "500/500 [==============================] - 0s 581us/sample - loss: 0.3450 - accuracy: 0.8700 - val_loss: 0.3438 - val_accuracy: 0.8841\n",
            "Epoch 518/1000\n",
            "500/500 [==============================] - 0s 642us/sample - loss: 0.3367 - accuracy: 0.8600 - val_loss: 0.3303 - val_accuracy: 0.9024\n",
            "Epoch 519/1000\n",
            "500/500 [==============================] - 0s 614us/sample - loss: 0.3209 - accuracy: 0.8760 - val_loss: 0.3374 - val_accuracy: 0.8902\n",
            "Epoch 520/1000\n",
            "500/500 [==============================] - 0s 502us/sample - loss: 0.3255 - accuracy: 0.8780 - val_loss: 0.3376 - val_accuracy: 0.8780\n",
            "Epoch 521/1000\n",
            "500/500 [==============================] - 0s 650us/sample - loss: 0.3351 - accuracy: 0.8700 - val_loss: 0.3256 - val_accuracy: 0.8841\n",
            "Epoch 522/1000\n",
            "500/500 [==============================] - 0s 569us/sample - loss: 0.2956 - accuracy: 0.8820 - val_loss: 0.3269 - val_accuracy: 0.8963\n",
            "Epoch 523/1000\n",
            "500/500 [==============================] - 0s 684us/sample - loss: 0.3495 - accuracy: 0.8560 - val_loss: 0.3294 - val_accuracy: 0.8841\n",
            "Epoch 524/1000\n",
            "500/500 [==============================] - 0s 638us/sample - loss: 0.3016 - accuracy: 0.8980 - val_loss: 0.3372 - val_accuracy: 0.8902\n",
            "Epoch 525/1000\n",
            "500/500 [==============================] - 0s 623us/sample - loss: 0.3282 - accuracy: 0.8720 - val_loss: 0.3245 - val_accuracy: 0.8841\n",
            "Epoch 526/1000\n",
            "500/500 [==============================] - 0s 587us/sample - loss: 0.3252 - accuracy: 0.8680 - val_loss: 0.3342 - val_accuracy: 0.8902\n",
            "Epoch 527/1000\n",
            "500/500 [==============================] - 0s 510us/sample - loss: 0.2801 - accuracy: 0.8940 - val_loss: 0.3332 - val_accuracy: 0.8902\n",
            "Epoch 528/1000\n",
            "500/500 [==============================] - 0s 652us/sample - loss: 0.3336 - accuracy: 0.8700 - val_loss: 0.3407 - val_accuracy: 0.8902\n",
            "Epoch 529/1000\n",
            "500/500 [==============================] - 0s 560us/sample - loss: 0.2849 - accuracy: 0.8880 - val_loss: 0.3381 - val_accuracy: 0.8902\n",
            "Epoch 530/1000\n",
            "500/500 [==============================] - 0s 592us/sample - loss: 0.3371 - accuracy: 0.8660 - val_loss: 0.3305 - val_accuracy: 0.8902\n",
            "Epoch 531/1000\n",
            "500/500 [==============================] - 0s 653us/sample - loss: 0.3421 - accuracy: 0.8740 - val_loss: 0.3328 - val_accuracy: 0.9024\n",
            "Epoch 532/1000\n",
            "500/500 [==============================] - 0s 564us/sample - loss: 0.2933 - accuracy: 0.8940 - val_loss: 0.3401 - val_accuracy: 0.9085\n",
            "Epoch 533/1000\n",
            "500/500 [==============================] - 0s 521us/sample - loss: 0.3356 - accuracy: 0.8900 - val_loss: 0.3402 - val_accuracy: 0.8963\n",
            "Epoch 534/1000\n",
            "500/500 [==============================] - 0s 532us/sample - loss: 0.2978 - accuracy: 0.8960 - val_loss: 0.3285 - val_accuracy: 0.8902\n",
            "Epoch 535/1000\n",
            "500/500 [==============================] - 0s 651us/sample - loss: 0.3287 - accuracy: 0.8760 - val_loss: 0.3499 - val_accuracy: 0.8841\n",
            "Epoch 536/1000\n",
            "500/500 [==============================] - 0s 594us/sample - loss: 0.3109 - accuracy: 0.8840 - val_loss: 0.3229 - val_accuracy: 0.8841\n",
            "Epoch 537/1000\n",
            "500/500 [==============================] - 0s 604us/sample - loss: 0.3391 - accuracy: 0.8720 - val_loss: 0.3257 - val_accuracy: 0.9085\n",
            "Epoch 538/1000\n",
            "500/500 [==============================] - 0s 644us/sample - loss: 0.3260 - accuracy: 0.8760 - val_loss: 0.3347 - val_accuracy: 0.8902\n",
            "Epoch 539/1000\n",
            "500/500 [==============================] - 0s 603us/sample - loss: 0.3380 - accuracy: 0.8780 - val_loss: 0.3608 - val_accuracy: 0.8780\n",
            "Epoch 540/1000\n",
            "500/500 [==============================] - 0s 562us/sample - loss: 0.3298 - accuracy: 0.8780 - val_loss: 0.3379 - val_accuracy: 0.9085\n",
            "Epoch 541/1000\n",
            "500/500 [==============================] - 0s 643us/sample - loss: 0.3090 - accuracy: 0.8900 - val_loss: 0.3279 - val_accuracy: 0.9085\n",
            "Epoch 542/1000\n",
            "500/500 [==============================] - 0s 605us/sample - loss: 0.3143 - accuracy: 0.8960 - val_loss: 0.3228 - val_accuracy: 0.9085\n",
            "Epoch 543/1000\n",
            "500/500 [==============================] - 0s 621us/sample - loss: 0.3320 - accuracy: 0.8700 - val_loss: 0.3379 - val_accuracy: 0.9024\n",
            "Epoch 544/1000\n",
            "500/500 [==============================] - 0s 540us/sample - loss: 0.3537 - accuracy: 0.8580 - val_loss: 0.3267 - val_accuracy: 0.8963\n",
            "Epoch 545/1000\n",
            "500/500 [==============================] - 0s 584us/sample - loss: 0.2858 - accuracy: 0.8860 - val_loss: 0.3370 - val_accuracy: 0.9024\n",
            "Epoch 546/1000\n",
            "500/500 [==============================] - 0s 539us/sample - loss: 0.3350 - accuracy: 0.8680 - val_loss: 0.3393 - val_accuracy: 0.8780\n",
            "Epoch 547/1000\n",
            "500/500 [==============================] - 0s 602us/sample - loss: 0.3256 - accuracy: 0.9020 - val_loss: 0.3434 - val_accuracy: 0.8841\n",
            "Epoch 548/1000\n",
            "500/500 [==============================] - 0s 636us/sample - loss: 0.3251 - accuracy: 0.8880 - val_loss: 0.3413 - val_accuracy: 0.8780\n",
            "Epoch 549/1000\n",
            "500/500 [==============================] - 0s 542us/sample - loss: 0.3101 - accuracy: 0.8740 - val_loss: 0.3457 - val_accuracy: 0.8780\n",
            "Epoch 550/1000\n",
            "500/500 [==============================] - 0s 639us/sample - loss: 0.3354 - accuracy: 0.8720 - val_loss: 0.3445 - val_accuracy: 0.8780\n",
            "Epoch 551/1000\n",
            "500/500 [==============================] - 0s 625us/sample - loss: 0.2899 - accuracy: 0.8840 - val_loss: 0.3386 - val_accuracy: 0.8780\n",
            "Epoch 552/1000\n",
            "500/500 [==============================] - 0s 632us/sample - loss: 0.3248 - accuracy: 0.8620 - val_loss: 0.3383 - val_accuracy: 0.8902\n",
            "Epoch 553/1000\n",
            "500/500 [==============================] - 0s 580us/sample - loss: 0.3472 - accuracy: 0.8820 - val_loss: 0.3359 - val_accuracy: 0.8902\n",
            "Epoch 554/1000\n",
            "500/500 [==============================] - 0s 600us/sample - loss: 0.3140 - accuracy: 0.8760 - val_loss: 0.3397 - val_accuracy: 0.8780\n",
            "Epoch 555/1000\n",
            "500/500 [==============================] - 0s 529us/sample - loss: 0.3316 - accuracy: 0.8760 - val_loss: 0.3202 - val_accuracy: 0.8841\n",
            "Epoch 556/1000\n",
            "500/500 [==============================] - 0s 531us/sample - loss: 0.3431 - accuracy: 0.8780 - val_loss: 0.3190 - val_accuracy: 0.8902\n",
            "Epoch 557/1000\n",
            "500/500 [==============================] - 0s 515us/sample - loss: 0.3316 - accuracy: 0.8680 - val_loss: 0.3287 - val_accuracy: 0.8963\n",
            "Epoch 558/1000\n",
            "500/500 [==============================] - 0s 590us/sample - loss: 0.3494 - accuracy: 0.8700 - val_loss: 0.3288 - val_accuracy: 0.8841\n",
            "Epoch 559/1000\n",
            "500/500 [==============================] - 0s 585us/sample - loss: 0.3058 - accuracy: 0.8720 - val_loss: 0.3413 - val_accuracy: 0.8720\n",
            "Epoch 560/1000\n",
            "500/500 [==============================] - 0s 585us/sample - loss: 0.3452 - accuracy: 0.8720 - val_loss: 0.3368 - val_accuracy: 0.8963\n",
            "Epoch 561/1000\n",
            "500/500 [==============================] - 0s 622us/sample - loss: 0.3477 - accuracy: 0.8500 - val_loss: 0.3299 - val_accuracy: 0.8902\n",
            "Epoch 562/1000\n",
            "500/500 [==============================] - 0s 619us/sample - loss: 0.3212 - accuracy: 0.8760 - val_loss: 0.3211 - val_accuracy: 0.9024\n",
            "Epoch 563/1000\n",
            "500/500 [==============================] - 0s 529us/sample - loss: 0.3210 - accuracy: 0.8640 - val_loss: 0.3303 - val_accuracy: 0.9024\n",
            "Epoch 564/1000\n",
            "500/500 [==============================] - 0s 628us/sample - loss: 0.3119 - accuracy: 0.8720 - val_loss: 0.3250 - val_accuracy: 0.8902\n",
            "Epoch 565/1000\n",
            "500/500 [==============================] - 0s 629us/sample - loss: 0.3507 - accuracy: 0.8580 - val_loss: 0.3239 - val_accuracy: 0.9024\n",
            "Epoch 566/1000\n",
            "500/500 [==============================] - 0s 513us/sample - loss: 0.3020 - accuracy: 0.9000 - val_loss: 0.3248 - val_accuracy: 0.8902\n",
            "Epoch 567/1000\n",
            "500/500 [==============================] - 0s 574us/sample - loss: 0.3168 - accuracy: 0.8780 - val_loss: 0.3201 - val_accuracy: 0.8780\n",
            "Epoch 568/1000\n",
            "500/500 [==============================] - 0s 627us/sample - loss: 0.3493 - accuracy: 0.8540 - val_loss: 0.3260 - val_accuracy: 0.8902\n",
            "Epoch 569/1000\n",
            "500/500 [==============================] - 0s 648us/sample - loss: 0.3414 - accuracy: 0.8700 - val_loss: 0.3348 - val_accuracy: 0.8902\n",
            "Epoch 570/1000\n",
            "500/500 [==============================] - 0s 560us/sample - loss: 0.3421 - accuracy: 0.8580 - val_loss: 0.3268 - val_accuracy: 0.9024\n",
            "Epoch 571/1000\n",
            "500/500 [==============================] - 0s 627us/sample - loss: 0.3020 - accuracy: 0.9020 - val_loss: 0.3377 - val_accuracy: 0.8902\n",
            "Epoch 572/1000\n",
            "500/500 [==============================] - 0s 657us/sample - loss: 0.3389 - accuracy: 0.8640 - val_loss: 0.3332 - val_accuracy: 0.8841\n",
            "Epoch 573/1000\n",
            "500/500 [==============================] - 0s 623us/sample - loss: 0.3238 - accuracy: 0.8720 - val_loss: 0.3363 - val_accuracy: 0.8902\n",
            "Epoch 574/1000\n",
            "500/500 [==============================] - 0s 651us/sample - loss: 0.3449 - accuracy: 0.8480 - val_loss: 0.3287 - val_accuracy: 0.8902\n",
            "Epoch 575/1000\n",
            "500/500 [==============================] - 0s 613us/sample - loss: 0.3002 - accuracy: 0.8760 - val_loss: 0.3362 - val_accuracy: 0.8720\n",
            "Epoch 576/1000\n",
            "500/500 [==============================] - 0s 593us/sample - loss: 0.3010 - accuracy: 0.8800 - val_loss: 0.3241 - val_accuracy: 0.8963\n",
            "Epoch 577/1000\n",
            "500/500 [==============================] - 0s 616us/sample - loss: 0.3056 - accuracy: 0.8960 - val_loss: 0.3321 - val_accuracy: 0.8841\n",
            "Epoch 578/1000\n",
            "500/500 [==============================] - 0s 592us/sample - loss: 0.3121 - accuracy: 0.8820 - val_loss: 0.3303 - val_accuracy: 0.8780\n",
            "Epoch 579/1000\n",
            "500/500 [==============================] - 0s 607us/sample - loss: 0.3015 - accuracy: 0.8980 - val_loss: 0.3205 - val_accuracy: 0.8902\n",
            "Epoch 580/1000\n",
            "500/500 [==============================] - 0s 592us/sample - loss: 0.3239 - accuracy: 0.8640 - val_loss: 0.3315 - val_accuracy: 0.8841\n",
            "Epoch 581/1000\n",
            "500/500 [==============================] - 0s 635us/sample - loss: 0.2954 - accuracy: 0.8940 - val_loss: 0.3255 - val_accuracy: 0.8780\n",
            "Epoch 582/1000\n",
            "500/500 [==============================] - 0s 581us/sample - loss: 0.3454 - accuracy: 0.8720 - val_loss: 0.3247 - val_accuracy: 0.8841\n",
            "Epoch 583/1000\n",
            "500/500 [==============================] - 0s 511us/sample - loss: 0.3394 - accuracy: 0.8660 - val_loss: 0.3273 - val_accuracy: 0.8841\n",
            "Epoch 584/1000\n",
            "500/500 [==============================] - 0s 519us/sample - loss: 0.3256 - accuracy: 0.8840 - val_loss: 0.3311 - val_accuracy: 0.8780\n",
            "Epoch 585/1000\n",
            "500/500 [==============================] - 0s 590us/sample - loss: 0.3477 - accuracy: 0.8800 - val_loss: 0.3340 - val_accuracy: 0.8841\n",
            "Epoch 586/1000\n",
            "500/500 [==============================] - 0s 595us/sample - loss: 0.3333 - accuracy: 0.8640 - val_loss: 0.3395 - val_accuracy: 0.8720\n",
            "Epoch 587/1000\n",
            "500/500 [==============================] - 0s 508us/sample - loss: 0.3428 - accuracy: 0.8680 - val_loss: 0.3228 - val_accuracy: 0.8902\n",
            "Epoch 588/1000\n",
            "500/500 [==============================] - 0s 575us/sample - loss: 0.3606 - accuracy: 0.8580 - val_loss: 0.3241 - val_accuracy: 0.8841\n",
            "Epoch 589/1000\n",
            "500/500 [==============================] - 0s 656us/sample - loss: 0.3066 - accuracy: 0.8740 - val_loss: 0.3281 - val_accuracy: 0.8841\n",
            "Epoch 590/1000\n",
            "500/500 [==============================] - 0s 637us/sample - loss: 0.3363 - accuracy: 0.8640 - val_loss: 0.3290 - val_accuracy: 0.8963\n",
            "Epoch 591/1000\n",
            "500/500 [==============================] - 0s 529us/sample - loss: 0.3127 - accuracy: 0.8820 - val_loss: 0.3288 - val_accuracy: 0.8780\n",
            "Epoch 592/1000\n",
            "500/500 [==============================] - 0s 607us/sample - loss: 0.3249 - accuracy: 0.8800 - val_loss: 0.3240 - val_accuracy: 0.8902\n",
            "Epoch 593/1000\n",
            "500/500 [==============================] - 0s 601us/sample - loss: 0.2964 - accuracy: 0.8980 - val_loss: 0.3334 - val_accuracy: 0.8902\n",
            "Epoch 594/1000\n",
            "500/500 [==============================] - 0s 554us/sample - loss: 0.3245 - accuracy: 0.8740 - val_loss: 0.3360 - val_accuracy: 0.8902\n",
            "Epoch 595/1000\n",
            "500/500 [==============================] - 0s 519us/sample - loss: 0.3282 - accuracy: 0.8580 - val_loss: 0.3242 - val_accuracy: 0.8902\n",
            "Epoch 596/1000\n",
            "500/500 [==============================] - 0s 624us/sample - loss: 0.3630 - accuracy: 0.8540 - val_loss: 0.3436 - val_accuracy: 0.8659\n",
            "Epoch 597/1000\n",
            "500/500 [==============================] - 0s 666us/sample - loss: 0.3305 - accuracy: 0.8760 - val_loss: 0.3343 - val_accuracy: 0.8841\n",
            "Epoch 598/1000\n",
            "500/500 [==============================] - 0s 638us/sample - loss: 0.3273 - accuracy: 0.8700 - val_loss: 0.3264 - val_accuracy: 0.8963\n",
            "Epoch 599/1000\n",
            "500/500 [==============================] - 0s 595us/sample - loss: 0.3437 - accuracy: 0.8680 - val_loss: 0.3206 - val_accuracy: 0.8902\n",
            "Epoch 600/1000\n",
            "500/500 [==============================] - 0s 603us/sample - loss: 0.3103 - accuracy: 0.8740 - val_loss: 0.3210 - val_accuracy: 0.8841\n",
            "Epoch 601/1000\n",
            "500/500 [==============================] - 0s 639us/sample - loss: 0.3370 - accuracy: 0.8760 - val_loss: 0.3317 - val_accuracy: 0.8780\n",
            "Epoch 602/1000\n",
            "500/500 [==============================] - 0s 648us/sample - loss: 0.2834 - accuracy: 0.8920 - val_loss: 0.3411 - val_accuracy: 0.8841\n",
            "Epoch 603/1000\n",
            "500/500 [==============================] - 0s 613us/sample - loss: 0.2893 - accuracy: 0.8700 - val_loss: 0.3427 - val_accuracy: 0.8902\n",
            "Epoch 604/1000\n",
            "500/500 [==============================] - 0s 595us/sample - loss: 0.3107 - accuracy: 0.8860 - val_loss: 0.3390 - val_accuracy: 0.8780\n",
            "Epoch 605/1000\n",
            "500/500 [==============================] - 0s 637us/sample - loss: 0.3359 - accuracy: 0.8520 - val_loss: 0.3370 - val_accuracy: 0.8780\n",
            "Epoch 606/1000\n",
            "500/500 [==============================] - 0s 590us/sample - loss: 0.3199 - accuracy: 0.8620 - val_loss: 0.3298 - val_accuracy: 0.8902\n",
            "Epoch 607/1000\n",
            "500/500 [==============================] - 0s 539us/sample - loss: 0.3438 - accuracy: 0.8780 - val_loss: 0.3355 - val_accuracy: 0.8841\n",
            "Epoch 608/1000\n",
            "500/500 [==============================] - 0s 616us/sample - loss: 0.2617 - accuracy: 0.9040 - val_loss: 0.3329 - val_accuracy: 0.8841\n",
            "Epoch 609/1000\n",
            "500/500 [==============================] - 0s 634us/sample - loss: 0.3074 - accuracy: 0.8920 - val_loss: 0.3250 - val_accuracy: 0.8902\n",
            "Epoch 610/1000\n",
            "500/500 [==============================] - 0s 584us/sample - loss: 0.3282 - accuracy: 0.8520 - val_loss: 0.3275 - val_accuracy: 0.8902\n",
            "Epoch 611/1000\n",
            "500/500 [==============================] - 0s 627us/sample - loss: 0.3557 - accuracy: 0.8720 - val_loss: 0.3271 - val_accuracy: 0.8841\n",
            "Epoch 612/1000\n",
            "500/500 [==============================] - 0s 660us/sample - loss: 0.3329 - accuracy: 0.8820 - val_loss: 0.3253 - val_accuracy: 0.8780\n",
            "Epoch 613/1000\n",
            "500/500 [==============================] - 0s 633us/sample - loss: 0.3318 - accuracy: 0.8720 - val_loss: 0.3304 - val_accuracy: 0.8902\n",
            "Epoch 614/1000\n",
            "500/500 [==============================] - 0s 647us/sample - loss: 0.3321 - accuracy: 0.8800 - val_loss: 0.3258 - val_accuracy: 0.8902\n",
            "Epoch 615/1000\n",
            "500/500 [==============================] - 0s 612us/sample - loss: 0.3352 - accuracy: 0.8500 - val_loss: 0.3325 - val_accuracy: 0.8902\n",
            "Epoch 616/1000\n",
            "500/500 [==============================] - 0s 596us/sample - loss: 0.3175 - accuracy: 0.8840 - val_loss: 0.3368 - val_accuracy: 0.8841\n",
            "Epoch 617/1000\n",
            "500/500 [==============================] - 0s 648us/sample - loss: 0.3127 - accuracy: 0.8780 - val_loss: 0.3447 - val_accuracy: 0.8902\n",
            "Epoch 618/1000\n",
            "500/500 [==============================] - 0s 608us/sample - loss: 0.3361 - accuracy: 0.8560 - val_loss: 0.3479 - val_accuracy: 0.8659\n",
            "Epoch 619/1000\n",
            "500/500 [==============================] - 0s 594us/sample - loss: 0.3350 - accuracy: 0.8640 - val_loss: 0.3463 - val_accuracy: 0.8720\n",
            "Epoch 620/1000\n",
            "500/500 [==============================] - 0s 569us/sample - loss: 0.3260 - accuracy: 0.8860 - val_loss: 0.3375 - val_accuracy: 0.8659\n",
            "Epoch 621/1000\n",
            "500/500 [==============================] - 0s 599us/sample - loss: 0.2963 - accuracy: 0.8900 - val_loss: 0.3358 - val_accuracy: 0.8841\n",
            "Epoch 622/1000\n",
            "500/500 [==============================] - 0s 627us/sample - loss: 0.3017 - accuracy: 0.8800 - val_loss: 0.3388 - val_accuracy: 0.8841\n",
            "Epoch 623/1000\n",
            "500/500 [==============================] - 0s 580us/sample - loss: 0.3069 - accuracy: 0.8780 - val_loss: 0.3439 - val_accuracy: 0.8963\n",
            "Epoch 624/1000\n",
            "500/500 [==============================] - 0s 573us/sample - loss: 0.3570 - accuracy: 0.8720 - val_loss: 0.3340 - val_accuracy: 0.9024\n",
            "Epoch 625/1000\n",
            "500/500 [==============================] - 0s 589us/sample - loss: 0.3216 - accuracy: 0.8820 - val_loss: 0.3374 - val_accuracy: 0.8841\n",
            "Epoch 626/1000\n",
            "500/500 [==============================] - 0s 677us/sample - loss: 0.3216 - accuracy: 0.8820 - val_loss: 0.3307 - val_accuracy: 0.8841\n",
            "Epoch 627/1000\n",
            "500/500 [==============================] - 0s 612us/sample - loss: 0.3049 - accuracy: 0.8780 - val_loss: 0.3276 - val_accuracy: 0.8902\n",
            "Epoch 628/1000\n",
            "500/500 [==============================] - 0s 610us/sample - loss: 0.3276 - accuracy: 0.8780 - val_loss: 0.3334 - val_accuracy: 0.8902\n",
            "Epoch 629/1000\n",
            "500/500 [==============================] - 0s 521us/sample - loss: 0.3707 - accuracy: 0.8620 - val_loss: 0.3199 - val_accuracy: 0.8841\n",
            "Epoch 630/1000\n",
            "500/500 [==============================] - 0s 593us/sample - loss: 0.3385 - accuracy: 0.8520 - val_loss: 0.3163 - val_accuracy: 0.8841\n",
            "Epoch 631/1000\n",
            "500/500 [==============================] - 0s 621us/sample - loss: 0.3450 - accuracy: 0.8740 - val_loss: 0.3136 - val_accuracy: 0.8902\n",
            "Epoch 632/1000\n",
            "500/500 [==============================] - 0s 523us/sample - loss: 0.2854 - accuracy: 0.8980 - val_loss: 0.3145 - val_accuracy: 0.8841\n",
            "Epoch 633/1000\n",
            "500/500 [==============================] - 0s 555us/sample - loss: 0.3218 - accuracy: 0.8760 - val_loss: 0.3174 - val_accuracy: 0.8902\n",
            "Epoch 634/1000\n",
            "500/500 [==============================] - 0s 664us/sample - loss: 0.3106 - accuracy: 0.8840 - val_loss: 0.3199 - val_accuracy: 0.8963\n",
            "Epoch 635/1000\n",
            "500/500 [==============================] - 0s 621us/sample - loss: 0.3168 - accuracy: 0.8700 - val_loss: 0.3146 - val_accuracy: 0.8902\n",
            "Epoch 636/1000\n",
            "500/500 [==============================] - 0s 499us/sample - loss: 0.3307 - accuracy: 0.8640 - val_loss: 0.3234 - val_accuracy: 0.8963\n",
            "Epoch 637/1000\n",
            "500/500 [==============================] - 0s 602us/sample - loss: 0.3383 - accuracy: 0.8620 - val_loss: 0.3258 - val_accuracy: 0.8841\n",
            "Epoch 638/1000\n",
            "500/500 [==============================] - 0s 623us/sample - loss: 0.3469 - accuracy: 0.8680 - val_loss: 0.3139 - val_accuracy: 0.8902\n",
            "Epoch 639/1000\n",
            "500/500 [==============================] - 0s 580us/sample - loss: 0.3241 - accuracy: 0.8660 - val_loss: 0.3111 - val_accuracy: 0.8902\n",
            "Epoch 640/1000\n",
            "500/500 [==============================] - 0s 576us/sample - loss: 0.3056 - accuracy: 0.8920 - val_loss: 0.3205 - val_accuracy: 0.8780\n",
            "Epoch 641/1000\n",
            "500/500 [==============================] - 0s 666us/sample - loss: 0.2945 - accuracy: 0.8840 - val_loss: 0.3189 - val_accuracy: 0.8720\n",
            "Epoch 642/1000\n",
            "500/500 [==============================] - 0s 569us/sample - loss: 0.2924 - accuracy: 0.8760 - val_loss: 0.3196 - val_accuracy: 0.8841\n",
            "Epoch 643/1000\n",
            "500/500 [==============================] - 0s 614us/sample - loss: 0.2582 - accuracy: 0.9120 - val_loss: 0.3333 - val_accuracy: 0.8720\n",
            "Epoch 644/1000\n",
            "500/500 [==============================] - 0s 661us/sample - loss: 0.3035 - accuracy: 0.8760 - val_loss: 0.3295 - val_accuracy: 0.8902\n",
            "Epoch 645/1000\n",
            "500/500 [==============================] - 0s 574us/sample - loss: 0.2939 - accuracy: 0.8880 - val_loss: 0.3211 - val_accuracy: 0.8841\n",
            "Epoch 646/1000\n",
            "500/500 [==============================] - 0s 542us/sample - loss: 0.3130 - accuracy: 0.8780 - val_loss: 0.3274 - val_accuracy: 0.8780\n",
            "Epoch 647/1000\n",
            "500/500 [==============================] - 0s 524us/sample - loss: 0.2973 - accuracy: 0.8920 - val_loss: 0.3262 - val_accuracy: 0.8659\n",
            "Epoch 648/1000\n",
            "500/500 [==============================] - 0s 623us/sample - loss: 0.3417 - accuracy: 0.8620 - val_loss: 0.3332 - val_accuracy: 0.8780\n",
            "Epoch 649/1000\n",
            "500/500 [==============================] - 0s 605us/sample - loss: 0.3056 - accuracy: 0.8720 - val_loss: 0.3450 - val_accuracy: 0.8720\n",
            "Epoch 650/1000\n",
            "500/500 [==============================] - 0s 628us/sample - loss: 0.3616 - accuracy: 0.8600 - val_loss: 0.3188 - val_accuracy: 0.8841\n",
            "Epoch 651/1000\n",
            "500/500 [==============================] - 0s 630us/sample - loss: 0.3236 - accuracy: 0.8820 - val_loss: 0.3146 - val_accuracy: 0.8841\n",
            "Epoch 652/1000\n",
            "500/500 [==============================] - 0s 537us/sample - loss: 0.3260 - accuracy: 0.8700 - val_loss: 0.3217 - val_accuracy: 0.8780\n",
            "Epoch 653/1000\n",
            "500/500 [==============================] - 0s 595us/sample - loss: 0.2825 - accuracy: 0.8880 - val_loss: 0.3233 - val_accuracy: 0.8902\n",
            "Epoch 654/1000\n",
            "500/500 [==============================] - 0s 658us/sample - loss: 0.3029 - accuracy: 0.8980 - val_loss: 0.3256 - val_accuracy: 0.8902\n",
            "Epoch 655/1000\n",
            "500/500 [==============================] - 0s 638us/sample - loss: 0.3397 - accuracy: 0.8700 - val_loss: 0.3373 - val_accuracy: 0.8659\n",
            "Epoch 656/1000\n",
            "500/500 [==============================] - 0s 554us/sample - loss: 0.3517 - accuracy: 0.8640 - val_loss: 0.3303 - val_accuracy: 0.8780\n",
            "Epoch 657/1000\n",
            "500/500 [==============================] - 0s 539us/sample - loss: 0.3311 - accuracy: 0.8800 - val_loss: 0.3253 - val_accuracy: 0.8963\n",
            "Epoch 658/1000\n",
            "500/500 [==============================] - 0s 597us/sample - loss: 0.3361 - accuracy: 0.8760 - val_loss: 0.3166 - val_accuracy: 0.8963\n",
            "Epoch 659/1000\n",
            "500/500 [==============================] - 0s 604us/sample - loss: 0.3247 - accuracy: 0.8860 - val_loss: 0.3181 - val_accuracy: 0.8963\n",
            "Epoch 660/1000\n",
            "500/500 [==============================] - 0s 531us/sample - loss: 0.2706 - accuracy: 0.8960 - val_loss: 0.3193 - val_accuracy: 0.8963\n",
            "Epoch 661/1000\n",
            "500/500 [==============================] - 0s 548us/sample - loss: 0.3173 - accuracy: 0.8680 - val_loss: 0.3248 - val_accuracy: 0.8902\n",
            "Epoch 662/1000\n",
            "500/500 [==============================] - 0s 625us/sample - loss: 0.3511 - accuracy: 0.8720 - val_loss: 0.3249 - val_accuracy: 0.9085\n",
            "Epoch 663/1000\n",
            "500/500 [==============================] - 0s 558us/sample - loss: 0.2946 - accuracy: 0.9060 - val_loss: 0.3193 - val_accuracy: 0.8841\n",
            "Epoch 664/1000\n",
            "500/500 [==============================] - 0s 651us/sample - loss: 0.3253 - accuracy: 0.8840 - val_loss: 0.3289 - val_accuracy: 0.8902\n",
            "Epoch 665/1000\n",
            "500/500 [==============================] - 0s 669us/sample - loss: 0.3316 - accuracy: 0.8760 - val_loss: 0.3340 - val_accuracy: 0.8780\n",
            "Epoch 666/1000\n",
            "500/500 [==============================] - 0s 589us/sample - loss: 0.3120 - accuracy: 0.8800 - val_loss: 0.3398 - val_accuracy: 0.8963\n",
            "Epoch 667/1000\n",
            "500/500 [==============================] - 0s 629us/sample - loss: 0.3416 - accuracy: 0.8560 - val_loss: 0.3388 - val_accuracy: 0.8963\n",
            "Epoch 668/1000\n",
            "500/500 [==============================] - 0s 621us/sample - loss: 0.2851 - accuracy: 0.9000 - val_loss: 0.3295 - val_accuracy: 0.8902\n",
            "Epoch 669/1000\n",
            "500/500 [==============================] - 0s 623us/sample - loss: 0.3239 - accuracy: 0.8820 - val_loss: 0.3181 - val_accuracy: 0.8902\n",
            "Epoch 670/1000\n",
            "500/500 [==============================] - 0s 651us/sample - loss: 0.3060 - accuracy: 0.8920 - val_loss: 0.3167 - val_accuracy: 0.8963\n",
            "Epoch 671/1000\n",
            "500/500 [==============================] - 0s 619us/sample - loss: 0.3153 - accuracy: 0.8620 - val_loss: 0.3188 - val_accuracy: 0.8963\n",
            "Epoch 672/1000\n",
            "500/500 [==============================] - 0s 606us/sample - loss: 0.3210 - accuracy: 0.8920 - val_loss: 0.3249 - val_accuracy: 0.8963\n",
            "Epoch 673/1000\n",
            "500/500 [==============================] - 0s 588us/sample - loss: 0.3139 - accuracy: 0.8760 - val_loss: 0.3180 - val_accuracy: 0.8963\n",
            "Epoch 674/1000\n",
            "500/500 [==============================] - 0s 697us/sample - loss: 0.2772 - accuracy: 0.8860 - val_loss: 0.3321 - val_accuracy: 0.8902\n",
            "Epoch 675/1000\n",
            "500/500 [==============================] - 0s 517us/sample - loss: 0.3208 - accuracy: 0.8600 - val_loss: 0.3371 - val_accuracy: 0.8841\n",
            "Epoch 676/1000\n",
            "500/500 [==============================] - 0s 569us/sample - loss: 0.3054 - accuracy: 0.8720 - val_loss: 0.3236 - val_accuracy: 0.8841\n",
            "Epoch 677/1000\n",
            "500/500 [==============================] - 0s 560us/sample - loss: 0.3375 - accuracy: 0.8680 - val_loss: 0.3238 - val_accuracy: 0.8902\n",
            "Epoch 678/1000\n",
            "500/500 [==============================] - 0s 506us/sample - loss: 0.3011 - accuracy: 0.8700 - val_loss: 0.3231 - val_accuracy: 0.9024\n",
            "Epoch 679/1000\n",
            "500/500 [==============================] - 0s 543us/sample - loss: 0.2840 - accuracy: 0.8980 - val_loss: 0.3281 - val_accuracy: 0.8780\n",
            "Epoch 680/1000\n",
            "500/500 [==============================] - 0s 609us/sample - loss: 0.3035 - accuracy: 0.8980 - val_loss: 0.3260 - val_accuracy: 0.8720\n",
            "Epoch 681/1000\n",
            "500/500 [==============================] - 0s 653us/sample - loss: 0.2855 - accuracy: 0.8920 - val_loss: 0.3255 - val_accuracy: 0.8841\n",
            "Epoch 682/1000\n",
            "500/500 [==============================] - 0s 583us/sample - loss: 0.2887 - accuracy: 0.8940 - val_loss: 0.3340 - val_accuracy: 0.8902\n",
            "Epoch 683/1000\n",
            "500/500 [==============================] - 0s 544us/sample - loss: 0.2938 - accuracy: 0.8800 - val_loss: 0.3182 - val_accuracy: 0.8902\n",
            "Epoch 684/1000\n",
            "500/500 [==============================] - 0s 541us/sample - loss: 0.3034 - accuracy: 0.8840 - val_loss: 0.3207 - val_accuracy: 0.8841\n",
            "Epoch 685/1000\n",
            "500/500 [==============================] - 0s 623us/sample - loss: 0.3083 - accuracy: 0.8880 - val_loss: 0.3239 - val_accuracy: 0.8659\n",
            "Epoch 686/1000\n",
            "500/500 [==============================] - 0s 532us/sample - loss: 0.3130 - accuracy: 0.8760 - val_loss: 0.3333 - val_accuracy: 0.8598\n",
            "Epoch 687/1000\n",
            "500/500 [==============================] - 0s 501us/sample - loss: 0.3358 - accuracy: 0.8720 - val_loss: 0.3395 - val_accuracy: 0.8659\n",
            "Epoch 688/1000\n",
            "500/500 [==============================] - 0s 598us/sample - loss: 0.3293 - accuracy: 0.8780 - val_loss: 0.3423 - val_accuracy: 0.8598\n",
            "Epoch 689/1000\n",
            "500/500 [==============================] - 0s 593us/sample - loss: 0.3364 - accuracy: 0.8720 - val_loss: 0.3495 - val_accuracy: 0.8659\n",
            "Epoch 690/1000\n",
            "500/500 [==============================] - 0s 513us/sample - loss: 0.3330 - accuracy: 0.8680 - val_loss: 0.3301 - val_accuracy: 0.8720\n",
            "Epoch 691/1000\n",
            "500/500 [==============================] - 0s 527us/sample - loss: 0.3395 - accuracy: 0.8720 - val_loss: 0.3330 - val_accuracy: 0.8659\n",
            "Epoch 692/1000\n",
            "500/500 [==============================] - 0s 576us/sample - loss: 0.3360 - accuracy: 0.8740 - val_loss: 0.3237 - val_accuracy: 0.9024\n",
            "Epoch 693/1000\n",
            "500/500 [==============================] - 0s 612us/sample - loss: 0.2810 - accuracy: 0.8900 - val_loss: 0.3268 - val_accuracy: 0.9146\n",
            "Epoch 694/1000\n",
            "500/500 [==============================] - 0s 610us/sample - loss: 0.3154 - accuracy: 0.8860 - val_loss: 0.3208 - val_accuracy: 0.8902\n",
            "Epoch 695/1000\n",
            "500/500 [==============================] - 0s 645us/sample - loss: 0.3287 - accuracy: 0.8700 - val_loss: 0.3196 - val_accuracy: 0.8963\n",
            "Epoch 696/1000\n",
            "500/500 [==============================] - 0s 579us/sample - loss: 0.2979 - accuracy: 0.8860 - val_loss: 0.3274 - val_accuracy: 0.8841\n",
            "Epoch 697/1000\n",
            "500/500 [==============================] - 0s 496us/sample - loss: 0.3098 - accuracy: 0.8960 - val_loss: 0.3146 - val_accuracy: 0.8780\n",
            "Epoch 698/1000\n",
            "500/500 [==============================] - 0s 631us/sample - loss: 0.3082 - accuracy: 0.8720 - val_loss: 0.3106 - val_accuracy: 0.8963\n",
            "Epoch 699/1000\n",
            "500/500 [==============================] - 0s 645us/sample - loss: 0.2927 - accuracy: 0.8760 - val_loss: 0.3188 - val_accuracy: 0.8902\n",
            "Epoch 700/1000\n",
            "500/500 [==============================] - 0s 496us/sample - loss: 0.3118 - accuracy: 0.8700 - val_loss: 0.3296 - val_accuracy: 0.8902\n",
            "Epoch 701/1000\n",
            "500/500 [==============================] - 0s 627us/sample - loss: 0.3040 - accuracy: 0.8820 - val_loss: 0.3222 - val_accuracy: 0.8841\n",
            "Epoch 702/1000\n",
            "500/500 [==============================] - 0s 655us/sample - loss: 0.3327 - accuracy: 0.8800 - val_loss: 0.3269 - val_accuracy: 0.8720\n",
            "Epoch 703/1000\n",
            "500/500 [==============================] - 0s 545us/sample - loss: 0.3355 - accuracy: 0.8760 - val_loss: 0.3256 - val_accuracy: 0.8598\n",
            "Epoch 704/1000\n",
            "500/500 [==============================] - 0s 498us/sample - loss: 0.3092 - accuracy: 0.8720 - val_loss: 0.3246 - val_accuracy: 0.8720\n",
            "Epoch 705/1000\n",
            "500/500 [==============================] - 0s 614us/sample - loss: 0.2968 - accuracy: 0.8700 - val_loss: 0.3235 - val_accuracy: 0.8841\n",
            "Epoch 706/1000\n",
            "500/500 [==============================] - 0s 657us/sample - loss: 0.3201 - accuracy: 0.8720 - val_loss: 0.3211 - val_accuracy: 0.8902\n",
            "Epoch 707/1000\n",
            "500/500 [==============================] - 0s 513us/sample - loss: 0.2934 - accuracy: 0.8960 - val_loss: 0.3133 - val_accuracy: 0.8963\n",
            "Epoch 708/1000\n",
            "500/500 [==============================] - 0s 539us/sample - loss: 0.3644 - accuracy: 0.8680 - val_loss: 0.3160 - val_accuracy: 0.8841\n",
            "Epoch 709/1000\n",
            "500/500 [==============================] - 0s 632us/sample - loss: 0.3199 - accuracy: 0.8860 - val_loss: 0.3190 - val_accuracy: 0.8720\n",
            "Epoch 710/1000\n",
            "500/500 [==============================] - 0s 613us/sample - loss: 0.3220 - accuracy: 0.8700 - val_loss: 0.3225 - val_accuracy: 0.8780\n",
            "Epoch 711/1000\n",
            "500/500 [==============================] - 0s 616us/sample - loss: 0.3293 - accuracy: 0.8760 - val_loss: 0.3162 - val_accuracy: 0.8780\n",
            "Epoch 712/1000\n",
            "500/500 [==============================] - 0s 620us/sample - loss: 0.2880 - accuracy: 0.8980 - val_loss: 0.3218 - val_accuracy: 0.8841\n",
            "Epoch 713/1000\n",
            "500/500 [==============================] - 0s 538us/sample - loss: 0.3062 - accuracy: 0.9000 - val_loss: 0.3198 - val_accuracy: 0.8963\n",
            "Epoch 714/1000\n",
            "500/500 [==============================] - 0s 630us/sample - loss: 0.3596 - accuracy: 0.8660 - val_loss: 0.3103 - val_accuracy: 0.8780\n",
            "Epoch 715/1000\n",
            "500/500 [==============================] - 0s 655us/sample - loss: 0.3304 - accuracy: 0.8640 - val_loss: 0.3140 - val_accuracy: 0.8780\n",
            "Epoch 716/1000\n",
            "500/500 [==============================] - 0s 648us/sample - loss: 0.3272 - accuracy: 0.8640 - val_loss: 0.3139 - val_accuracy: 0.8902\n",
            "Epoch 717/1000\n",
            "500/500 [==============================] - 0s 597us/sample - loss: 0.3640 - accuracy: 0.8580 - val_loss: 0.3229 - val_accuracy: 0.8963\n",
            "Epoch 718/1000\n",
            "500/500 [==============================] - 0s 613us/sample - loss: 0.2966 - accuracy: 0.8800 - val_loss: 0.3261 - val_accuracy: 0.9024\n",
            "Epoch 719/1000\n",
            "500/500 [==============================] - 0s 638us/sample - loss: 0.3312 - accuracy: 0.8800 - val_loss: 0.3244 - val_accuracy: 0.8902\n",
            "Epoch 720/1000\n",
            "500/500 [==============================] - 0s 601us/sample - loss: 0.3192 - accuracy: 0.8780 - val_loss: 0.3146 - val_accuracy: 0.8963\n",
            "Epoch 721/1000\n",
            "500/500 [==============================] - 0s 583us/sample - loss: 0.3028 - accuracy: 0.8840 - val_loss: 0.3236 - val_accuracy: 0.8841\n",
            "Epoch 722/1000\n",
            "500/500 [==============================] - 0s 629us/sample - loss: 0.3078 - accuracy: 0.8880 - val_loss: 0.3176 - val_accuracy: 0.8963\n",
            "Epoch 723/1000\n",
            "500/500 [==============================] - 0s 640us/sample - loss: 0.2790 - accuracy: 0.8920 - val_loss: 0.3130 - val_accuracy: 0.8841\n",
            "Epoch 724/1000\n",
            "500/500 [==============================] - 0s 494us/sample - loss: 0.3066 - accuracy: 0.8960 - val_loss: 0.3201 - val_accuracy: 0.8841\n",
            "Epoch 725/1000\n",
            "500/500 [==============================] - 0s 506us/sample - loss: 0.2886 - accuracy: 0.8980 - val_loss: 0.3215 - val_accuracy: 0.8841\n",
            "Epoch 726/1000\n",
            "500/500 [==============================] - 0s 606us/sample - loss: 0.3243 - accuracy: 0.8860 - val_loss: 0.3439 - val_accuracy: 0.8902\n",
            "Epoch 727/1000\n",
            "500/500 [==============================] - 0s 553us/sample - loss: 0.2960 - accuracy: 0.8800 - val_loss: 0.3266 - val_accuracy: 0.9085\n",
            "Epoch 728/1000\n",
            "500/500 [==============================] - 0s 500us/sample - loss: 0.2952 - accuracy: 0.8820 - val_loss: 0.3217 - val_accuracy: 0.9085\n",
            "Epoch 729/1000\n",
            "500/500 [==============================] - 0s 542us/sample - loss: 0.3186 - accuracy: 0.8700 - val_loss: 0.3201 - val_accuracy: 0.9146\n",
            "Epoch 730/1000\n",
            "500/500 [==============================] - 0s 588us/sample - loss: 0.3473 - accuracy: 0.8600 - val_loss: 0.3161 - val_accuracy: 0.8963\n",
            "Epoch 731/1000\n",
            "500/500 [==============================] - 0s 587us/sample - loss: 0.2984 - accuracy: 0.8880 - val_loss: 0.3196 - val_accuracy: 0.9024\n",
            "Epoch 732/1000\n",
            "500/500 [==============================] - 0s 631us/sample - loss: 0.2920 - accuracy: 0.8980 - val_loss: 0.3155 - val_accuracy: 0.8963\n",
            "Epoch 733/1000\n",
            "500/500 [==============================] - 0s 556us/sample - loss: 0.2800 - accuracy: 0.8980 - val_loss: 0.3306 - val_accuracy: 0.8902\n",
            "Epoch 734/1000\n",
            "500/500 [==============================] - 0s 499us/sample - loss: 0.2807 - accuracy: 0.8960 - val_loss: 0.3313 - val_accuracy: 0.8841\n",
            "Epoch 735/1000\n",
            "500/500 [==============================] - 0s 608us/sample - loss: 0.2925 - accuracy: 0.8880 - val_loss: 0.3317 - val_accuracy: 0.8841\n",
            "Epoch 736/1000\n",
            "500/500 [==============================] - 0s 589us/sample - loss: 0.3017 - accuracy: 0.8920 - val_loss: 0.3208 - val_accuracy: 0.8963\n",
            "Epoch 737/1000\n",
            "500/500 [==============================] - 0s 583us/sample - loss: 0.3177 - accuracy: 0.8740 - val_loss: 0.3332 - val_accuracy: 0.8963\n",
            "Epoch 738/1000\n",
            "500/500 [==============================] - 0s 536us/sample - loss: 0.3052 - accuracy: 0.8960 - val_loss: 0.3464 - val_accuracy: 0.8963\n",
            "Epoch 739/1000\n",
            "500/500 [==============================] - 0s 606us/sample - loss: 0.3007 - accuracy: 0.8840 - val_loss: 0.3432 - val_accuracy: 0.9024\n",
            "Epoch 740/1000\n",
            "500/500 [==============================] - 0s 518us/sample - loss: 0.3003 - accuracy: 0.8800 - val_loss: 0.3442 - val_accuracy: 0.8902\n",
            "Epoch 741/1000\n",
            "500/500 [==============================] - 0s 610us/sample - loss: 0.2716 - accuracy: 0.8900 - val_loss: 0.3469 - val_accuracy: 0.8963\n",
            "Epoch 742/1000\n",
            "500/500 [==============================] - 0s 561us/sample - loss: 0.3404 - accuracy: 0.8700 - val_loss: 0.3367 - val_accuracy: 0.8902\n",
            "Epoch 743/1000\n",
            "500/500 [==============================] - 0s 632us/sample - loss: 0.2949 - accuracy: 0.8940 - val_loss: 0.3241 - val_accuracy: 0.8902\n",
            "Epoch 744/1000\n",
            "500/500 [==============================] - 0s 589us/sample - loss: 0.2784 - accuracy: 0.8820 - val_loss: 0.3187 - val_accuracy: 0.9085\n",
            "Epoch 745/1000\n",
            "500/500 [==============================] - 0s 640us/sample - loss: 0.3192 - accuracy: 0.8740 - val_loss: 0.3231 - val_accuracy: 0.8963\n",
            "Epoch 746/1000\n",
            "500/500 [==============================] - 0s 615us/sample - loss: 0.3151 - accuracy: 0.8720 - val_loss: 0.3111 - val_accuracy: 0.9024\n",
            "Epoch 747/1000\n",
            "500/500 [==============================] - 0s 573us/sample - loss: 0.3455 - accuracy: 0.8660 - val_loss: 0.3109 - val_accuracy: 0.8902\n",
            "Epoch 748/1000\n",
            "500/500 [==============================] - 0s 548us/sample - loss: 0.2991 - accuracy: 0.8900 - val_loss: 0.3136 - val_accuracy: 0.8841\n",
            "Epoch 749/1000\n",
            "500/500 [==============================] - 0s 553us/sample - loss: 0.2933 - accuracy: 0.8940 - val_loss: 0.3164 - val_accuracy: 0.8841\n",
            "Epoch 750/1000\n",
            "500/500 [==============================] - 0s 554us/sample - loss: 0.2789 - accuracy: 0.8920 - val_loss: 0.3334 - val_accuracy: 0.8720\n",
            "Epoch 751/1000\n",
            "500/500 [==============================] - 0s 560us/sample - loss: 0.2998 - accuracy: 0.8760 - val_loss: 0.3357 - val_accuracy: 0.8841\n",
            "Epoch 752/1000\n",
            "500/500 [==============================] - 0s 503us/sample - loss: 0.2886 - accuracy: 0.8980 - val_loss: 0.3364 - val_accuracy: 0.8841\n",
            "Epoch 753/1000\n",
            "500/500 [==============================] - 0s 530us/sample - loss: 0.3442 - accuracy: 0.8760 - val_loss: 0.3195 - val_accuracy: 0.8902\n",
            "Epoch 754/1000\n",
            "500/500 [==============================] - 0s 503us/sample - loss: 0.3158 - accuracy: 0.8780 - val_loss: 0.3195 - val_accuracy: 0.8963\n",
            "Epoch 755/1000\n",
            "500/500 [==============================] - 0s 513us/sample - loss: 0.2799 - accuracy: 0.9160 - val_loss: 0.3131 - val_accuracy: 0.8902\n",
            "Epoch 756/1000\n",
            "500/500 [==============================] - 0s 615us/sample - loss: 0.2670 - accuracy: 0.8980 - val_loss: 0.3102 - val_accuracy: 0.8902\n",
            "Epoch 757/1000\n",
            "500/500 [==============================] - 0s 632us/sample - loss: 0.3049 - accuracy: 0.8820 - val_loss: 0.3199 - val_accuracy: 0.8598\n",
            "Epoch 758/1000\n",
            "500/500 [==============================] - 0s 531us/sample - loss: 0.3438 - accuracy: 0.8660 - val_loss: 0.3157 - val_accuracy: 0.8841\n",
            "Epoch 759/1000\n",
            "500/500 [==============================] - 0s 555us/sample - loss: 0.3388 - accuracy: 0.8740 - val_loss: 0.3100 - val_accuracy: 0.8841\n",
            "Epoch 760/1000\n",
            "500/500 [==============================] - 0s 605us/sample - loss: 0.3175 - accuracy: 0.8900 - val_loss: 0.3205 - val_accuracy: 0.8963\n",
            "Epoch 761/1000\n",
            "500/500 [==============================] - 0s 594us/sample - loss: 0.3173 - accuracy: 0.8680 - val_loss: 0.3216 - val_accuracy: 0.8841\n",
            "Epoch 762/1000\n",
            "500/500 [==============================] - 0s 495us/sample - loss: 0.3223 - accuracy: 0.8880 - val_loss: 0.3260 - val_accuracy: 0.8841\n",
            "Epoch 763/1000\n",
            "500/500 [==============================] - 0s 557us/sample - loss: 0.3011 - accuracy: 0.8860 - val_loss: 0.3286 - val_accuracy: 0.8841\n",
            "Epoch 764/1000\n",
            "500/500 [==============================] - 0s 628us/sample - loss: 0.3326 - accuracy: 0.8760 - val_loss: 0.3254 - val_accuracy: 0.8659\n",
            "Epoch 765/1000\n",
            "500/500 [==============================] - 0s 528us/sample - loss: 0.3128 - accuracy: 0.8780 - val_loss: 0.3271 - val_accuracy: 0.8780\n",
            "Epoch 766/1000\n",
            "500/500 [==============================] - 0s 506us/sample - loss: 0.3292 - accuracy: 0.8720 - val_loss: 0.3197 - val_accuracy: 0.8780\n",
            "Epoch 767/1000\n",
            "500/500 [==============================] - 0s 592us/sample - loss: 0.3215 - accuracy: 0.9020 - val_loss: 0.3193 - val_accuracy: 0.8841\n",
            "Epoch 768/1000\n",
            "500/500 [==============================] - 0s 591us/sample - loss: 0.3282 - accuracy: 0.8860 - val_loss: 0.3174 - val_accuracy: 0.8841\n",
            "Epoch 769/1000\n",
            "500/500 [==============================] - 0s 474us/sample - loss: 0.3048 - accuracy: 0.8940 - val_loss: 0.3204 - val_accuracy: 0.8659\n",
            "Epoch 770/1000\n",
            "500/500 [==============================] - 0s 499us/sample - loss: 0.3380 - accuracy: 0.8680 - val_loss: 0.3152 - val_accuracy: 0.8841\n",
            "Epoch 771/1000\n",
            "500/500 [==============================] - 0s 642us/sample - loss: 0.3031 - accuracy: 0.8720 - val_loss: 0.3161 - val_accuracy: 0.8720\n",
            "Epoch 772/1000\n",
            "500/500 [==============================] - 0s 546us/sample - loss: 0.3331 - accuracy: 0.8760 - val_loss: 0.3211 - val_accuracy: 0.8780\n",
            "Epoch 773/1000\n",
            "500/500 [==============================] - 0s 586us/sample - loss: 0.2869 - accuracy: 0.8920 - val_loss: 0.3279 - val_accuracy: 0.8841\n",
            "Epoch 774/1000\n",
            "500/500 [==============================] - 0s 590us/sample - loss: 0.3411 - accuracy: 0.8620 - val_loss: 0.3208 - val_accuracy: 0.8841\n",
            "Epoch 775/1000\n",
            "500/500 [==============================] - 0s 616us/sample - loss: 0.2934 - accuracy: 0.8940 - val_loss: 0.3156 - val_accuracy: 0.8780\n",
            "Epoch 776/1000\n",
            "500/500 [==============================] - 0s 612us/sample - loss: 0.3040 - accuracy: 0.8840 - val_loss: 0.3161 - val_accuracy: 0.8841\n",
            "Epoch 777/1000\n",
            "500/500 [==============================] - 0s 628us/sample - loss: 0.2750 - accuracy: 0.9000 - val_loss: 0.3080 - val_accuracy: 0.8963\n",
            "Epoch 778/1000\n",
            "500/500 [==============================] - 0s 584us/sample - loss: 0.3054 - accuracy: 0.8880 - val_loss: 0.3128 - val_accuracy: 0.8841\n",
            "Epoch 779/1000\n",
            "500/500 [==============================] - 0s 530us/sample - loss: 0.2953 - accuracy: 0.8840 - val_loss: 0.3236 - val_accuracy: 0.8963\n",
            "Epoch 780/1000\n",
            "500/500 [==============================] - 0s 539us/sample - loss: 0.3285 - accuracy: 0.8720 - val_loss: 0.3167 - val_accuracy: 0.8720\n",
            "Epoch 781/1000\n",
            "500/500 [==============================] - 0s 597us/sample - loss: 0.3144 - accuracy: 0.8820 - val_loss: 0.3260 - val_accuracy: 0.8841\n",
            "Epoch 782/1000\n",
            "500/500 [==============================] - 0s 513us/sample - loss: 0.3297 - accuracy: 0.8660 - val_loss: 0.3195 - val_accuracy: 0.8963\n",
            "Epoch 783/1000\n",
            "500/500 [==============================] - 0s 576us/sample - loss: 0.3127 - accuracy: 0.8900 - val_loss: 0.3297 - val_accuracy: 0.8780\n",
            "Epoch 784/1000\n",
            "500/500 [==============================] - 0s 515us/sample - loss: 0.2975 - accuracy: 0.8880 - val_loss: 0.3331 - val_accuracy: 0.8780\n",
            "Epoch 785/1000\n",
            "500/500 [==============================] - 0s 525us/sample - loss: 0.2690 - accuracy: 0.9020 - val_loss: 0.3444 - val_accuracy: 0.8841\n",
            "Epoch 786/1000\n",
            "500/500 [==============================] - 0s 550us/sample - loss: 0.2725 - accuracy: 0.8860 - val_loss: 0.3348 - val_accuracy: 0.8780\n",
            "Epoch 787/1000\n",
            "500/500 [==============================] - 0s 588us/sample - loss: 0.3519 - accuracy: 0.8540 - val_loss: 0.3259 - val_accuracy: 0.8841\n",
            "Epoch 788/1000\n",
            "500/500 [==============================] - 0s 498us/sample - loss: 0.3050 - accuracy: 0.8760 - val_loss: 0.3181 - val_accuracy: 0.8780\n",
            "Epoch 789/1000\n",
            "500/500 [==============================] - 0s 507us/sample - loss: 0.2976 - accuracy: 0.8820 - val_loss: 0.3094 - val_accuracy: 0.8963\n",
            "Epoch 790/1000\n",
            "500/500 [==============================] - 0s 520us/sample - loss: 0.3041 - accuracy: 0.8880 - val_loss: 0.3092 - val_accuracy: 0.8902\n",
            "Epoch 791/1000\n",
            "500/500 [==============================] - 0s 547us/sample - loss: 0.2665 - accuracy: 0.9140 - val_loss: 0.3188 - val_accuracy: 0.8780\n",
            "Epoch 792/1000\n",
            "500/500 [==============================] - 0s 517us/sample - loss: 0.2779 - accuracy: 0.9000 - val_loss: 0.3267 - val_accuracy: 0.8841\n",
            "Epoch 793/1000\n",
            "500/500 [==============================] - 0s 553us/sample - loss: 0.2635 - accuracy: 0.9100 - val_loss: 0.3345 - val_accuracy: 0.8780\n",
            "Epoch 794/1000\n",
            "500/500 [==============================] - 0s 527us/sample - loss: 0.2896 - accuracy: 0.8900 - val_loss: 0.3368 - val_accuracy: 0.8841\n",
            "Epoch 795/1000\n",
            "500/500 [==============================] - 0s 620us/sample - loss: 0.2895 - accuracy: 0.8900 - val_loss: 0.3310 - val_accuracy: 0.8780\n",
            "Epoch 796/1000\n",
            "500/500 [==============================] - 0s 628us/sample - loss: 0.2876 - accuracy: 0.8740 - val_loss: 0.3223 - val_accuracy: 0.8841\n",
            "Epoch 797/1000\n",
            "500/500 [==============================] - 0s 584us/sample - loss: 0.2840 - accuracy: 0.8880 - val_loss: 0.3210 - val_accuracy: 0.8902\n",
            "Epoch 798/1000\n",
            "500/500 [==============================] - 0s 623us/sample - loss: 0.3586 - accuracy: 0.8660 - val_loss: 0.3383 - val_accuracy: 0.8841\n",
            "Epoch 799/1000\n",
            "500/500 [==============================] - 0s 611us/sample - loss: 0.3250 - accuracy: 0.8800 - val_loss: 0.3409 - val_accuracy: 0.8720\n",
            "Epoch 800/1000\n",
            "500/500 [==============================] - 0s 549us/sample - loss: 0.3240 - accuracy: 0.8820 - val_loss: 0.3268 - val_accuracy: 0.8841\n",
            "Epoch 801/1000\n",
            "500/500 [==============================] - 0s 497us/sample - loss: 0.3503 - accuracy: 0.8600 - val_loss: 0.3236 - val_accuracy: 0.8720\n",
            "Epoch 802/1000\n",
            "500/500 [==============================] - 0s 632us/sample - loss: 0.3090 - accuracy: 0.8720 - val_loss: 0.3153 - val_accuracy: 0.8902\n",
            "Epoch 803/1000\n",
            "500/500 [==============================] - 0s 585us/sample - loss: 0.3158 - accuracy: 0.8780 - val_loss: 0.3122 - val_accuracy: 0.8720\n",
            "Epoch 804/1000\n",
            "500/500 [==============================] - 0s 615us/sample - loss: 0.3089 - accuracy: 0.8760 - val_loss: 0.3098 - val_accuracy: 0.8720\n",
            "Epoch 805/1000\n",
            "500/500 [==============================] - 0s 534us/sample - loss: 0.3152 - accuracy: 0.8820 - val_loss: 0.3163 - val_accuracy: 0.8720\n",
            "Epoch 806/1000\n",
            "500/500 [==============================] - 0s 675us/sample - loss: 0.3118 - accuracy: 0.8680 - val_loss: 0.3221 - val_accuracy: 0.8902\n",
            "Epoch 807/1000\n",
            "500/500 [==============================] - 0s 545us/sample - loss: 0.3364 - accuracy: 0.8740 - val_loss: 0.3135 - val_accuracy: 0.8902\n",
            "Epoch 808/1000\n",
            "500/500 [==============================] - 0s 616us/sample - loss: 0.3317 - accuracy: 0.8520 - val_loss: 0.3262 - val_accuracy: 0.8780\n",
            "Epoch 809/1000\n",
            "500/500 [==============================] - 0s 631us/sample - loss: 0.3067 - accuracy: 0.8700 - val_loss: 0.3154 - val_accuracy: 0.8841\n",
            "Epoch 810/1000\n",
            "500/500 [==============================] - 0s 549us/sample - loss: 0.3214 - accuracy: 0.8840 - val_loss: 0.3143 - val_accuracy: 0.8841\n",
            "Epoch 811/1000\n",
            "500/500 [==============================] - 0s 544us/sample - loss: 0.2923 - accuracy: 0.8900 - val_loss: 0.3260 - val_accuracy: 0.8902\n",
            "Epoch 812/1000\n",
            "500/500 [==============================] - 0s 498us/sample - loss: 0.3217 - accuracy: 0.8680 - val_loss: 0.3295 - val_accuracy: 0.8902\n",
            "Epoch 813/1000\n",
            "500/500 [==============================] - 0s 628us/sample - loss: 0.3173 - accuracy: 0.8880 - val_loss: 0.3167 - val_accuracy: 0.8963\n",
            "Epoch 814/1000\n",
            "500/500 [==============================] - 0s 546us/sample - loss: 0.2948 - accuracy: 0.8900 - val_loss: 0.3184 - val_accuracy: 0.8902\n",
            "Epoch 815/1000\n",
            "500/500 [==============================] - 0s 534us/sample - loss: 0.2748 - accuracy: 0.9020 - val_loss: 0.3227 - val_accuracy: 0.9024\n",
            "Epoch 816/1000\n",
            "500/500 [==============================] - 0s 572us/sample - loss: 0.3242 - accuracy: 0.8760 - val_loss: 0.3197 - val_accuracy: 0.8902\n",
            "Epoch 817/1000\n",
            "500/500 [==============================] - 0s 570us/sample - loss: 0.3448 - accuracy: 0.8560 - val_loss: 0.3241 - val_accuracy: 0.9024\n",
            "Epoch 818/1000\n",
            "500/500 [==============================] - 0s 495us/sample - loss: 0.3361 - accuracy: 0.8800 - val_loss: 0.3178 - val_accuracy: 0.8902\n",
            "Epoch 819/1000\n",
            "500/500 [==============================] - 0s 611us/sample - loss: 0.3260 - accuracy: 0.8680 - val_loss: 0.3153 - val_accuracy: 0.8963\n",
            "Epoch 820/1000\n",
            "500/500 [==============================] - 0s 619us/sample - loss: 0.3192 - accuracy: 0.8620 - val_loss: 0.3150 - val_accuracy: 0.8720\n",
            "Epoch 821/1000\n",
            "500/500 [==============================] - 0s 497us/sample - loss: 0.3343 - accuracy: 0.8620 - val_loss: 0.3058 - val_accuracy: 0.8902\n",
            "Epoch 822/1000\n",
            "500/500 [==============================] - 0s 615us/sample - loss: 0.2952 - accuracy: 0.8960 - val_loss: 0.3094 - val_accuracy: 0.8780\n",
            "Epoch 823/1000\n",
            "500/500 [==============================] - 0s 654us/sample - loss: 0.2996 - accuracy: 0.8820 - val_loss: 0.3090 - val_accuracy: 0.8902\n",
            "Epoch 824/1000\n",
            "500/500 [==============================] - 0s 523us/sample - loss: 0.3028 - accuracy: 0.8760 - val_loss: 0.3089 - val_accuracy: 0.8780\n",
            "Epoch 825/1000\n",
            "500/500 [==============================] - 0s 574us/sample - loss: 0.2940 - accuracy: 0.9080 - val_loss: 0.3103 - val_accuracy: 0.8720\n",
            "Epoch 826/1000\n",
            "500/500 [==============================] - 0s 623us/sample - loss: 0.3010 - accuracy: 0.8920 - val_loss: 0.3107 - val_accuracy: 0.8841\n",
            "Epoch 827/1000\n",
            "500/500 [==============================] - 0s 634us/sample - loss: 0.3418 - accuracy: 0.8740 - val_loss: 0.3098 - val_accuracy: 0.8720\n",
            "Epoch 828/1000\n",
            "500/500 [==============================] - 0s 616us/sample - loss: 0.3019 - accuracy: 0.8840 - val_loss: 0.3119 - val_accuracy: 0.8780\n",
            "Epoch 829/1000\n",
            "500/500 [==============================] - 0s 539us/sample - loss: 0.2950 - accuracy: 0.8780 - val_loss: 0.3205 - val_accuracy: 0.8841\n",
            "Epoch 830/1000\n",
            "500/500 [==============================] - 0s 527us/sample - loss: 0.2831 - accuracy: 0.8760 - val_loss: 0.3274 - val_accuracy: 0.8720\n",
            "Epoch 831/1000\n",
            "500/500 [==============================] - 0s 592us/sample - loss: 0.3248 - accuracy: 0.8740 - val_loss: 0.3218 - val_accuracy: 0.8780\n",
            "Epoch 832/1000\n",
            "500/500 [==============================] - 0s 606us/sample - loss: 0.3097 - accuracy: 0.8840 - val_loss: 0.3279 - val_accuracy: 0.8841\n",
            "Epoch 833/1000\n",
            "500/500 [==============================] - 0s 658us/sample - loss: 0.3000 - accuracy: 0.8800 - val_loss: 0.3171 - val_accuracy: 0.8780\n",
            "Epoch 834/1000\n",
            "500/500 [==============================] - 0s 641us/sample - loss: 0.2523 - accuracy: 0.9120 - val_loss: 0.3152 - val_accuracy: 0.8841\n",
            "Epoch 835/1000\n",
            "500/500 [==============================] - 0s 499us/sample - loss: 0.2754 - accuracy: 0.9080 - val_loss: 0.3150 - val_accuracy: 0.8780\n",
            "Epoch 836/1000\n",
            "500/500 [==============================] - 0s 480us/sample - loss: 0.3158 - accuracy: 0.8800 - val_loss: 0.3104 - val_accuracy: 0.8659\n",
            "Epoch 837/1000\n",
            "500/500 [==============================] - 0s 634us/sample - loss: 0.2839 - accuracy: 0.8940 - val_loss: 0.3096 - val_accuracy: 0.8780\n",
            "Epoch 838/1000\n",
            "500/500 [==============================] - 0s 579us/sample - loss: 0.3070 - accuracy: 0.8860 - val_loss: 0.3098 - val_accuracy: 0.8902\n",
            "Epoch 839/1000\n",
            "500/500 [==============================] - 0s 525us/sample - loss: 0.2590 - accuracy: 0.9120 - val_loss: 0.3207 - val_accuracy: 0.8720\n",
            "Epoch 840/1000\n",
            "500/500 [==============================] - 0s 517us/sample - loss: 0.3358 - accuracy: 0.8720 - val_loss: 0.3307 - val_accuracy: 0.8780\n",
            "Epoch 841/1000\n",
            "500/500 [==============================] - 0s 549us/sample - loss: 0.3197 - accuracy: 0.8880 - val_loss: 0.3148 - val_accuracy: 0.8841\n",
            "Epoch 842/1000\n",
            "500/500 [==============================] - 0s 605us/sample - loss: 0.2995 - accuracy: 0.8880 - val_loss: 0.3112 - val_accuracy: 0.8780\n",
            "Epoch 843/1000\n",
            "500/500 [==============================] - 0s 494us/sample - loss: 0.3124 - accuracy: 0.8820 - val_loss: 0.3157 - val_accuracy: 0.8841\n",
            "Epoch 844/1000\n",
            "500/500 [==============================] - 0s 537us/sample - loss: 0.3023 - accuracy: 0.8800 - val_loss: 0.3140 - val_accuracy: 0.8841\n",
            "Epoch 845/1000\n",
            "500/500 [==============================] - 0s 553us/sample - loss: 0.2987 - accuracy: 0.8840 - val_loss: 0.3134 - val_accuracy: 0.8841\n",
            "Epoch 846/1000\n",
            "500/500 [==============================] - 0s 567us/sample - loss: 0.3155 - accuracy: 0.8840 - val_loss: 0.3176 - val_accuracy: 0.8780\n",
            "Epoch 847/1000\n",
            "500/500 [==============================] - 0s 500us/sample - loss: 0.2999 - accuracy: 0.8840 - val_loss: 0.3205 - val_accuracy: 0.8902\n",
            "Epoch 848/1000\n",
            "500/500 [==============================] - 0s 591us/sample - loss: 0.2872 - accuracy: 0.8920 - val_loss: 0.3163 - val_accuracy: 0.8841\n",
            "Epoch 849/1000\n",
            "500/500 [==============================] - 0s 560us/sample - loss: 0.2637 - accuracy: 0.9120 - val_loss: 0.3287 - val_accuracy: 0.8841\n",
            "Epoch 850/1000\n",
            "500/500 [==============================] - 0s 653us/sample - loss: 0.2692 - accuracy: 0.9000 - val_loss: 0.3208 - val_accuracy: 0.8780\n",
            "Epoch 851/1000\n",
            "500/500 [==============================] - 0s 639us/sample - loss: 0.3112 - accuracy: 0.8860 - val_loss: 0.3248 - val_accuracy: 0.8598\n",
            "Epoch 852/1000\n",
            "500/500 [==============================] - 0s 545us/sample - loss: 0.3412 - accuracy: 0.8660 - val_loss: 0.3244 - val_accuracy: 0.8720\n",
            "Epoch 853/1000\n",
            "500/500 [==============================] - 0s 564us/sample - loss: 0.2865 - accuracy: 0.8980 - val_loss: 0.3301 - val_accuracy: 0.8780\n",
            "Epoch 854/1000\n",
            "500/500 [==============================] - 0s 508us/sample - loss: 0.2811 - accuracy: 0.8900 - val_loss: 0.3241 - val_accuracy: 0.8720\n",
            "Epoch 855/1000\n",
            "500/500 [==============================] - 0s 543us/sample - loss: 0.3031 - accuracy: 0.8840 - val_loss: 0.3244 - val_accuracy: 0.8963\n",
            "Epoch 856/1000\n",
            "500/500 [==============================] - 0s 527us/sample - loss: 0.3071 - accuracy: 0.8960 - val_loss: 0.3219 - val_accuracy: 0.8902\n",
            "Epoch 857/1000\n",
            "500/500 [==============================] - 0s 579us/sample - loss: 0.2715 - accuracy: 0.9020 - val_loss: 0.3317 - val_accuracy: 0.8780\n",
            "Epoch 858/1000\n",
            "500/500 [==============================] - 0s 634us/sample - loss: 0.2924 - accuracy: 0.8920 - val_loss: 0.3391 - val_accuracy: 0.8720\n",
            "Epoch 859/1000\n",
            "500/500 [==============================] - 0s 639us/sample - loss: 0.2884 - accuracy: 0.8880 - val_loss: 0.3267 - val_accuracy: 0.8720\n",
            "Epoch 860/1000\n",
            "500/500 [==============================] - 0s 588us/sample - loss: 0.2980 - accuracy: 0.8860 - val_loss: 0.3349 - val_accuracy: 0.8659\n",
            "Epoch 861/1000\n",
            "500/500 [==============================] - 0s 605us/sample - loss: 0.3215 - accuracy: 0.8700 - val_loss: 0.3297 - val_accuracy: 0.8720\n",
            "Epoch 862/1000\n",
            "500/500 [==============================] - 0s 632us/sample - loss: 0.3025 - accuracy: 0.8860 - val_loss: 0.3338 - val_accuracy: 0.8780\n",
            "Epoch 863/1000\n",
            "500/500 [==============================] - 0s 490us/sample - loss: 0.2475 - accuracy: 0.9140 - val_loss: 0.3347 - val_accuracy: 0.8780\n",
            "Epoch 864/1000\n",
            "500/500 [==============================] - 0s 591us/sample - loss: 0.3297 - accuracy: 0.8820 - val_loss: 0.3255 - val_accuracy: 0.8902\n",
            "Epoch 865/1000\n",
            "500/500 [==============================] - 0s 600us/sample - loss: 0.3059 - accuracy: 0.8840 - val_loss: 0.3285 - val_accuracy: 0.8902\n",
            "Epoch 866/1000\n",
            "500/500 [==============================] - 0s 615us/sample - loss: 0.2926 - accuracy: 0.8780 - val_loss: 0.3451 - val_accuracy: 0.8902\n",
            "Epoch 867/1000\n",
            "500/500 [==============================] - 0s 494us/sample - loss: 0.3173 - accuracy: 0.8740 - val_loss: 0.3342 - val_accuracy: 0.8841\n",
            "Epoch 868/1000\n",
            "500/500 [==============================] - 0s 619us/sample - loss: 0.2942 - accuracy: 0.9020 - val_loss: 0.3415 - val_accuracy: 0.8841\n",
            "Epoch 869/1000\n",
            "500/500 [==============================] - 0s 609us/sample - loss: 0.2974 - accuracy: 0.8980 - val_loss: 0.3297 - val_accuracy: 0.8841\n",
            "Epoch 870/1000\n",
            "500/500 [==============================] - 0s 544us/sample - loss: 0.2916 - accuracy: 0.8920 - val_loss: 0.3264 - val_accuracy: 0.9024\n",
            "Epoch 871/1000\n",
            "500/500 [==============================] - 0s 542us/sample - loss: 0.3234 - accuracy: 0.8820 - val_loss: 0.3289 - val_accuracy: 0.8902\n",
            "Epoch 872/1000\n",
            "500/500 [==============================] - 0s 631us/sample - loss: 0.2918 - accuracy: 0.8840 - val_loss: 0.3332 - val_accuracy: 0.8841\n",
            "Epoch 873/1000\n",
            "500/500 [==============================] - 0s 602us/sample - loss: 0.3290 - accuracy: 0.8720 - val_loss: 0.3255 - val_accuracy: 0.8963\n",
            "Epoch 874/1000\n",
            "500/500 [==============================] - 0s 535us/sample - loss: 0.3548 - accuracy: 0.8540 - val_loss: 0.3334 - val_accuracy: 0.8659\n",
            "Epoch 875/1000\n",
            "500/500 [==============================] - 0s 666us/sample - loss: 0.2978 - accuracy: 0.8920 - val_loss: 0.3219 - val_accuracy: 0.8841\n",
            "Epoch 876/1000\n",
            "500/500 [==============================] - 0s 603us/sample - loss: 0.2793 - accuracy: 0.8800 - val_loss: 0.3220 - val_accuracy: 0.8841\n",
            "Epoch 877/1000\n",
            "500/500 [==============================] - 0s 624us/sample - loss: 0.2739 - accuracy: 0.8880 - val_loss: 0.3187 - val_accuracy: 0.8902\n",
            "Epoch 878/1000\n",
            "500/500 [==============================] - 0s 619us/sample - loss: 0.2856 - accuracy: 0.8960 - val_loss: 0.3195 - val_accuracy: 0.8902\n",
            "Epoch 879/1000\n",
            "500/500 [==============================] - 0s 629us/sample - loss: 0.2873 - accuracy: 0.8840 - val_loss: 0.3195 - val_accuracy: 0.8659\n",
            "Epoch 880/1000\n",
            "500/500 [==============================] - 0s 620us/sample - loss: 0.2687 - accuracy: 0.8920 - val_loss: 0.3299 - val_accuracy: 0.8963\n",
            "Epoch 881/1000\n",
            "500/500 [==============================] - 0s 620us/sample - loss: 0.2916 - accuracy: 0.8800 - val_loss: 0.3222 - val_accuracy: 0.8841\n",
            "Epoch 882/1000\n",
            "500/500 [==============================] - 0s 549us/sample - loss: 0.2793 - accuracy: 0.8960 - val_loss: 0.3238 - val_accuracy: 0.8902\n",
            "Epoch 883/1000\n",
            "500/500 [==============================] - 0s 519us/sample - loss: 0.3082 - accuracy: 0.8620 - val_loss: 0.3310 - val_accuracy: 0.8902\n",
            "Epoch 884/1000\n",
            "500/500 [==============================] - 0s 593us/sample - loss: 0.2996 - accuracy: 0.9020 - val_loss: 0.3113 - val_accuracy: 0.8841\n",
            "Epoch 885/1000\n",
            "500/500 [==============================] - 0s 633us/sample - loss: 0.2987 - accuracy: 0.8840 - val_loss: 0.3222 - val_accuracy: 0.8841\n",
            "Epoch 886/1000\n",
            "500/500 [==============================] - 0s 560us/sample - loss: 0.3476 - accuracy: 0.8800 - val_loss: 0.3164 - val_accuracy: 0.8902\n",
            "Epoch 887/1000\n",
            "500/500 [==============================] - 0s 510us/sample - loss: 0.2843 - accuracy: 0.9100 - val_loss: 0.3263 - val_accuracy: 0.8659\n",
            "Epoch 888/1000\n",
            "500/500 [==============================] - 0s 607us/sample - loss: 0.3200 - accuracy: 0.8720 - val_loss: 0.3143 - val_accuracy: 0.8841\n",
            "Epoch 889/1000\n",
            "500/500 [==============================] - 0s 612us/sample - loss: 0.2736 - accuracy: 0.9000 - val_loss: 0.3183 - val_accuracy: 0.8780\n",
            "Epoch 890/1000\n",
            "500/500 [==============================] - 0s 532us/sample - loss: 0.3333 - accuracy: 0.8720 - val_loss: 0.3185 - val_accuracy: 0.8902\n",
            "Epoch 891/1000\n",
            "500/500 [==============================] - 0s 560us/sample - loss: 0.3532 - accuracy: 0.8660 - val_loss: 0.3138 - val_accuracy: 0.8963\n",
            "Epoch 892/1000\n",
            "500/500 [==============================] - 0s 623us/sample - loss: 0.3262 - accuracy: 0.8860 - val_loss: 0.3197 - val_accuracy: 0.8537\n",
            "Epoch 893/1000\n",
            "500/500 [==============================] - 0s 505us/sample - loss: 0.3196 - accuracy: 0.8700 - val_loss: 0.3142 - val_accuracy: 0.8720\n",
            "Epoch 894/1000\n",
            "500/500 [==============================] - 0s 507us/sample - loss: 0.2732 - accuracy: 0.8880 - val_loss: 0.3133 - val_accuracy: 0.8841\n",
            "Epoch 895/1000\n",
            "500/500 [==============================] - 0s 559us/sample - loss: 0.3118 - accuracy: 0.8940 - val_loss: 0.3133 - val_accuracy: 0.8902\n",
            "Epoch 896/1000\n",
            "500/500 [==============================] - 0s 572us/sample - loss: 0.3366 - accuracy: 0.8780 - val_loss: 0.3206 - val_accuracy: 0.8780\n",
            "Epoch 897/1000\n",
            "500/500 [==============================] - 0s 597us/sample - loss: 0.3128 - accuracy: 0.8760 - val_loss: 0.3143 - val_accuracy: 0.8902\n",
            "Epoch 898/1000\n",
            "500/500 [==============================] - 0s 622us/sample - loss: 0.2519 - accuracy: 0.9040 - val_loss: 0.3149 - val_accuracy: 0.8902\n",
            "Epoch 899/1000\n",
            "500/500 [==============================] - 0s 608us/sample - loss: 0.2869 - accuracy: 0.8920 - val_loss: 0.3117 - val_accuracy: 0.8841\n",
            "Epoch 900/1000\n",
            "500/500 [==============================] - 0s 549us/sample - loss: 0.3098 - accuracy: 0.8840 - val_loss: 0.3209 - val_accuracy: 0.8780\n",
            "Epoch 901/1000\n",
            "500/500 [==============================] - 0s 502us/sample - loss: 0.3198 - accuracy: 0.8680 - val_loss: 0.3170 - val_accuracy: 0.8902\n",
            "Epoch 902/1000\n",
            "500/500 [==============================] - 0s 624us/sample - loss: 0.2886 - accuracy: 0.8820 - val_loss: 0.3128 - val_accuracy: 0.8841\n",
            "Epoch 903/1000\n",
            "500/500 [==============================] - 0s 606us/sample - loss: 0.3159 - accuracy: 0.8620 - val_loss: 0.3113 - val_accuracy: 0.8841\n",
            "Epoch 904/1000\n",
            "500/500 [==============================] - 0s 529us/sample - loss: 0.3224 - accuracy: 0.8600 - val_loss: 0.3016 - val_accuracy: 0.8963\n",
            "Epoch 905/1000\n",
            "500/500 [==============================] - 0s 573us/sample - loss: 0.3169 - accuracy: 0.8880 - val_loss: 0.3084 - val_accuracy: 0.8902\n",
            "Epoch 906/1000\n",
            "500/500 [==============================] - 0s 624us/sample - loss: 0.2962 - accuracy: 0.9020 - val_loss: 0.3013 - val_accuracy: 0.8902\n",
            "Epoch 907/1000\n",
            "500/500 [==============================] - 0s 550us/sample - loss: 0.3251 - accuracy: 0.8780 - val_loss: 0.3017 - val_accuracy: 0.8963\n",
            "Epoch 908/1000\n",
            "500/500 [==============================] - 0s 496us/sample - loss: 0.3007 - accuracy: 0.8740 - val_loss: 0.3026 - val_accuracy: 0.8963\n",
            "Epoch 909/1000\n",
            "500/500 [==============================] - 0s 490us/sample - loss: 0.3147 - accuracy: 0.8800 - val_loss: 0.3000 - val_accuracy: 0.9024\n",
            "Epoch 910/1000\n",
            "500/500 [==============================] - 0s 640us/sample - loss: 0.2872 - accuracy: 0.8900 - val_loss: 0.3054 - val_accuracy: 0.8841\n",
            "Epoch 911/1000\n",
            "500/500 [==============================] - 0s 556us/sample - loss: 0.3209 - accuracy: 0.8840 - val_loss: 0.3119 - val_accuracy: 0.8841\n",
            "Epoch 912/1000\n",
            "500/500 [==============================] - 0s 493us/sample - loss: 0.2981 - accuracy: 0.8820 - val_loss: 0.3135 - val_accuracy: 0.8841\n",
            "Epoch 913/1000\n",
            "500/500 [==============================] - 0s 496us/sample - loss: 0.2941 - accuracy: 0.8940 - val_loss: 0.3053 - val_accuracy: 0.8720\n",
            "Epoch 914/1000\n",
            "500/500 [==============================] - 0s 603us/sample - loss: 0.2922 - accuracy: 0.8780 - val_loss: 0.3115 - val_accuracy: 0.8902\n",
            "Epoch 915/1000\n",
            "500/500 [==============================] - 0s 634us/sample - loss: 0.3249 - accuracy: 0.8760 - val_loss: 0.3088 - val_accuracy: 0.8902\n",
            "Epoch 916/1000\n",
            "500/500 [==============================] - 0s 659us/sample - loss: 0.3065 - accuracy: 0.8940 - val_loss: 0.3149 - val_accuracy: 0.8780\n",
            "Epoch 917/1000\n",
            "500/500 [==============================] - 0s 618us/sample - loss: 0.3066 - accuracy: 0.8820 - val_loss: 0.3189 - val_accuracy: 0.8598\n",
            "Epoch 918/1000\n",
            "500/500 [==============================] - 0s 606us/sample - loss: 0.2948 - accuracy: 0.8840 - val_loss: 0.3203 - val_accuracy: 0.8720\n",
            "Epoch 919/1000\n",
            "500/500 [==============================] - 0s 618us/sample - loss: 0.3048 - accuracy: 0.8740 - val_loss: 0.3233 - val_accuracy: 0.8720\n",
            "Epoch 920/1000\n",
            "500/500 [==============================] - 0s 607us/sample - loss: 0.2961 - accuracy: 0.8860 - val_loss: 0.3166 - val_accuracy: 0.8780\n",
            "Epoch 921/1000\n",
            "500/500 [==============================] - 0s 616us/sample - loss: 0.3333 - accuracy: 0.8600 - val_loss: 0.3201 - val_accuracy: 0.8841\n",
            "Epoch 922/1000\n",
            "500/500 [==============================] - 0s 625us/sample - loss: 0.2853 - accuracy: 0.8740 - val_loss: 0.3278 - val_accuracy: 0.8780\n",
            "Epoch 923/1000\n",
            "500/500 [==============================] - 0s 597us/sample - loss: 0.2895 - accuracy: 0.8980 - val_loss: 0.3290 - val_accuracy: 0.8780\n",
            "Epoch 924/1000\n",
            "500/500 [==============================] - 0s 623us/sample - loss: 0.2489 - accuracy: 0.9140 - val_loss: 0.3334 - val_accuracy: 0.8841\n",
            "Epoch 925/1000\n",
            "500/500 [==============================] - 0s 587us/sample - loss: 0.2895 - accuracy: 0.8940 - val_loss: 0.3334 - val_accuracy: 0.8841\n",
            "Epoch 926/1000\n",
            "500/500 [==============================] - 0s 624us/sample - loss: 0.3011 - accuracy: 0.8860 - val_loss: 0.3170 - val_accuracy: 0.8780\n",
            "Epoch 927/1000\n",
            "500/500 [==============================] - 0s 578us/sample - loss: 0.2767 - accuracy: 0.8980 - val_loss: 0.3081 - val_accuracy: 0.8780\n",
            "Epoch 928/1000\n",
            "500/500 [==============================] - 0s 578us/sample - loss: 0.2699 - accuracy: 0.9120 - val_loss: 0.3139 - val_accuracy: 0.8780\n",
            "Epoch 929/1000\n",
            "500/500 [==============================] - 0s 660us/sample - loss: 0.3198 - accuracy: 0.8840 - val_loss: 0.3187 - val_accuracy: 0.8963\n",
            "Epoch 930/1000\n",
            "500/500 [==============================] - 0s 610us/sample - loss: 0.3045 - accuracy: 0.8820 - val_loss: 0.3158 - val_accuracy: 0.8902\n",
            "Epoch 931/1000\n",
            "500/500 [==============================] - 0s 643us/sample - loss: 0.2950 - accuracy: 0.8940 - val_loss: 0.3224 - val_accuracy: 0.8902\n",
            "Epoch 932/1000\n",
            "500/500 [==============================] - 0s 639us/sample - loss: 0.3019 - accuracy: 0.8840 - val_loss: 0.3189 - val_accuracy: 0.9024\n",
            "Epoch 933/1000\n",
            "500/500 [==============================] - 0s 571us/sample - loss: 0.2762 - accuracy: 0.9080 - val_loss: 0.3189 - val_accuracy: 0.8963\n",
            "Epoch 934/1000\n",
            "500/500 [==============================] - 0s 609us/sample - loss: 0.2716 - accuracy: 0.9060 - val_loss: 0.3209 - val_accuracy: 0.8902\n",
            "Epoch 935/1000\n",
            "500/500 [==============================] - 0s 655us/sample - loss: 0.3373 - accuracy: 0.8760 - val_loss: 0.3130 - val_accuracy: 0.8902\n",
            "Epoch 936/1000\n",
            "500/500 [==============================] - 0s 605us/sample - loss: 0.2889 - accuracy: 0.8920 - val_loss: 0.3134 - val_accuracy: 0.8963\n",
            "Epoch 937/1000\n",
            "500/500 [==============================] - 0s 549us/sample - loss: 0.2955 - accuracy: 0.8860 - val_loss: 0.3122 - val_accuracy: 0.8841\n",
            "Epoch 938/1000\n",
            "500/500 [==============================] - 0s 596us/sample - loss: 0.2818 - accuracy: 0.8820 - val_loss: 0.3087 - val_accuracy: 0.9085\n",
            "Epoch 939/1000\n",
            "500/500 [==============================] - 0s 549us/sample - loss: 0.3348 - accuracy: 0.8560 - val_loss: 0.2985 - val_accuracy: 0.8902\n",
            "Epoch 940/1000\n",
            "500/500 [==============================] - 0s 539us/sample - loss: 0.3181 - accuracy: 0.8860 - val_loss: 0.3085 - val_accuracy: 0.8902\n",
            "Epoch 941/1000\n",
            "500/500 [==============================] - 0s 579us/sample - loss: 0.2948 - accuracy: 0.8900 - val_loss: 0.3082 - val_accuracy: 0.8902\n",
            "Epoch 942/1000\n",
            "500/500 [==============================] - 0s 623us/sample - loss: 0.2948 - accuracy: 0.8860 - val_loss: 0.3009 - val_accuracy: 0.8963\n",
            "Epoch 943/1000\n",
            "500/500 [==============================] - 0s 603us/sample - loss: 0.2939 - accuracy: 0.8920 - val_loss: 0.3205 - val_accuracy: 0.8902\n",
            "Epoch 944/1000\n",
            "500/500 [==============================] - 0s 524us/sample - loss: 0.3091 - accuracy: 0.8860 - val_loss: 0.3045 - val_accuracy: 0.9024\n",
            "Epoch 945/1000\n",
            "500/500 [==============================] - 0s 508us/sample - loss: 0.2982 - accuracy: 0.8720 - val_loss: 0.3042 - val_accuracy: 0.8963\n",
            "Epoch 946/1000\n",
            "500/500 [==============================] - 0s 529us/sample - loss: 0.2906 - accuracy: 0.8900 - val_loss: 0.3018 - val_accuracy: 0.8963\n",
            "Epoch 947/1000\n",
            "500/500 [==============================] - 0s 585us/sample - loss: 0.3001 - accuracy: 0.8840 - val_loss: 0.3107 - val_accuracy: 0.8963\n",
            "Epoch 948/1000\n",
            "500/500 [==============================] - 0s 620us/sample - loss: 0.3276 - accuracy: 0.8800 - val_loss: 0.3328 - val_accuracy: 0.9024\n",
            "Epoch 949/1000\n",
            "500/500 [==============================] - 0s 632us/sample - loss: 0.3118 - accuracy: 0.8820 - val_loss: 0.3280 - val_accuracy: 0.8841\n",
            "Epoch 950/1000\n",
            "500/500 [==============================] - 0s 600us/sample - loss: 0.3372 - accuracy: 0.8540 - val_loss: 0.3027 - val_accuracy: 0.8963\n",
            "Epoch 951/1000\n",
            "500/500 [==============================] - 0s 536us/sample - loss: 0.3364 - accuracy: 0.8720 - val_loss: 0.3000 - val_accuracy: 0.8902\n",
            "Epoch 952/1000\n",
            "500/500 [==============================] - 0s 631us/sample - loss: 0.2935 - accuracy: 0.8920 - val_loss: 0.3194 - val_accuracy: 0.8780\n",
            "Epoch 953/1000\n",
            "500/500 [==============================] - 0s 651us/sample - loss: 0.3018 - accuracy: 0.8920 - val_loss: 0.3058 - val_accuracy: 0.8841\n",
            "Epoch 954/1000\n",
            "500/500 [==============================] - 0s 581us/sample - loss: 0.2926 - accuracy: 0.8880 - val_loss: 0.3077 - val_accuracy: 0.8720\n",
            "Epoch 955/1000\n",
            "500/500 [==============================] - 0s 484us/sample - loss: 0.2860 - accuracy: 0.8980 - val_loss: 0.3204 - val_accuracy: 0.8841\n",
            "Epoch 956/1000\n",
            "500/500 [==============================] - 0s 526us/sample - loss: 0.2800 - accuracy: 0.8980 - val_loss: 0.3132 - val_accuracy: 0.8902\n",
            "Epoch 957/1000\n",
            "500/500 [==============================] - 0s 612us/sample - loss: 0.3090 - accuracy: 0.8780 - val_loss: 0.3158 - val_accuracy: 0.8841\n",
            "Epoch 958/1000\n",
            "500/500 [==============================] - 0s 535us/sample - loss: 0.3008 - accuracy: 0.8940 - val_loss: 0.3109 - val_accuracy: 0.8963\n",
            "Epoch 959/1000\n",
            "500/500 [==============================] - 0s 502us/sample - loss: 0.3197 - accuracy: 0.8860 - val_loss: 0.3128 - val_accuracy: 0.8841\n",
            "Epoch 960/1000\n",
            "500/500 [==============================] - 0s 640us/sample - loss: 0.2568 - accuracy: 0.9100 - val_loss: 0.3191 - val_accuracy: 0.8902\n",
            "Epoch 961/1000\n",
            "500/500 [==============================] - 0s 570us/sample - loss: 0.2734 - accuracy: 0.8940 - val_loss: 0.3105 - val_accuracy: 0.8841\n",
            "Epoch 962/1000\n",
            "500/500 [==============================] - 0s 558us/sample - loss: 0.2956 - accuracy: 0.8900 - val_loss: 0.3105 - val_accuracy: 0.8780\n",
            "Epoch 963/1000\n",
            "500/500 [==============================] - 0s 550us/sample - loss: 0.2842 - accuracy: 0.8920 - val_loss: 0.3145 - val_accuracy: 0.8902\n",
            "Epoch 964/1000\n",
            "500/500 [==============================] - 0s 610us/sample - loss: 0.2779 - accuracy: 0.8960 - val_loss: 0.3125 - val_accuracy: 0.8780\n",
            "Epoch 965/1000\n",
            "500/500 [==============================] - 0s 523us/sample - loss: 0.3461 - accuracy: 0.8700 - val_loss: 0.3200 - val_accuracy: 0.8841\n",
            "Epoch 966/1000\n",
            "500/500 [==============================] - 0s 505us/sample - loss: 0.3208 - accuracy: 0.8760 - val_loss: 0.3144 - val_accuracy: 0.8902\n",
            "Epoch 967/1000\n",
            "500/500 [==============================] - 0s 643us/sample - loss: 0.3128 - accuracy: 0.8860 - val_loss: 0.3180 - val_accuracy: 0.8780\n",
            "Epoch 968/1000\n",
            "500/500 [==============================] - 0s 591us/sample - loss: 0.2878 - accuracy: 0.8980 - val_loss: 0.3215 - val_accuracy: 0.8902\n",
            "Epoch 969/1000\n",
            "500/500 [==============================] - 0s 478us/sample - loss: 0.3179 - accuracy: 0.8760 - val_loss: 0.3188 - val_accuracy: 0.8841\n",
            "Epoch 970/1000\n",
            "500/500 [==============================] - 0s 499us/sample - loss: 0.3411 - accuracy: 0.8800 - val_loss: 0.3240 - val_accuracy: 0.8780\n",
            "Epoch 971/1000\n",
            "500/500 [==============================] - 0s 591us/sample - loss: 0.3299 - accuracy: 0.8640 - val_loss: 0.3305 - val_accuracy: 0.8720\n",
            "Epoch 972/1000\n",
            "500/500 [==============================] - 0s 600us/sample - loss: 0.2824 - accuracy: 0.8780 - val_loss: 0.3211 - val_accuracy: 0.8841\n",
            "Epoch 973/1000\n",
            "500/500 [==============================] - 0s 651us/sample - loss: 0.3308 - accuracy: 0.8780 - val_loss: 0.3090 - val_accuracy: 0.8902\n",
            "Epoch 974/1000\n",
            "500/500 [==============================] - 0s 612us/sample - loss: 0.3042 - accuracy: 0.8960 - val_loss: 0.3025 - val_accuracy: 0.8902\n",
            "Epoch 975/1000\n",
            "500/500 [==============================] - 0s 597us/sample - loss: 0.2784 - accuracy: 0.9040 - val_loss: 0.3056 - val_accuracy: 0.8963\n",
            "Epoch 976/1000\n",
            "500/500 [==============================] - 0s 554us/sample - loss: 0.3462 - accuracy: 0.8600 - val_loss: 0.3043 - val_accuracy: 0.8780\n",
            "Epoch 977/1000\n",
            "500/500 [==============================] - 0s 498us/sample - loss: 0.3074 - accuracy: 0.8880 - val_loss: 0.3129 - val_accuracy: 0.8902\n",
            "Epoch 978/1000\n",
            "500/500 [==============================] - 0s 592us/sample - loss: 0.2726 - accuracy: 0.9000 - val_loss: 0.3186 - val_accuracy: 0.8963\n",
            "Epoch 979/1000\n",
            "500/500 [==============================] - 0s 533us/sample - loss: 0.3252 - accuracy: 0.8680 - val_loss: 0.3384 - val_accuracy: 0.8841\n",
            "Epoch 980/1000\n",
            "500/500 [==============================] - 0s 663us/sample - loss: 0.3120 - accuracy: 0.8780 - val_loss: 0.3178 - val_accuracy: 0.8720\n",
            "Epoch 981/1000\n",
            "500/500 [==============================] - 0s 659us/sample - loss: 0.2967 - accuracy: 0.8960 - val_loss: 0.3286 - val_accuracy: 0.8841\n",
            "Epoch 982/1000\n",
            "500/500 [==============================] - 0s 609us/sample - loss: 0.3012 - accuracy: 0.8820 - val_loss: 0.3315 - val_accuracy: 0.8841\n",
            "Epoch 983/1000\n",
            "500/500 [==============================] - 0s 605us/sample - loss: 0.2728 - accuracy: 0.9120 - val_loss: 0.3311 - val_accuracy: 0.8841\n",
            "Epoch 984/1000\n",
            "500/500 [==============================] - 0s 600us/sample - loss: 0.3098 - accuracy: 0.8780 - val_loss: 0.3334 - val_accuracy: 0.8902\n",
            "Epoch 985/1000\n",
            "500/500 [==============================] - 0s 607us/sample - loss: 0.2645 - accuracy: 0.9080 - val_loss: 0.3334 - val_accuracy: 0.9085\n",
            "Epoch 986/1000\n",
            "500/500 [==============================] - 0s 585us/sample - loss: 0.3245 - accuracy: 0.8740 - val_loss: 0.3383 - val_accuracy: 0.8902\n",
            "Epoch 987/1000\n",
            "500/500 [==============================] - 0s 523us/sample - loss: 0.3371 - accuracy: 0.8620 - val_loss: 0.3246 - val_accuracy: 0.9024\n",
            "Epoch 988/1000\n",
            "500/500 [==============================] - 0s 533us/sample - loss: 0.2826 - accuracy: 0.8820 - val_loss: 0.3337 - val_accuracy: 0.9024\n",
            "Epoch 989/1000\n",
            "500/500 [==============================] - 0s 578us/sample - loss: 0.2843 - accuracy: 0.8860 - val_loss: 0.3373 - val_accuracy: 0.8902\n",
            "Epoch 990/1000\n",
            "500/500 [==============================] - 0s 574us/sample - loss: 0.3119 - accuracy: 0.8720 - val_loss: 0.3221 - val_accuracy: 0.8963\n",
            "Epoch 991/1000\n",
            "500/500 [==============================] - 0s 543us/sample - loss: 0.2994 - accuracy: 0.8860 - val_loss: 0.3215 - val_accuracy: 0.9085\n",
            "Epoch 992/1000\n",
            "500/500 [==============================] - 0s 555us/sample - loss: 0.2959 - accuracy: 0.8800 - val_loss: 0.3206 - val_accuracy: 0.8963\n",
            "Epoch 993/1000\n",
            "500/500 [==============================] - 0s 612us/sample - loss: 0.2664 - accuracy: 0.9080 - val_loss: 0.3196 - val_accuracy: 0.8841\n",
            "Epoch 994/1000\n",
            "500/500 [==============================] - 0s 615us/sample - loss: 0.3447 - accuracy: 0.8620 - val_loss: 0.3124 - val_accuracy: 0.8963\n",
            "Epoch 995/1000\n",
            "500/500 [==============================] - 0s 596us/sample - loss: 0.2937 - accuracy: 0.9000 - val_loss: 0.3178 - val_accuracy: 0.8902\n",
            "Epoch 996/1000\n",
            "500/500 [==============================] - 0s 609us/sample - loss: 0.2853 - accuracy: 0.8900 - val_loss: 0.3357 - val_accuracy: 0.8902\n",
            "Epoch 997/1000\n",
            "500/500 [==============================] - 0s 679us/sample - loss: 0.2868 - accuracy: 0.8900 - val_loss: 0.3217 - val_accuracy: 0.8841\n",
            "Epoch 998/1000\n",
            "500/500 [==============================] - 0s 640us/sample - loss: 0.2744 - accuracy: 0.8980 - val_loss: 0.3119 - val_accuracy: 0.8902\n",
            "Epoch 999/1000\n",
            "500/500 [==============================] - 0s 594us/sample - loss: 0.3125 - accuracy: 0.8880 - val_loss: 0.3179 - val_accuracy: 0.8841\n",
            "Epoch 1000/1000\n",
            "500/500 [==============================] - 0s 584us/sample - loss: 0.3988 - accuracy: 0.8580 - val_loss: 0.3059 - val_accuracy: 0.9085\n",
            "164/164 [==============================] - 0s 331us/sample - loss: 0.3059 - accuracy: 0.9085\n",
            "\n",
            "Accuracy: 0.91\n",
            "MCC: 0.82\n",
            "Sensitivity: 0.9512\n",
            "Specificity: 0.8659\n",
            "Precision: 0.8764\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nUsrmNBAopZTNaSBQSimb+3903nIZfoOm6gAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R3YFPacCNbz0",
        "colab_type": "code",
        "outputId": "fe8ede5f-ab1b-43df-fc42-4846cc7bf13f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Help on class Dropout in module tensorflow.python.keras.layers.core:\n",
            "\n",
            "class Dropout(tensorflow.python.keras.engine.base_layer.Layer)\n",
            " |  Applies Dropout to the input.\n",
            " |  \n",
            " |  Dropout consists in randomly setting\n",
            " |  a fraction `rate` of input units to 0 at each update during training time,\n",
            " |  which helps prevent overfitting.\n",
            " |  \n",
            " |  Arguments:\n",
            " |    rate: Float between 0 and 1. Fraction of the input units to drop.\n",
            " |    noise_shape: 1D integer tensor representing the shape of the\n",
            " |      binary dropout mask that will be multiplied with the input.\n",
            " |      For instance, if your inputs have shape\n",
            " |      `(batch_size, timesteps, features)` and\n",
            " |      you want the dropout mask to be the same for all timesteps,\n",
            " |      you can use `noise_shape=(batch_size, 1, features)`.\n",
            " |    seed: A Python integer to use as random seed.\n",
            " |  \n",
            " |  Call arguments:\n",
            " |    inputs: Input tensor (of any rank).\n",
            " |    training: Python boolean indicating whether the layer should behave in\n",
            " |      training mode (adding dropout) or in inference mode (doing nothing).\n",
            " |  \n",
            " |  Method resolution order:\n",
            " |      Dropout\n",
            " |      tensorflow.python.keras.engine.base_layer.Layer\n",
            " |      tensorflow.python.module.module.Module\n",
            " |      tensorflow.python.training.tracking.tracking.AutoTrackable\n",
            " |      tensorflow.python.training.tracking.base.Trackable\n",
            " |      builtins.object\n",
            " |  \n",
            " |  Methods defined here:\n",
            " |  \n",
            " |  __init__(self, rate, noise_shape=None, seed=None, **kwargs)\n",
            " |  \n",
            " |  call(self, inputs, training=None)\n",
            " |      This is where the layer's logic lives.\n",
            " |      \n",
            " |      Arguments:\n",
            " |          inputs: Input tensor, or list/tuple of input tensors.\n",
            " |          **kwargs: Additional keyword arguments.\n",
            " |      \n",
            " |      Returns:\n",
            " |          A tensor or list/tuple of tensors.\n",
            " |  \n",
            " |  compute_output_shape(self, input_shape)\n",
            " |      Computes the output shape of the layer.\n",
            " |      \n",
            " |      If the layer has not been built, this method will call `build` on the\n",
            " |      layer. This assumes that the layer will later be used with inputs that\n",
            " |      match the input shape provided here.\n",
            " |      \n",
            " |      Arguments:\n",
            " |          input_shape: Shape tuple (tuple of integers)\n",
            " |              or list of shape tuples (one per output tensor of the layer).\n",
            " |              Shape tuples can include None for free dimensions,\n",
            " |              instead of an integer.\n",
            " |      \n",
            " |      Returns:\n",
            " |          An input shape tuple.\n",
            " |  \n",
            " |  get_config(self)\n",
            " |      Returns the config of the layer.\n",
            " |      \n",
            " |      A layer config is a Python dictionary (serializable)\n",
            " |      containing the configuration of a layer.\n",
            " |      The same layer can be reinstantiated later\n",
            " |      (without its trained weights) from this configuration.\n",
            " |      \n",
            " |      The config of a layer does not include connectivity\n",
            " |      information, nor the layer class name. These are handled\n",
            " |      by `Network` (one layer of abstraction above).\n",
            " |      \n",
            " |      Returns:\n",
            " |          Python dictionary.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Methods inherited from tensorflow.python.keras.engine.base_layer.Layer:\n",
            " |  \n",
            " |  __call__(self, inputs, *args, **kwargs)\n",
            " |      Wraps `call`, applying pre- and post-processing steps.\n",
            " |      \n",
            " |      Arguments:\n",
            " |        inputs: input tensor(s).\n",
            " |        *args: additional positional arguments to be passed to `self.call`.\n",
            " |        **kwargs: additional keyword arguments to be passed to `self.call`.\n",
            " |      \n",
            " |      Returns:\n",
            " |        Output tensor(s).\n",
            " |      \n",
            " |      Note:\n",
            " |        - The following optional keyword arguments are reserved for specific uses:\n",
            " |          * `training`: Boolean scalar tensor of Python boolean indicating\n",
            " |            whether the `call` is meant for training or inference.\n",
            " |          * `mask`: Boolean input mask.\n",
            " |        - If the layer's `call` method takes a `mask` argument (as some Keras\n",
            " |          layers do), its default value will be set to the mask generated\n",
            " |          for `inputs` by the previous layer (if `input` did come from\n",
            " |          a layer that generated a corresponding mask, i.e. if it came from\n",
            " |          a Keras layer with masking support.\n",
            " |      \n",
            " |      Raises:\n",
            " |        ValueError: if the layer's `call` method returns None (an invalid value).\n",
            " |  \n",
            " |  __delattr__(self, name)\n",
            " |      Implement delattr(self, name).\n",
            " |  \n",
            " |  __getstate__(self)\n",
            " |  \n",
            " |  __setattr__(self, name, value)\n",
            " |      Support self.foo = trackable syntax.\n",
            " |  \n",
            " |  __setstate__(self, state)\n",
            " |  \n",
            " |  add_loss(self, losses, inputs=None)\n",
            " |      Add loss tensor(s), potentially dependent on layer inputs.\n",
            " |      \n",
            " |      Some losses (for instance, activity regularization losses) may be dependent\n",
            " |      on the inputs passed when calling a layer. Hence, when reusing the same\n",
            " |      layer on different inputs `a` and `b`, some entries in `layer.losses` may\n",
            " |      be dependent on `a` and some on `b`. This method automatically keeps track\n",
            " |      of dependencies.\n",
            " |      \n",
            " |      This method can be used inside a subclassed layer or model's `call`\n",
            " |      function, in which case `losses` should be a Tensor or list of Tensors.\n",
            " |      \n",
            " |      Example:\n",
            " |      \n",
            " |      ```python\n",
            " |      class MyLayer(tf.keras.layers.Layer):\n",
            " |        def call(inputs, self):\n",
            " |          self.add_loss(tf.abs(tf.reduce_mean(inputs)), inputs=True)\n",
            " |          return inputs\n",
            " |      ```\n",
            " |      \n",
            " |      This method can also be called directly on a Functional Model during\n",
            " |      construction. In this case, any loss Tensors passed to this Model must\n",
            " |      be symbolic and be able to be traced back to the model's `Input`s. These\n",
            " |      losses become part of the model's topology and are tracked in `get_config`.\n",
            " |      \n",
            " |      Example:\n",
            " |      \n",
            " |      ```python\n",
            " |      inputs = tf.keras.Input(shape=(10,))\n",
            " |      x = tf.keras.layers.Dense(10)(inputs)\n",
            " |      outputs = tf.keras.layers.Dense(1)(x)\n",
            " |      model = tf.keras.Model(inputs, outputs)\n",
            " |      # Actvity regularization.\n",
            " |      model.add_loss(tf.abs(tf.reduce_mean(x)))\n",
            " |      ```\n",
            " |      \n",
            " |      If this is not the case for your loss (if, for example, your loss references\n",
            " |      a `Variable` of one of the model's layers), you can wrap your loss in a\n",
            " |      zero-argument lambda. These losses are not tracked as part of the model's\n",
            " |      topology since they can't be serialized.\n",
            " |      \n",
            " |      Example:\n",
            " |      \n",
            " |      ```python\n",
            " |      inputs = tf.keras.Input(shape=(10,))\n",
            " |      x = tf.keras.layers.Dense(10)(inputs)\n",
            " |      outputs = tf.keras.layers.Dense(1)(x)\n",
            " |      model = tf.keras.Model(inputs, outputs)\n",
            " |      # Weight regularization.\n",
            " |      model.add_loss(lambda: tf.reduce_mean(x.kernel))\n",
            " |      ```\n",
            " |      \n",
            " |      The `get_losses_for` method allows to retrieve the losses relevant to a\n",
            " |      specific set of inputs.\n",
            " |      \n",
            " |      Arguments:\n",
            " |        losses: Loss tensor, or list/tuple of tensors. Rather than tensors, losses\n",
            " |          may also be zero-argument callables which create a loss tensor.\n",
            " |        inputs: Ignored when executing eagerly. If anything other than None is\n",
            " |          passed, it signals the losses are conditional on some of the layer's\n",
            " |          inputs, and thus they should only be run where these inputs are\n",
            " |          available. This is the case for activity regularization losses, for\n",
            " |          instance. If `None` is passed, the losses are assumed\n",
            " |          to be unconditional, and will apply across all dataflows of the layer\n",
            " |          (e.g. weight regularization losses).\n",
            " |  \n",
            " |  add_metric(self, value, aggregation=None, name=None)\n",
            " |      Adds metric tensor to the layer.\n",
            " |      \n",
            " |      Args:\n",
            " |        value: Metric tensor.\n",
            " |        aggregation: Sample-wise metric reduction function. If `aggregation=None`,\n",
            " |          it indicates that the metric tensor provided has been aggregated\n",
            " |          already. eg, `bin_acc = BinaryAccuracy(name='acc')` followed by\n",
            " |          `model.add_metric(bin_acc(y_true, y_pred))`. If aggregation='mean', the\n",
            " |          given metric tensor will be sample-wise reduced using `mean` function.\n",
            " |          eg, `model.add_metric(tf.reduce_sum(outputs), name='output_mean',\n",
            " |          aggregation='mean')`.\n",
            " |        name: String metric name.\n",
            " |      \n",
            " |      Raises:\n",
            " |        ValueError: If `aggregation` is anything other than None or `mean`.\n",
            " |  \n",
            " |  add_update(self, updates, inputs=None)\n",
            " |      Add update op(s), potentially dependent on layer inputs. (deprecated arguments)\n",
            " |      \n",
            " |      Warning: SOME ARGUMENTS ARE DEPRECATED: `(inputs)`. They will be removed in a future version.\n",
            " |      Instructions for updating:\n",
            " |      `inputs` is now automatically inferred\n",
            " |      \n",
            " |      Weight updates (for instance, the updates of the moving mean and variance\n",
            " |      in a BatchNormalization layer) may be dependent on the inputs passed\n",
            " |      when calling a layer. Hence, when reusing the same layer on\n",
            " |      different inputs `a` and `b`, some entries in `layer.updates` may be\n",
            " |      dependent on `a` and some on `b`. This method automatically keeps track\n",
            " |      of dependencies.\n",
            " |      \n",
            " |      The `get_updates_for` method allows to retrieve the updates relevant to a\n",
            " |      specific set of inputs.\n",
            " |      \n",
            " |      This call is ignored when eager execution is enabled (in that case, variable\n",
            " |      updates are run on the fly and thus do not need to be tracked for later\n",
            " |      execution).\n",
            " |      \n",
            " |      Arguments:\n",
            " |        updates: Update op, or list/tuple of update ops, or zero-arg callable\n",
            " |          that returns an update op. A zero-arg callable should be passed in\n",
            " |          order to disable running the updates by setting `trainable=False`\n",
            " |          on this Layer, when executing in Eager mode.\n",
            " |        inputs: Deprecated, will be automatically inferred.\n",
            " |  \n",
            " |  add_variable(self, *args, **kwargs)\n",
            " |      Deprecated, do NOT use! Alias for `add_weight`. (deprecated)\n",
            " |      \n",
            " |      Warning: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
            " |      Instructions for updating:\n",
            " |      Please use `layer.add_weight` method instead.\n",
            " |  \n",
            " |  add_weight(self, name=None, shape=None, dtype=None, initializer=None, regularizer=None, trainable=None, constraint=None, partitioner=None, use_resource=None, synchronization=<VariableSynchronization.AUTO: 0>, aggregation=<VariableAggregation.NONE: 0>, **kwargs)\n",
            " |      Adds a new variable to the layer.\n",
            " |      \n",
            " |      Arguments:\n",
            " |        name: Variable name.\n",
            " |        shape: Variable shape. Defaults to scalar if unspecified.\n",
            " |        dtype: The type of the variable. Defaults to `self.dtype` or `float32`.\n",
            " |        initializer: Initializer instance (callable).\n",
            " |        regularizer: Regularizer instance (callable).\n",
            " |        trainable: Boolean, whether the variable should be part of the layer's\n",
            " |          \"trainable_variables\" (e.g. variables, biases)\n",
            " |          or \"non_trainable_variables\" (e.g. BatchNorm mean and variance).\n",
            " |          Note that `trainable` cannot be `True` if `synchronization`\n",
            " |          is set to `ON_READ`.\n",
            " |        constraint: Constraint instance (callable).\n",
            " |        partitioner: Partitioner to be passed to the `Trackable` API.\n",
            " |        use_resource: Whether to use `ResourceVariable`.\n",
            " |        synchronization: Indicates when a distributed a variable will be\n",
            " |          aggregated. Accepted values are constants defined in the class\n",
            " |          `tf.VariableSynchronization`. By default the synchronization is set to\n",
            " |          `AUTO` and the current `DistributionStrategy` chooses\n",
            " |          when to synchronize. If `synchronization` is set to `ON_READ`,\n",
            " |          `trainable` must not be set to `True`.\n",
            " |        aggregation: Indicates how a distributed variable will be aggregated.\n",
            " |          Accepted values are constants defined in the class\n",
            " |          `tf.VariableAggregation`.\n",
            " |        **kwargs: Additional keyword arguments. Accepted values are `getter`,\n",
            " |          `collections`, `experimental_autocast` and `caching_device`.\n",
            " |      \n",
            " |      Returns:\n",
            " |        The created variable. Usually either a `Variable` or `ResourceVariable`\n",
            " |        instance. If `partitioner` is not `None`, a `PartitionedVariable`\n",
            " |        instance is returned.\n",
            " |      \n",
            " |      Raises:\n",
            " |        RuntimeError: If called with partitioned variable regularization and\n",
            " |          eager execution is enabled.\n",
            " |        ValueError: When giving unsupported dtype and no initializer or when\n",
            " |          trainable has been set to True with synchronization set as `ON_READ`.\n",
            " |  \n",
            " |  apply(self, inputs, *args, **kwargs)\n",
            " |      Deprecated, do NOT use! (deprecated)\n",
            " |      \n",
            " |      Warning: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
            " |      Instructions for updating:\n",
            " |      Please use `layer.__call__` method instead.\n",
            " |      \n",
            " |      This is an alias of `self.__call__`.\n",
            " |      \n",
            " |      Arguments:\n",
            " |        inputs: Input tensor(s).\n",
            " |        *args: additional positional arguments to be passed to `self.call`.\n",
            " |        **kwargs: additional keyword arguments to be passed to `self.call`.\n",
            " |      \n",
            " |      Returns:\n",
            " |        Output tensor(s).\n",
            " |  \n",
            " |  build(self, input_shape)\n",
            " |      Creates the variables of the layer (optional, for subclass implementers).\n",
            " |      \n",
            " |      This is a method that implementers of subclasses of `Layer` or `Model`\n",
            " |      can override if they need a state-creation step in-between\n",
            " |      layer instantiation and layer call.\n",
            " |      \n",
            " |      This is typically used to create the weights of `Layer` subclasses.\n",
            " |      \n",
            " |      Arguments:\n",
            " |        input_shape: Instance of `TensorShape`, or list of instances of\n",
            " |          `TensorShape` if the layer expects a list of inputs\n",
            " |          (one instance per input).\n",
            " |  \n",
            " |  compute_mask(self, inputs, mask=None)\n",
            " |      Computes an output mask tensor.\n",
            " |      \n",
            " |      Arguments:\n",
            " |          inputs: Tensor or list of tensors.\n",
            " |          mask: Tensor or list of tensors.\n",
            " |      \n",
            " |      Returns:\n",
            " |          None or a tensor (or list of tensors,\n",
            " |              one per output tensor of the layer).\n",
            " |  \n",
            " |  compute_output_signature(self, input_signature)\n",
            " |      Compute the output tensor signature of the layer based on the inputs.\n",
            " |      \n",
            " |      Unlike a TensorShape object, a TensorSpec object contains both shape\n",
            " |      and dtype information for a tensor. This method allows layers to provide\n",
            " |      output dtype information if it is different from the input dtype.\n",
            " |      For any layer that doesn't implement this function,\n",
            " |      the framework will fall back to use `compute_output_shape`, and will\n",
            " |      assume that the output dtype matches the input dtype.\n",
            " |      \n",
            " |      Args:\n",
            " |        input_signature: Single TensorSpec or nested structure of TensorSpec\n",
            " |          objects, describing a candidate input for the layer.\n",
            " |      \n",
            " |      Returns:\n",
            " |        Single TensorSpec or nested structure of TensorSpec objects, describing\n",
            " |          how the layer would transform the provided input.\n",
            " |      \n",
            " |      Raises:\n",
            " |        TypeError: If input_signature contains a non-TensorSpec object.\n",
            " |  \n",
            " |  count_params(self)\n",
            " |      Count the total number of scalars composing the weights.\n",
            " |      \n",
            " |      Returns:\n",
            " |          An integer count.\n",
            " |      \n",
            " |      Raises:\n",
            " |          ValueError: if the layer isn't yet built\n",
            " |            (in which case its weights aren't yet defined).\n",
            " |  \n",
            " |  get_input_at(self, node_index)\n",
            " |      Retrieves the input tensor(s) of a layer at a given node.\n",
            " |      \n",
            " |      Arguments:\n",
            " |          node_index: Integer, index of the node\n",
            " |              from which to retrieve the attribute.\n",
            " |              E.g. `node_index=0` will correspond to the\n",
            " |              first time the layer was called.\n",
            " |      \n",
            " |      Returns:\n",
            " |          A tensor (or list of tensors if the layer has multiple inputs).\n",
            " |      \n",
            " |      Raises:\n",
            " |        RuntimeError: If called in Eager mode.\n",
            " |  \n",
            " |  get_input_mask_at(self, node_index)\n",
            " |      Retrieves the input mask tensor(s) of a layer at a given node.\n",
            " |      \n",
            " |      Arguments:\n",
            " |          node_index: Integer, index of the node\n",
            " |              from which to retrieve the attribute.\n",
            " |              E.g. `node_index=0` will correspond to the\n",
            " |              first time the layer was called.\n",
            " |      \n",
            " |      Returns:\n",
            " |          A mask tensor\n",
            " |          (or list of tensors if the layer has multiple inputs).\n",
            " |  \n",
            " |  get_input_shape_at(self, node_index)\n",
            " |      Retrieves the input shape(s) of a layer at a given node.\n",
            " |      \n",
            " |      Arguments:\n",
            " |          node_index: Integer, index of the node\n",
            " |              from which to retrieve the attribute.\n",
            " |              E.g. `node_index=0` will correspond to the\n",
            " |              first time the layer was called.\n",
            " |      \n",
            " |      Returns:\n",
            " |          A shape tuple\n",
            " |          (or list of shape tuples if the layer has multiple inputs).\n",
            " |      \n",
            " |      Raises:\n",
            " |        RuntimeError: If called in Eager mode.\n",
            " |  \n",
            " |  get_losses_for(self, inputs)\n",
            " |      Retrieves losses relevant to a specific set of inputs.\n",
            " |      \n",
            " |      Arguments:\n",
            " |        inputs: Input tensor or list/tuple of input tensors.\n",
            " |      \n",
            " |      Returns:\n",
            " |        List of loss tensors of the layer that depend on `inputs`.\n",
            " |  \n",
            " |  get_output_at(self, node_index)\n",
            " |      Retrieves the output tensor(s) of a layer at a given node.\n",
            " |      \n",
            " |      Arguments:\n",
            " |          node_index: Integer, index of the node\n",
            " |              from which to retrieve the attribute.\n",
            " |              E.g. `node_index=0` will correspond to the\n",
            " |              first time the layer was called.\n",
            " |      \n",
            " |      Returns:\n",
            " |          A tensor (or list of tensors if the layer has multiple outputs).\n",
            " |      \n",
            " |      Raises:\n",
            " |        RuntimeError: If called in Eager mode.\n",
            " |  \n",
            " |  get_output_mask_at(self, node_index)\n",
            " |      Retrieves the output mask tensor(s) of a layer at a given node.\n",
            " |      \n",
            " |      Arguments:\n",
            " |          node_index: Integer, index of the node\n",
            " |              from which to retrieve the attribute.\n",
            " |              E.g. `node_index=0` will correspond to the\n",
            " |              first time the layer was called.\n",
            " |      \n",
            " |      Returns:\n",
            " |          A mask tensor\n",
            " |          (or list of tensors if the layer has multiple outputs).\n",
            " |  \n",
            " |  get_output_shape_at(self, node_index)\n",
            " |      Retrieves the output shape(s) of a layer at a given node.\n",
            " |      \n",
            " |      Arguments:\n",
            " |          node_index: Integer, index of the node\n",
            " |              from which to retrieve the attribute.\n",
            " |              E.g. `node_index=0` will correspond to the\n",
            " |              first time the layer was called.\n",
            " |      \n",
            " |      Returns:\n",
            " |          A shape tuple\n",
            " |          (or list of shape tuples if the layer has multiple outputs).\n",
            " |      \n",
            " |      Raises:\n",
            " |        RuntimeError: If called in Eager mode.\n",
            " |  \n",
            " |  get_updates_for(self, inputs)\n",
            " |      Retrieves updates relevant to a specific set of inputs.\n",
            " |      \n",
            " |      Arguments:\n",
            " |        inputs: Input tensor or list/tuple of input tensors.\n",
            " |      \n",
            " |      Returns:\n",
            " |        List of update ops of the layer that depend on `inputs`.\n",
            " |  \n",
            " |  get_weights(self)\n",
            " |      Returns the current weights of the layer.\n",
            " |      \n",
            " |      Returns:\n",
            " |          Weights values as a list of numpy arrays.\n",
            " |  \n",
            " |  set_weights(self, weights)\n",
            " |      Sets the weights of the layer, from Numpy arrays.\n",
            " |      \n",
            " |      Arguments:\n",
            " |          weights: a list of Numpy arrays. The number\n",
            " |              of arrays and their shape must match\n",
            " |              number of the dimensions of the weights\n",
            " |              of the layer (i.e. it should match the\n",
            " |              output of `get_weights`).\n",
            " |      \n",
            " |      Raises:\n",
            " |          ValueError: If the provided weights list does not match the\n",
            " |              layer's specifications.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Class methods inherited from tensorflow.python.keras.engine.base_layer.Layer:\n",
            " |  \n",
            " |  from_config(config) from builtins.type\n",
            " |      Creates a layer from its config.\n",
            " |      \n",
            " |      This method is the reverse of `get_config`,\n",
            " |      capable of instantiating the same layer from the config\n",
            " |      dictionary. It does not handle layer connectivity\n",
            " |      (handled by Network), nor weights (handled by `set_weights`).\n",
            " |      \n",
            " |      Arguments:\n",
            " |          config: A Python dictionary, typically the\n",
            " |              output of get_config.\n",
            " |      \n",
            " |      Returns:\n",
            " |          A layer instance.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Data descriptors inherited from tensorflow.python.keras.engine.base_layer.Layer:\n",
            " |  \n",
            " |  activity_regularizer\n",
            " |      Optional regularizer function for the output of this layer.\n",
            " |  \n",
            " |  dtype\n",
            " |  \n",
            " |  dynamic\n",
            " |  \n",
            " |  inbound_nodes\n",
            " |      Deprecated, do NOT use! Only for compatibility with external Keras.\n",
            " |  \n",
            " |  input\n",
            " |      Retrieves the input tensor(s) of a layer.\n",
            " |      \n",
            " |      Only applicable if the layer has exactly one input,\n",
            " |      i.e. if it is connected to one incoming layer.\n",
            " |      \n",
            " |      Returns:\n",
            " |          Input tensor or list of input tensors.\n",
            " |      \n",
            " |      Raises:\n",
            " |        RuntimeError: If called in Eager mode.\n",
            " |        AttributeError: If no inbound nodes are found.\n",
            " |  \n",
            " |  input_mask\n",
            " |      Retrieves the input mask tensor(s) of a layer.\n",
            " |      \n",
            " |      Only applicable if the layer has exactly one inbound node,\n",
            " |      i.e. if it is connected to one incoming layer.\n",
            " |      \n",
            " |      Returns:\n",
            " |          Input mask tensor (potentially None) or list of input\n",
            " |          mask tensors.\n",
            " |      \n",
            " |      Raises:\n",
            " |          AttributeError: if the layer is connected to\n",
            " |          more than one incoming layers.\n",
            " |  \n",
            " |  input_shape\n",
            " |      Retrieves the input shape(s) of a layer.\n",
            " |      \n",
            " |      Only applicable if the layer has exactly one input,\n",
            " |      i.e. if it is connected to one incoming layer, or if all inputs\n",
            " |      have the same shape.\n",
            " |      \n",
            " |      Returns:\n",
            " |          Input shape, as an integer shape tuple\n",
            " |          (or list of shape tuples, one tuple per input tensor).\n",
            " |      \n",
            " |      Raises:\n",
            " |          AttributeError: if the layer has no defined input_shape.\n",
            " |          RuntimeError: if called in Eager mode.\n",
            " |  \n",
            " |  input_spec\n",
            " |  \n",
            " |  losses\n",
            " |      Losses which are associated with this `Layer`.\n",
            " |      \n",
            " |      Variable regularization tensors are created when this property is accessed,\n",
            " |      so it is eager safe: accessing `losses` under a `tf.GradientTape` will\n",
            " |      propagate gradients back to the corresponding variables.\n",
            " |      \n",
            " |      Returns:\n",
            " |        A list of tensors.\n",
            " |  \n",
            " |  metrics\n",
            " |  \n",
            " |  name\n",
            " |      Returns the name of this module as passed or determined in the ctor.\n",
            " |      \n",
            " |      NOTE: This is not the same as the `self.name_scope.name` which includes\n",
            " |      parent module names.\n",
            " |  \n",
            " |  non_trainable_variables\n",
            " |  \n",
            " |  non_trainable_weights\n",
            " |  \n",
            " |  outbound_nodes\n",
            " |      Deprecated, do NOT use! Only for compatibility with external Keras.\n",
            " |  \n",
            " |  output\n",
            " |      Retrieves the output tensor(s) of a layer.\n",
            " |      \n",
            " |      Only applicable if the layer has exactly one output,\n",
            " |      i.e. if it is connected to one incoming layer.\n",
            " |      \n",
            " |      Returns:\n",
            " |        Output tensor or list of output tensors.\n",
            " |      \n",
            " |      Raises:\n",
            " |        AttributeError: if the layer is connected to more than one incoming\n",
            " |          layers.\n",
            " |        RuntimeError: if called in Eager mode.\n",
            " |  \n",
            " |  output_mask\n",
            " |      Retrieves the output mask tensor(s) of a layer.\n",
            " |      \n",
            " |      Only applicable if the layer has exactly one inbound node,\n",
            " |      i.e. if it is connected to one incoming layer.\n",
            " |      \n",
            " |      Returns:\n",
            " |          Output mask tensor (potentially None) or list of output\n",
            " |          mask tensors.\n",
            " |      \n",
            " |      Raises:\n",
            " |          AttributeError: if the layer is connected to\n",
            " |          more than one incoming layers.\n",
            " |  \n",
            " |  output_shape\n",
            " |      Retrieves the output shape(s) of a layer.\n",
            " |      \n",
            " |      Only applicable if the layer has one output,\n",
            " |      or if all outputs have the same shape.\n",
            " |      \n",
            " |      Returns:\n",
            " |          Output shape, as an integer shape tuple\n",
            " |          (or list of shape tuples, one tuple per output tensor).\n",
            " |      \n",
            " |      Raises:\n",
            " |          AttributeError: if the layer has no defined output shape.\n",
            " |          RuntimeError: if called in Eager mode.\n",
            " |  \n",
            " |  stateful\n",
            " |  \n",
            " |  trainable\n",
            " |  \n",
            " |  trainable_variables\n",
            " |      Sequence of trainable variables owned by this module and its submodules.\n",
            " |      \n",
            " |      Note: this method uses reflection to find variables on the current instance\n",
            " |      and submodules. For performance reasons you may wish to cache the result\n",
            " |      of calling this method if you don't expect the return value to change.\n",
            " |      \n",
            " |      Returns:\n",
            " |        A sequence of variables for the current module (sorted by attribute\n",
            " |        name) followed by variables from all submodules recursively (breadth\n",
            " |        first).\n",
            " |  \n",
            " |  trainable_weights\n",
            " |  \n",
            " |  updates\n",
            " |  \n",
            " |  variables\n",
            " |      Returns the list of all layer variables/weights.\n",
            " |      \n",
            " |      Alias of `self.weights`.\n",
            " |      \n",
            " |      Returns:\n",
            " |        A list of variables.\n",
            " |  \n",
            " |  weights\n",
            " |      Returns the list of all layer variables/weights.\n",
            " |      \n",
            " |      Returns:\n",
            " |        A list of variables.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Class methods inherited from tensorflow.python.module.module.Module:\n",
            " |  \n",
            " |  with_name_scope(method) from builtins.type\n",
            " |      Decorator to automatically enter the module name scope.\n",
            " |      \n",
            " |      ```\n",
            " |      class MyModule(tf.Module):\n",
            " |        @tf.Module.with_name_scope\n",
            " |        def __call__(self, x):\n",
            " |          if not hasattr(self, 'w'):\n",
            " |            self.w = tf.Variable(tf.random.normal([x.shape[1], 64]))\n",
            " |          return tf.matmul(x, self.w)\n",
            " |      ```\n",
            " |      \n",
            " |      Using the above module would produce `tf.Variable`s and `tf.Tensor`s whose\n",
            " |      names included the module name:\n",
            " |      \n",
            " |      ```\n",
            " |      mod = MyModule()\n",
            " |      mod(tf.ones([8, 32]))\n",
            " |      # ==> <tf.Tensor: ...>\n",
            " |      mod.w\n",
            " |      # ==> <tf.Variable ...'my_module/w:0'>\n",
            " |      ```\n",
            " |      \n",
            " |      Args:\n",
            " |        method: The method to wrap.\n",
            " |      \n",
            " |      Returns:\n",
            " |        The original method wrapped such that it enters the module's name scope.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Data descriptors inherited from tensorflow.python.module.module.Module:\n",
            " |  \n",
            " |  name_scope\n",
            " |      Returns a `tf.name_scope` instance for this class.\n",
            " |  \n",
            " |  submodules\n",
            " |      Sequence of all sub-modules.\n",
            " |      \n",
            " |      Submodules are modules which are properties of this module, or found as\n",
            " |      properties of modules which are properties of this module (and so on).\n",
            " |      \n",
            " |      ```\n",
            " |      a = tf.Module()\n",
            " |      b = tf.Module()\n",
            " |      c = tf.Module()\n",
            " |      a.b = b\n",
            " |      b.c = c\n",
            " |      assert list(a.submodules) == [b, c]\n",
            " |      assert list(b.submodules) == [c]\n",
            " |      assert list(c.submodules) == []\n",
            " |      ```\n",
            " |      \n",
            " |      Returns:\n",
            " |        A sequence of all submodules.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Data descriptors inherited from tensorflow.python.training.tracking.base.Trackable:\n",
            " |  \n",
            " |  __dict__\n",
            " |      dictionary for instance variables (if defined)\n",
            " |  \n",
            " |  __weakref__\n",
            " |      list of weak references to the object (if defined)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KjmMbjvDm6ll",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}